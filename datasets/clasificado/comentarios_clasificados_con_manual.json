[{"comentario": "yes, monadic i/o is a consequence of haskell being lazy. specifically, though, monadic i/o is a consequence of haskell being pure, which is effectively necessary for a lazy language to be predictable.\u2020 this is easy to illustrate with an example. imagine for a moment that haskell were not pure, but it was still lazy. instead of code_removed having the type code_removed, it would simply have the type code_removed, and it would print a string to stdout as a side-effect. the trouble with this is that this would only happen when code_removed is actually called, and in a lazy language, functions are only called when their results are needed. here\u2019s the trouble: code_removed produces code_removed. looking at a value of type code_removed is useless, because code_removed means \u201cboring\u201d. that means that this program would do what you expect: code_removed but i think you can agree that programming style is pretty odd. the code_removed is necessary, however, because it forces the evaluation of the call to code_removed by matching against code_removed. if you tweak the program slightly: code_removed \u2026now it only prints code_removed, and the first call isn\u2019t evaluated at all. this actually gets even worse, though, because it becomes even harder to predict as soon as you start trying to do any actual programming. consider this program: code_removed does this program print out code_removed or code_removed? without knowing the order in which code_removed evaluates its arguments, we don\u2019t know. and in haskell, evaluation order isn\u2019t even always well-defined, so it\u2019s entirely possible that the order in which the two effects are executed is actually completely impossible to determine! this problem doesn\u2019t arise in strict languages with a well-defined evaluation order, but in a lazy language like haskell, we need some additional structure to ensure side-effects are (a) actually evaluated and (b) executed in the correct order. monads happen to be an interface that elegantly provide the necessary structure to enforce that order. why is that? and how is that even possible? well, the monadic interface provides a notion of data dependency in the signature for code_removed, which enforces a well-defined evaluation order. haskell\u2019s implementation of code_removed is \u201cmagic\u201d, in the sense that it\u2019s implemented in the runtime, but the choice of the monadic interface is far from arbitrary. it seems to be a fairly good way to encode the notion of sequential actions in a pure language, and it makes it possible for haskell to be lazy and referentially transparent without sacrificing predictable sequencing of effects. it\u2019s worth noting that monads are not the only way to encode side-effects in a pure way\u2014in fact, historically, they\u2019re not even the only way haskell handled side-effects. don\u2019t be misled into thinking that monads are only for i/o (they\u2019re not), only useful in a lazy language (they\u2019re plenty useful to maintain purity even in a strict language), only useful in a pure language (many things are useful monads that aren\u2019t just for enforcing purity), or that you needs monads to do i/o (you don\u2019t). they do seem to have worked out pretty well in haskell for those purposes, though. \u2020 regarding this, simon peyton jones once noted that \u201claziness keeps you honest\u201d with respect to purity.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["monadic", "monadic"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i think one thing one should ask is:if monads are the solution to x, and we add a different solution to x to the language, then what are monads for?let\u2019s say you have imperative io. then promises are a monad but then you could just add language support for async and promises are not really needed as a monad anymore.a more functional replacement for monads could be something like algebraic effects. these could replace monads completely or they could be like multi core ocaml and only give you one shot continuations (so not allowing for list or other multi-shot monads).in this context i like to think about the continuation monad. in haskell:code_removed this means \u201csome computation yielding a r which got paused part-done having just yielded an a. in some sense all monads are expressible in terms of cont. i feel like this is largely the essence of why it is useful to have monads: they express computations which happen with some context, able to switch back and forth between things in the context and things in the normal computation. i don\u2019t think sequencing evaluation is so important to the definition.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["largely"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there is an abundance of priority queue implementations to be found on hackage, just to complete your list: out of those i found that psqueue has an especially nice interface. i guess it was one of the first implementations and is nicely covered in this paper by ralf hinze. it might not be the most efficient and complete implementation but so far it has served all my needs. there is a very good article in the monadreader (issue 16) by louis wassermann (who also wrote the pqueue package). in his article louis gives a variety of different priority queue implementations and also includes algorithmic complexities for each. as a striking example of the simplicity of some priority queue internals he includes some cool little implementations. my favorite one (taken from his article): code_removed cool little implementation...a short usage example: code_removed some benchmarks of priority queue implementations can be found here and in a rather interesting thread on haskell.org here.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["especially nice"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "\"usedata.vector only if your usage pattern doesn't involve making many modifications, or if you need extremely high performance within the st/io monads..\" interesting wording, because if you are making many modifications (like repeatedly (100k times) evolving 100k elements ), then you do need st/io vector to get acceptable performance,", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["extremely high"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "did you check that this actually works? i see two potential problems: 1. not actually a problem necessarily, but it's way easier to reason about when things are evaluated with respect to io if you use code_removed rather than your code_removed, and 2. a more serious problem, code_removed will only evaluate up to the first constructor of val, so you'll only fetch one line; you really want something more substantial like a deepseq, or better still non-lazy io. admittedly i didn't check it /doesn't/ work, but i suspect it:)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["i", "see", "potential problem", "see two"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "to take this to its logical conclusion, see the unittyped package. it's really awesome about automatically managing units for you, but it has to use a bunch of extensions and the error messages are absurdly bad.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["automatically"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "what is the meaning of exceptions in haskell? the only usage i see is to put in code_removed or code_removed in my code to stop programs from running. otherwise i consider programming with exceptions as a logical design flaw. but haskell has an advanced exception module code_removed which is used by code_removed. i read that the reason for exceptions in c++ was to prevent a lot of \"call function, then check status\"-lines in code. but such things can be abstracted away in haskell. the only other reason i can see for exception handling in haskell is with ffi, to handle foreign exceptions, but only for internal use in a haskell function wrapping the call.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["logical"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "a few years ago, a pretty girl in our department decided to study computer science part-time. many people were surprised to discover one of the introductory courses was being taught using haskell as a/the programming language! although i didn't have experience with haskell, i had some background in lisp and other functional programming languages and was able to help her with her exercises. no, there's no happy end to this story: she dropped out, married somebody else and i haven't seen her in a long time. but i think the anecdote shows how knowledge can be useful when you least expect it. in more practical terms: you may have noticed that cpu speeds hit a wall some years ago, and now the most practical way to pull more performance from computers is by installing multiple cpus. now it so happens that most if not all of the programming languages you know are essentially single tasking, and subject to the von neumann bottleneck. an obvious solution is parallel programming, but that can be very painful if the parallel parts of your program end up sharing state, i.e. memory - and this is most often the case. it turns out that functional programming is a style that allows you to mostly circumvent the problems of parallel programming with shared state. stated differently, it's fairly easy to write programs in the fp style that are \"naturally\" thread safe and suitable for parallel processing. depending on the language, compiler and hardware you may even find (as i recently did) parts of your program running in parallel without ever having done any explicit coding for parallelism. i'm frequently wrong, but my guess is that functional programming will turn out to be one of the hot programming paradigms of the future as parallel programming becomes more important and more difficult. haskell may not turn out to be the language of choice - my personal favorite is currently clojure - but it may well be worthwhile to take a look at one or more fp languages.", "aspectos": {"AvailabilityAndScalability": ["subject"], "Maintainability": [], "Performance": ["more"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "could anyone give some pointers on why the unpure computations in haskell are modeled as monads? this question contains a widespread misunderstanding. impurity and monad are independent notions. impurity is not modeled by monad. rather, there are a few data types, such as code_removed, that represent imperative computation. and for some of those types, a tiny fraction of their interface corresponds to the interface pattern called \"monad\". moreover, there is no known pure/functional/denotative explanation of code_removed (and there is unlikely to be one, considering the \"sin bin\" purpose of code_removed), though there is the commonly told story about code_removed being the meaning of code_removed. that story cannot truthfully describe code_removed, because code_removed supports concurrency and nondeterminism. the story doesn't even work when for deterministic computations that allow mid-computation interaction with the world. for more explanation, see this answer. edit: on re-reading the question, i don't think my answer is quite on track. models of imperative computation do often turn out to be monads, just as the question said. the asker might not really assume that monadness in any way enables the modeling of imperative computation.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["mid-computation"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i have created a monster that i will now unleash on the world. here's an implementation of your transformation in idris. i started looking at this in haskell first, and the problem is that we are essentially looking for a way to collect, for each variable, a set of functions code_removed. coming up with a good representation for this in haskell is tricky because on one hand, we would like to hide the code_removed types behind an existential, but on the other hand, when we see a code_removed we need to construct a function which extracts the right coordinates from our code_removed at just the right type. so, first of all, let's make sure our variable references are well-scoped and well-typed, by indexing code_removed with the variables in scope and using de bruijn indexing for the variable occurrences: code_removed as can be seen, i've made two simplifications to code_removed: everything is always a list-like thing anyway, so e.g. code_removed's type is code_removed instead of code_removed. with just the combinators provided in the original question, the only values of code_removed one can build are lists anyway. this makes the implementation simpler (in other words, i was running into all kinds of unneeded complications before i made this change). code_removed is binary instead of n-ary. changing code_removed below to supprot n-ary concatenation is an exercise left for the reader. let's implement vertical fusion first, just to get our feet wet: code_removed so far so good: code_removed now for the fun part. we need a good representation of \"collection of functions from the same domain\" and a way to point at a particular function (with a particular codomain) in that collection. we will be collecting these functions from code_removed calls, keyed by code_removed; and then replace the call itself with a hole that will be filled in once we finished collecting everything. when we encounter code_removed, we will need to merge the functions collected from both sides, and then weaken the holes in code_removed and code_removed to be over this extended collection. i am using a binary tree instead of a flat list for this reason: so that the weakening is easy to implement. it goes in its own namespace since i am reusing the code_removed/code_removed terminology: code_removed now that we have a representation for the collection of all functions applied on a given variable, we can finally make some progress towards implementing horizontal fusion. to reiterate, the goal is to turn something like code_removed into something like code_removed so first of all, we need to be able to code-gen the memoizer (the definition of code_removed) from the collection of functions applied on code_removed: code_removed it won't be much use if we can't look up these memoized results later on: code_removed now, as we traverse the source tree, we of course collect usages (via code_removed) of several variables at the same time, since it is entirely possible to have something like code_removed this will be populated in lockstep with the variable context, since in every code_removed binding, we can also generate the memoizer of all the usages of the new variable. code_removed we will be reserving space for these synthetic variables: code_removed now we are finally ready to define our optimizer's internal intermediate representation: \"code_removed with holes\". each hole stands for an application of a function on a variable, which will be filled in when we know all the usages and we have all the synthetic variables for them in scope: code_removed so once we have such a holey code_removed, filling it in is just a matter of walking it and resolving the holes: code_removed horizontal fusion, then, is just a matter of elbow grease: turning a code_removed into a code_removed such that every code_removed is turned into an code_removed. we need to do some extra funny dance to shift holes around when combining two code_removed from the two sides of a code_removed. code_removed we can use this monstrosity by combining it with code_removed and feeding it to code_removed: code_removed and presto: code_removed addendum i wish i could have fused code_removed into code_removed, since i think all it should require is an extra case: code_removed however, this confused the idris termination checker unless i add an code_removed on code_removed vs code_removed which i don't understand why, since one has one more layer of code_removed constructors than the other.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["same"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "that runtime system is huge. i remember it was an obstacle to high-assurance in haskell. is there a detailed write-up on what those 80,000loc do? maybe someone could redo it in one of the verifying, imperative languages like spark or ats to increase its assurance without full verification.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["full"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}}, {"comentario": "that depends on what the meaning of \"is\" is\u2014or at least what the meaning of \"convention\" is. if a \"convention\" means \"the way things are usually done\" or \"an agreement among parties covering a particular matter\" then it is easy to give a boring answer: yes, the code_removed monad is a convention. it is the way the designers of the language agreed to handle io operations and the way that users of the language usually perform io operations. if we are allowed to choose a more interesting definition of \"convention\" then we can get a more interesting answer. if a \"convention\" is a discipline imposed on a language by its users in order to achieve a particular goal without assistance from the language itself, then the answer is no: the code_removed monad is the opposite of a convention. it is a discipline enforced by the language that assists its users in constructing and reasoning about programs. the purpose of the code_removed type is to create a clear distinction between the types of \"pure\" values and the types of values which require execution by the runtime system to generate a meaningful result. the haskell type system enforces this strict separation, preventing a user from (say) creating a value of type code_removed which launches the proverbial missiles. this is not a convention in the second sense: its entire goal is to move the discipline required to perform side effects in a safe and consistent way from the user and onto the language and its compiler. could you just ffi into libc.so instead to do io and skip the io monad thing? it is, of course, possible to do io without an io monad: see almost every other extant programming language. would it work anyway or is the outcome undeterministic because of haskell evaluating lazy or something else, like that the ghc is pattern matching for io monad and then handling it in a special way or something else. there is no such thing as a free lunch. if haskell allowed any value to require execution involving io then it would have to lose other things that we value. the most important of these is probably referential transparency: if code_removed could sometimes be code_removed and sometimes be code_removed depending on external factors then we would lose most of our ability to reason about our programs in a rigorous way (known as equational reasoning). laziness was mentioned in other answers, but the issue with laziness would specifically be that sharing would no longer be safe. if code_removed in code_removed was not referentially transparent, ghc would not be able to share the work and would have to compute it twice. what is the real reason? without the strict separation of effectful values from non-effectful values provided by code_removed and enforced by the compiler, haskell would effectively cease to be haskell. there are plenty of languages that don't enforce this discipline. it would be nice to have at least one around that does. in the end you end you endup in a sideeffect. so why not do it the simple way? yes, in the end your program is represented by a value called code_removed with an io type. but the question isn't where you end up, it's where you start: if you start by being able to differentiate between effectful and non-effectful values in a rigorous way then you gain a lot of advantages when constructing that program.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["probably referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@omar: perhaps \"isomorphic to a function\" would be a better phrase then. i was more or less getting at referential transparency.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "haskell doesn't \"need\" an io type\u2014it wants one. the io type gives us a language-level way to separate code that has side-effects from code that doesn't. it's a powerful tool to help manage complexity in our programs.one of the advantages of keeping io in an explicit io type is that code that isn't in io becomes easier to refactor. this is what people mean by referential transparency: since i know that a `char` cannot implicitly depend on the state of the rest of the program, i am always free to move it around, put it in a variable or replace it with an equivalent expression without changing the meaning of the program. you would not get this with getchar:: char because two getchars could give you different results, so moving them around or reordering them would change the semantics of your program.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "imo docker is a dead end, it essentially ended up being a glorified zip file, the real solution what docker was trying to do (reproducibility) is what nix does, and if nix is not a solution then something in that direction.in nix, you're basically describing the whole dependency tree of your application all the way to libc. when you build your application it builds everything necessary to run it.the great thing about it is that your cde essentially is identical to your build system, and the builds are fully reproducible, it takes over being a build system, package manager and as mentioned cde.they went even further with that (i have not explored that myself yet) and used the language to describe the entire system (called nixos) which looks like cms is no longer necessary and also nix is used for deployment (nixops, also did not tried it)if you are into containers you can still deploy into systemd lxc containers, or even create a minimalistic docker image.the disadvantage is that there is a significant learning curve, it's a new language, and it is a functional, lazily evaluated language. the language is not really that hard, but many people are not used to functional programming. it is especially popular for deployment of haskell code, since the language is also functional and lazily evaluated.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["still", "especially popular"], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}}, {"comentario": "@thomas: i must agree with user3125280 - the languages should be compared how they fare doing something smart instead of how they fail to beat a real programming language at doing something dumb. smart algorithms usually care less about microscopic efficiencies than about flexibility, the ability to wire things up (combine them) and infrastructure. the point is not so much whether one gets 20 ms or 50 ms, it is not getting 8 seconds or 8 minutes.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["microscopic"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "it's really asking from an abstraction layer with opaque capabilities... something like the mobile frameworks or haskell's mtl-style io.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["opaque"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "i find myself doing more and more scripting in haskell. but there are some cases where i'm really not sure of how to do it \"right\". e.g. copy a directory recursively (a la unix code_removed). since i mostly use linux and mac os i usually cheat: code_removed but what is the recommended way to copy a directory in a platform independent fashion? i didn't find anything suitable on hackage. this is my rather naiv implementation i use so far: code_removed any suggestions of what really is the way to do it? i updated this with the suggestions of hammar and fuzxxl....but still it feels kind of clumsy to me for such a common task!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["independent"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "so, coalgebras seem to fit as a better, first-class substitute of haskell modules, so that we can construct various coalgebras satisfying an interface (= a signature, or better -- a \"cosignature\"? since a \"signature\" is what an algebra has) and pass them as parameters to functions which depend the particular interface of a module that wish to use...", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["particular"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "an alternative to using code_removed is to use the lens package and its code_removed function and associated operators. the lens provides a uniform interface for accessing a wide variety of structures and nested structures above and beyond lists. below i will focus on providing examples and will gloss over both the type signatures and the theory behind the lens package. if you want to know more about the theory a good place to start is the readme file at the github repo. accessing lists and other datatypes getting access to the lens package at the command line: code_removed accessing lists to access a list with the infix operator code_removed unlike the code_removed this will not throw an exception when accessing an element out of bounds and will return code_removed instead. it is often recommend to avoid partial functions like code_removed or code_removed since they have more corner cases and are more likely to cause a run time error. you can read a little more about why to avoid partial functions at this wiki page. code_removed you can force the lens technique to be a partial function and throw an exception when out of bounds by using the code_removed operator instead of the code_removed operator. code_removed working with types other than lists this is not just limited to lists however. for example the same technique works on trees from the standard containers package. code_removed we can now access the elements of the tree in depth-first order: code_removed we can also access sequences from the containers package: code_removed we can access the standard int indexed arrays from the vector package, text from the standard text package, bytestrings fro the standard bytestring package, and many other standard data structures. this standard method of access can be extended to your personal data structures by making them an instance of the typeclass taversable, see a longer list of example traversables in the lens documentation.. nested structures digging down into nested structures is simple with the lens hackage. for example accessing an element in a list of lists: code_removed this composition works even when the nested data structures are of different types. so for example if i had a list of trees: code_removed you can nest arbitrarily deeply with arbitrary types as long as they meet the code_removed requirement. so accessing a list of trees of sequences of text is no sweat. changing the nth element a common operation in many languages is to assign to an indexed position in an array. in python you might: code_removed the lens package gives this functionality with the code_removed operator. though unlike in python the original list is not mutated, rather a new list is returned. code_removed code_removed is just a function and the code_removed operator, part of the lens package, is just reverse function application. here it is with the more common function application. code_removed assignment again works perfectly fine with arbitrary nesting of code_removeds. code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["uniform"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "+1 for backing up from code_removed to code_removed, code_removed, and code_removed, and i'd recommend in the reverse order (starting with code_removed). then revisit monad and check out code_removed. i bet you'll end up understanding code_removed better for putting it into a wider context. there's a lot of magical thinking attached to code_removed. it's just another type class, i.e., interface plus algebraic laws.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["algebraic"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "as my first programming language, i decided to learn haskell. i'm an analytic philosophy major, and haskell allowed me to quickly and correctly create programs of interest, for instance, transducers for natural language parsing, theorem provers, and interpreters. although i've only been programming for two and a half months, i found haskell's semantics and syntax much easier to learn than more traditional imperative languages, and feel comfortable (now) with the majority of its constructs. programming in haskell is like sorcery, however, and i would like to broaden my knowledge of programming. i would like to choose a new programming language to learn, but i do not have enough time to pick up an arbitrary language, drop it, and repeat. so i thought i would pose the question here, along with several stipulations about the type of language i am looking for. some are subjective, some are intended to ease the transition from haskell. strong type system. one of my favorite parts of programming in haskell is writing type declarations. this helps structure my thoughts about individual functions and their relationship to the program as a whole. it also makes informally reasoning about the correctness of my program easier. i'm concerned with correctness, not efficiency. emphasis on recursion rather than iteration. i use iterative constructs in haskell, but implement them recursively. however, it is much easier to understand the structure of a recursive function than a complicated iterative procedure, especially when using combinators and higher-order functions like maps, folds and bind. rewarding to learn. haskell is a rewarding language to work in. it's a little like reading kant. my experience several years ago with c, however, was not. i'm not looking for c. the language should enforce a conceptually interesting paradigm, which in my entirely subjective opinion, the c-likes do not. weighing the answers: these are just notes, of course. i'd just like to reply to everyone who gave well-formed responses. you have been very helpful. 1) several responses indicated that a strong, statically typed language emphasizing recursion means another functional language. while i want to continue working strongly with haskell, camccann and larsmans correctly pointed out that another such language would \"ease the transition too much.\" these comments have been very helpful, because i am not looking to write haskell in caml! of the proof assistants, coq and agda both look interesting. in particular, coq would provide a solid introduction to constructive logic and formal type theory. i've spent a little time with first-order predicate and modal logic (mendellsohn, enderton, some of hinman), so i would probably have a lot of fun with coq. 2) others heavily favored lisp (common lisp, scheme and clojure). from what i gather, both common lisp and scheme have excellent introductory material (on lisp and the reasoned schemer, sicp). the material in sicp causes me to lean towards scheme. in particular, scheme through sicp would cover a different evaluation strategy, the implementation of laziness, and a chance to focus on topics like continuations, interpreters, symbolic computation, and so on. finally, as others have pointed out, lisp's treatment of code/data would be entirely new. hence, i am leaning heavily towards option (2), a lisp. 3) third, prolog. prolog has a wealth of interesting material, and its primary domain is exactly the one i'm interested in. it has a simple syntax and is easy to read. i can't comment more at the moment, but after reading an overview of prolog and skimming some introductory material, it ranks with (2). and it seems like prolog's backtracking is always being hacked into haskell! 4) of the mainstream languages, python looks the most interesting. tim yates makes the languages sound very appealing. apparently, python is often taught to first-year cs majors; so it's either conceptually rich or easy to learn. i'd have to do more research. thank you all for your recommendations! it looks like a lisp (scheme, clojure), prolog, or a proof assistant like coq or agda are the main langauages being recommended.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["not"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["different", "primary"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "c++11, < 20ms for me - run it here i understand that you want tips to help improve your language specific knowledge, but since that has been well covered here, i thought i would add some context for people who may have looked at the mathematica comment on your question, etc, and wondered why this code was so much slower. this answer is mainly to provide context to hopefully help people evaluate the code in your question / other answers more easily. this code uses only a couple of (uglyish) optimisations, unrelated to the language used, based on: every traingle number is of the form n(n+1)/2 n and n+1 are coprime the number of divisors is a multiplicative function code_removed that takes around 19ms on average for my desktop and 80ms for my laptop, a far cry from most of the other code i've seen here. and there are, no doubt, many optimisations still available.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["many", "still available"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "a language that has recently come to my attention is eta. eta's compiler is a fork of ghc 7.10 which has a jvm backend. it is possible to use the generated jar files to write android apps and even use its foreign function interface to call native android java libraries. brian mckenna has written a blog post about how to configure an android studio project to use an eta library.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["foreign"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "as far as my experience goes, i don't know any such library. and if such a library exists, i'd advise against using it. unless you are using the lens package, i'd suggest not to use externally defined operators of that kind. (in case of that lens package, you really need and already have such an operator.) in my experience, imho and such... in cases where the readability enhances with a forward composition in contrast to the usual composition (not only when dealing with lenses), it is beneficial to define a special operator in that module or locally via code_removed or code_removed. for that, i tend to use single unicode symbols rather than ascii combos. code_removed some years ago(, when there were no lenses), i thought of defining my own module for these, too. but then i grow to use that module sooo infrequent that i tended to reinvent the wheel anyway. to have these operators in a library may even increase the effort of reading the code: the reader has to look those rarely used operators up. in that case, locally defined operators are way better.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["even"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@mysticial perhaps, but i'm thinking pure latency here. we can worry about power consumption when my $200 laptop stops lagging and people start writing actually efficient code.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["pure"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@evi1m4chine i mean anything you can do with an oo interface can be done with a typeclass, plus a hell of a lot more. so you kind of can just use them as a replacement for java interfaces 99% of the time and be very happy with the huge increase in power.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["huge", "very happy"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "many years after my first exposure to this book and having learned more heavy-fp in scala, i would not recommend this as a resource for learning either fp or haskell.but let that not be a pock on the overall great mission to make fp more accessible.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["first"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "note that this explanation cannot really apply to haskell's code_removed, because the latter supports interaction, concurrency, and nondeterminism. see my answer to this question for some more pointers.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["latter"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@pigworker: the irritating thing here is that the induction involved is clearly within ghc's capability to understand, but the usual approach of brazenly asserting an inductive step knowing that ghc will be able to figure things out at the call site fails because class constraints must be satisfied at the instance. in a way, this forces us to actually prove the inductive step itself, rather than treating it as advice to ghc on how to prove arbitrary specific cases on its own. should be possible, with enough hand-holding to walk ghc through it.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["clearly"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "note that many are in the hopl paper: 8.2.1 hierarchical module names; 8.1 the foreign function interface; 7.2 monads; 7.3 monadic i/o; 7.4 subsequent developments (stm, imprecise exceptions; etc). 6.7 gadts. type families i think might be the main truly new thing since the hopl paper came out.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["foreign"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "the haskell approach seems to be to just wrap imperative gui toolkits (such as gtk+ or wxwidgets) and to use \"do\" blocks to simulate an imperative style that's not really the \"haskell approach\" -- that's just how you bind to imperative gui toolkits most directly -- via an imperative interface. haskell just happens to have fairly prominent bindings. there are several moderately mature, or more experimental purely functional/declarative approaches to guis, mostly in haskell, and primarily using functional reactive programming. some examples are: reflex-platform, grapefruit, reactive, wxfruit, reactive-banana, for those of you not familiar with haskell, flapjax, is an implementation of functional reactive programming on top of javascript.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["imperative"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "you're broaching a very important subject in functional programming, that is, performing i/o. the way many pure languages go about it is by using embedded domain-specific languages, e.g., a sublanguage whose task it is to encode actions, which can have results. the haskell runtime for example expects me to define an action called code_removed that is composed of all actions that make up my program. the runtime then executes this action. most of the time, in doing so it executes pure code. from time to time the runtime will use the computed data to perform i/o and feeds back data back into pure code. you might complain that this sounds like cheating, and in a way it is: by defining actions and expecting the runtime to execute them, the programmer can do everything a normal program can do. but haskell's strong type system creates a strong barrier between pure and \"impure\" parts of the program: you cannot simply add, say, two seconds to the current cpu time, and print it, you have to define an action that results in the current cpu time, and pass the result on to another action that adds two seconds and prints the result. writing too much of a program is considered bad style though, because it makes it hard to infer which effects are caused, compared to haskell types that tell us everything we can know about what a value is. example: code_removed in c, vs. code_removed in haskell. the operator code_removed is used to compose actions, passing the result of the first to a function resulting in the second action. this looking quite arcane, haskell compilers support syntactic sugar that allows us to write the latter code as follows: code_removed the latter looks quite imperative, doesn't it?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["strong"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "code_removed is built on a tree data structure. basically, a new code_removed value is constructed, but it'll be filled almost entirely with pointers to the old structure. since values never change in haskell, this is a safe, and very important optimisation, known as sharing. this means that you can have many similar versions of the same data structure hanging around, but only the branches of the tree that differ will be stored anew; the rest will simply be pointers to the original copy of the branch. and, of course, if you throw away the old code_removed, the branches you did change will be reclaimed by the garbage collector. sharing is key to the performance of immutable data structures. you might find this wikipedia article helpful; it has some enlightening graphs showing how modified data gets represented with sharing.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["safe", "key"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "hey, i think we should add this book also by chris allen haskell programming from first principles. it is also a good book.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "for your second point, the term i've seen most often is spine-strict. for a spine-strict list, you could probably use code_removed (from containers) or code_removed (from vector). neither one is a list, however depending on what you're doing one (or both) are likely to be better. sequence provides o(1) cons and snoc, with very fast access to either end of the structure. vector's performance is similar to an array. if you want a more list-like interface to code_removed, you might consider the listlike package (there's a listlike interface for vectors too, but it's less useful because vector provides a fairly comprehensive interface on its own). both are spine-strict. for strict sets, you might try unordered-containers, which also provides a strict map.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["similar"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["more list-like", "listlike", "fairly comprehensive"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i did as well. i tried haskell on my own in the aughts before giving up. i had some fond exposure to ocaml and sml but never got into it until i heard the jane street talks, heard about mirageos, and decided to take the ocaml course in 2016.i've since gone back to haskell and am finally enjoying it... but i credit ocaml with getting me to a place where i could enjoy haskell the second time around.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["some fond"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i disagree with the vote to move; i am asking this question in the same spirit that i asked what's so bad about lazy i/o? and i expect to see answers of the same fashion. i am open to rewording the question if that would help.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["same"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> i think it's less that go has significantly different needs, but it's more that people overestimate what their actual needs are.i think you are right. and i doubt it hurts that sat solving is a fun problem!my main package management experience has been with haskell, which has used the cabal tool for many years. cabal was a traditional solver-based tool (with the added pain of a global mutable package database, although that is going away), and it frequently broke down in confusing ways. cabal hell was a widely used term. a few years ago, another tool arrived on the scene, stack, which used the same package format and such as cabal, but snapshotted the central package list (hackage) by gathering subsets of packages and versions that were guaranteed to work together (or at least do not have conflicting bounds). it works well[0], and although it does in principle result in a major loss in flexibility, it's rarely something i miss. importantly, the improvement in reliability was nothing short of astounding. that certainly helped convince me that flexibility may not be a needed feature for a (language) package manager.[0]: there are all sorts of socio-political stack/cabal conflicts in the haskell community now, but i'm not sure they are founded in technical issues.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["major"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "well, there's a lot to comment on here. i'll try to answer as much as i can. used correctly, it can get close-ish to low-level languages. in my experience, it's usually possible to get within 2x the performance of rust in many cases. but there are also some (broad) use cases where performance is poor compared to low-level languages. or even beat it, but that means you are using an inefficient c program, since ghc compiles haskell to c) that is not entirely correct. haskell compiles to c-- (a subset of c), which is then compiled via the native code generator to assembly. the native code generator usually generates faster code than the c compiler, because it can apply some optimizations that an ordinary c compiler can't. machine architectures are clearly imperative, being based on turing machines, roughly. that's not a good way to think about it, particularly since modern processors will evaluate instructions out of order and possibly at the same time. indeed, haskell doesn't even have a specific evaluation order. actually, haskell does implicitly define an evaluation order. also, instead of dealing with machine data types, you make algebraic data types all the time. they correspond in many cases, provided you have a sufficiently advanced compiler. you would think that creating functions on the fly, and throwing them around, would make a program slower. haskell is compiled, and so higher-order functions are not actually created on the fly. it seems to optimize haskell code, you need to make it more elegant and abstract, instead of more machine like. in general, making code more \"machine like\" is an unproductive way to get better performance in haskell. but making it more abstract is not always a good idea either. what is a good idea is using common data structures and functions that have been heavily optimized (such as linked lists). code_removed and code_removed are the exact same thing in haskell, for instance. a good compiler would not yield better performance in the former case. why is haskell (compiled with ghc) so fast, considering its abstract nature and differences from physical machines? the short answer is \"because it was designed to do exactly that.\" ghc uses the spineless tagless g-machine (stg). you can read a paper about it here (it's quite complex). ghc does a lot of other things as well, such as strictness analysis and optimistic evaluation. the reason i say c and other imperative languages are somewhat similar to turing machines (but not to the extent that haskell is similar to lambda calculus) is that in an imperative language, you have a finite number of states (a.k.a. line number), along with a tape (the ram), such that the state and the current tape determine what to do to the tape. is the point of confusion then that mutability should lead to slower code? haskell's laziness actually means that mutability doesn't matter as much as you think it would, plus it's high-level so there are many optimizations the compiler can apply. thus, modifying a record in-place will rarely be slower than it would in a language such as c.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["where poor", "good", "good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "your question conflates two related measures of a computer language: functional/imperative and pure/impure. a functional language defines relationships between inputs and outputs of functions, and an imperative language describes specific operations in a specific order to perform. a pure language does not create or depend on side effects, and an impure language uses them throughout. one-hundred percent pure programs are basically useless. they may perform an interesting calculation, but because they cannot have side effects they have no input or output so you would never know what they calculated. to be useful at all, a program has to be at least a smidge impure. one way to make a pure program useful is to put it inside a thin impure wrapper. like this untested haskell program: code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["related"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "yesod also has an as-yet-unreleased interface to mongodb for persistent.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["as-yet-unreleased"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "above there are very good detailed answers with theoretical background. but i want to give my view on io monad. i am not experienced haskell programmer, so may be it is quite naive or even wrong. but i helped me to deal with io monad to some extent (note, that it do not relates to other monads). first i want to say, that example with \"real world\" is not too clear for me as we cannot access its (real world) previous states. may be it do not relates to monad computations at all but it is desired in the sense of referential transparency, which is generally presents in haskell code. so we want our language (haskell) to be pure. but we need input/output operations as without them our program cannot be useful. and those operations cannot be pure by their nature. so the only way to deal with this we have to separate impure operations from the rest of code. here monad comes. actually, i am not sure, that there cannot exist other construct with similar needed properties, but the point is that monad have these properties, so it can be used (and it is used successfully). the main property is that we cannot escape from it. monad interface do not have operations to get rid of the monad around our value. other (not io) monads provide such operations and allow pattern matching (e.g. maybe), but those operations are not in monad interface. another required property is ability to chain operations. if we think about what we need in terms of type system, we come to the fact that we need type with constructor, which can be wrapped around any vale. constructor must be private, as we prohibit escaping from it(i.e. pattern matching). but we need function to put value into this constructor (here return comes to mind). and we need the way to chain operations. if we think about it for some time, we will come to the fact, that chaining operation must have type as >>= has. so, we come to something very similar to monad. i think, if we now analyze possible contradictory situations with this construct, we will come to monad axioms. note, that developed construct do not have anything in common with impurity. it only have properties, which we wished to have to be able to deal with impure operations, namely, no-escaping, chaining, and a way to get in. now some set of impure operations is predefined by the language within this selected monad io. we can combine those operations to create new unpure operations. and all those operations will have to have io in their type. note however, that presence of io in type of some function do not make this function impure. but as i understand, it is bad idea to write pure functions with io in their type, as it was initially our idea to separate pure and impure functions. finally, i want to say, that monad do not turn impure operations into pure ones. it only allows to separate them effectively. (i repeat, that it is only my understanding)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": ["not"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "snap has pretty good momentum. first of all, it was the most downloaded web framework on hackage last year even though the project didn't launch publicly until may. second, since the 0.3 release in december, we've seen a big increase in activity. libraries for sessions, auth, mongodb, the xmlhtml library, and more are all being worked on by people who are for the most part new contributors in 2011. you can also usually find 30 or more people in the #snapframework irc channel. it is definitely an active project.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["big"], "Reliability": [], "Deployability": [], "Securability": ["session", ","], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}}, {"comentario": "this answer is in response to the issues brought up by illissius, point by point: it's ugly to use. $(foobar ''asdf) just does not look nice. superficial, sure, but it contributes. i agree. i feel like $( ) was chosen to look like it was part of the language - using the familiar symbol pallet of haskell. however, that's exactly what you /don't/ want in the symbols used for your macro splicing. they definitely blend in too much, and this cosmetic aspect is quite important. i like the look of {{ }} for splices, because they are quite visually distinct. it's even uglier to write. quoting works sometimes, but a lot of the time you have to do manual ast grafting and plumbing. the [api][1] is big and unwieldy, there's always a lot of cases you don't care about but still need to dispatch, and the cases you do care about tend to be present in multiple similar but not identical forms (data vs. newtype, record-style vs. normal constructors, and so on). it's boring and repetitive to write and complicated enough to not be mechanical. the [reform proposal][2] addresses some of this (making quotes more widely applicable). i also agree with this, however, as some of the comments in \"new directions for th\" observe, the lack of good out-of-the-box ast quoting is not a critical flaw. in this wip package, i seek to address these problems in library form: so far i allow splicing in a few more places than usual and can pattern match on asts. the stage restriction is hell. not being able to splice functions defined in the same module is the smaller part of it: the other consequence is that if you have a top-level splice, everything after it in the module will be out of scope to anything before it. other languages with this property (c, c++) make it workable by allowing you to forward declare things, but haskell doesn't. if you need cyclic references between spliced declarations or their dependencies and dependents, you're usually just screwed. i've run into the issue of cyclic th definitions being impossible before... it's quite annoying. there is a solution, but it's ugly - wrap the things involved in the cyclic dependency in a th expression that combines all of the generated declarations. one of these declarations generators could just be a quasi-quoter that accepts haskell code. it's unprincipled. what i mean by this is that most of the time when you express an abstraction, there is some kind of principle or concept behind that abstraction. for many abstractions, the principle behind them can be expressed in their types. when you define a type class, you can often formulate laws which instances should obey and clients can assume. if you use ghc's [new generics feature][3] to abstract the form of an instance declaration over any datatype (within bounds), you get to say \"for sum types, it works like this, for product types, it works like that\". but template haskell is just dumb macros. it's not abstraction at the level of ideas, but abstraction at the level of asts, which is better, but only modestly, than abstraction at the level of plain text. it's only unprincipled if you do unprincipled things with it. the only difference is that with the compiler implemented mechanisms for abstraction, you have more confidence that the abstraction isn't leaky. perhaps democratizing language design does sound a bit scary! creators of th libraries need to document well and clearly define the meaning and results of the tools they provide. a good example of principled th is the derive package: - it uses a dsl such that the example of many of the derivations /specifies/ the actual derivation. it ties you to ghc. in theory another compiler could implement it, but in practice i doubt this will ever happen. (this is in contrast to various type system extensions which, though they might only be implemented by ghc at the moment, i could easily imagine being adopted by other compilers down the road and eventually standardized.) that's a pretty good point - the th api is pretty big and clunky. re-implementing it seems like it could be tough. however, there are only really only a few ways to slice the problem of representing haskell asts. i imagine that copying the th adts, and writing a converter to the internal ast representation would get you a good deal of the way there. this would be equivalent to the (not insignificant) effort of creating haskell-src-meta. it could also be simply re-implemented by pretty printing the th ast and using the compiler's internal parser. while i could be wrong, i don't see th as being that complicated of a compiler extension, from an implementation perspective. this is actually one of the benefits of \"keeping it simple\" and not having the fundamental layer be some theoretically appealing, statically verifiable templating system. the api isn't stable. when new language features are added to ghc and the template-haskell package is updated to support them, this often involves backwards-incompatible changes to the th datatypes. if you want your th code to be compatible with more than just one version of ghc you need to be very careful and possibly use code_removed. this is also a good point, but somewhat dramaticized. while there have been api additions lately, they haven't been extensively breakage inducing. also, i think that with the superior ast quoting i mentioned earlier, the api that actually needs to be used can be very substantially reduced. if no construction / matching needs distinct functions, and are instead expressed as literals, then most of the api disappears. moreover, the code you write would port more easily to ast representations for languages similar to haskell. in summary, i think that th is a powerful, semi-neglected tool. less hate could lead to a more lively eco-system of libraries, encouraging the implementation of more language feature prototypes. it's been observed that th is an overpowered tool, that can let you /do/ almost anything. anarchy! well, it's my opinion that this power can allow you to overcome most of its limitations, and construct systems capable of quite principled meta-programming approaches. it's worth the usage of ugly hacks to simulate the \"proper\" implementation, as this way the design of the \"proper\" implementation will gradually become clear. in my personal ideal version of nirvana, much of the language would actually move out of the compiler, into libraries of these variety. the fact that the features are implemented as libraries does not heavily influence their ability to faithfully abstract. what's the typical haskell answer to boilerplate code? abstraction. what're our favorite abstractions? functions and typeclasses! typeclasses let us define a set of methods, that can then be used in all manner of functions generic on that class. however, other than this, the only way classes help avoid boilerplate is by offering \"default definitions\". now here is an example of an unprincipled feature! minimal binding sets are not declarable / compiler checkable. this could lead to inadvertent definitions that yield bottom due to mutual recursion. despite the great convenience and power this would yield, you cannot specify superclass defaults, due to orphan instances these would let us fix the numeric hierarchy gracefully! going after th-like capabilities for method defaults led to while this is cool stuff, my only experience debugging code using these generics was nigh-impossible, due to the size of the type induced for and adt as complicated as an ast. in other words, this went after the features provided by th, but it had to lift an entire domain of the language, the construction language, into a type system representation. while i can see it working well for your common problem, for complex ones, it seems prone to yielding a pile of symbols far more terrifying than th hackery. th gives you value-level compile-time computation of the output code, whereas generics forces you to lift the pattern matching / recursion part of the code into the type system. while this does restrict the user in a few fairly useful ways, i don't think the complexity is worth it. i think that the rejection of th and lisp-like metaprogramming led to the preference towards things like method-defaults instead of more flexible, macro-expansion like declarations of instances. the discipline of avoiding things that could lead to unforseen results is wise, however, we should not ignore that haskell's capable type system allows for more reliable metaprogramming than in many other environments (by checking the generated code).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["not", "critical"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["th-like", "entire"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "essentially, it's about doing io in a functional style, correctly and efficiently. that's all, really. correct and efficient are easy enough using quasi-imperative style with strict io. functional style is easy with lazy io, but it's technically cheating (using code_removed under the hood) and can have issues with resource management and efficiency. in very, very general terms, a lot of pure functional code follows a pattern of taking some data, recursively expanding it into smaller pieces, transforming the pieces in some fashion, then recombining it into a final result. the structure may be implicit (in the call graph of the program) or an explicit data structure being traversed. but this falls apart when io is involved. say your initial data is a file handle, the \"recursively expand\" step is reading a line from it, and you can't read the entire file into memory at once. this forces the entire read-transform-recombine process to be done for each line before reading the next one, so instead of the clean \"unfold, map, fold\" structure they get mashed together into explicitly recursive monadic functions using strict io. iteratees provide an alternative structure to solve the same problem. the \"transform and recombine\" steps are extracted and, instead of being functions, are changed into a data structure representing the current state of the computation. the \"recursively expand\" step is given the responsibility of obtaining the data and feeding it to an (otherwise passive) iteratee. what benefits does this offer? among other things: because an iteratee is a passive object that performs single steps of a computation, they can be easily composed in different ways--for instance, interleaving two iteratees instead of running them sequentially. the interface between iteratees and enumerators is pure, just a stream of values being processed, so a pure function can be freely spliced in between them. data sources and computations are oblivious to each other's internal workings, decoupling input and resource management from processing and output. the end result is that a program can have a high-level structure much closer to what a pure functional version would look like, with many of the same benefits to compositionality, while simultaneously having efficiency comparable to the more imperative, strict io version. as for being \"worth the complexity\"? well, that's the thing--they're really not that complex, just a bit new and unfamiliar. the idea's been floating around for only, what, a couple years? give it some time for things to shake out as people use iteratee-based io in larger projects (e.g., with things like snap), and for more examples/tutorials to appear. it's likely that, in hindsight, the current implementations will seem very rough around the edges. somewhat related: you may want to read this discussion about functional-style io. iteratees aren't mentioned all that much, but the central issue is very similar. in particular this solution, which is both very elegant and goes even further than iteratees in abstracting incremental io.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["comparable"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["pure"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "@pigworker i hope you didn't take my comment as implying that \"proofs everywhere\" was a necessity, but it is certainly the case that today we have more programmer annotation than is \"fun\" for newcomers; as you say, this will change.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["everywhere"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this answer is in response to the issues brought up by illissius, point by point: it's ugly to use. $(foobar ''asdf) just does not look nice. superficial, sure, but it contributes. i agree. i feel like $( ) was chosen to look like it was part of the language - using the familiar symbol pallet of haskell. however, that's exactly what you /don't/ want in the symbols used for your macro splicing. they definitely blend in too much, and this cosmetic aspect is quite important. i like the look of {{ }} for splices, because they are quite visually distinct. it's even uglier to write. quoting works sometimes, but a lot of the time you have to do manual ast grafting and plumbing. the [api][1] is big and unwieldy, there's always a lot of cases you don't care about but still need to dispatch, and the cases you do care about tend to be present in multiple similar but not identical forms (data vs. newtype, record-style vs. normal constructors, and so on). it's boring and repetitive to write and complicated enough to not be mechanical. the [reform proposal][2] addresses some of this (making quotes more widely applicable). i also agree with this, however, as some of the comments in \"new directions for th\" observe, the lack of good out-of-the-box ast quoting is not a critical flaw. in this wip package, i seek to address these problems in library form: so far i allow splicing in a few more places than usual and can pattern match on asts. the stage restriction is hell. not being able to splice functions defined in the same module is the smaller part of it: the other consequence is that if you have a top-level splice, everything after it in the module will be out of scope to anything before it. other languages with this property (c, c++) make it workable by allowing you to forward declare things, but haskell doesn't. if you need cyclic references between spliced declarations or their dependencies and dependents, you're usually just screwed. i've run into the issue of cyclic th definitions being impossible before... it's quite annoying. there is a solution, but it's ugly - wrap the things involved in the cyclic dependency in a th expression that combines all of the generated declarations. one of these declarations generators could just be a quasi-quoter that accepts haskell code. it's unprincipled. what i mean by this is that most of the time when you express an abstraction, there is some kind of principle or concept behind that abstraction. for many abstractions, the principle behind them can be expressed in their types. when you define a type class, you can often formulate laws which instances should obey and clients can assume. if you use ghc's [new generics feature][3] to abstract the form of an instance declaration over any datatype (within bounds), you get to say \"for sum types, it works like this, for product types, it works like that\". but template haskell is just dumb macros. it's not abstraction at the level of ideas, but abstraction at the level of asts, which is better, but only modestly, than abstraction at the level of plain text. it's only unprincipled if you do unprincipled things with it. the only difference is that with the compiler implemented mechanisms for abstraction, you have more confidence that the abstraction isn't leaky. perhaps democratizing language design does sound a bit scary! creators of th libraries need to document well and clearly define the meaning and results of the tools they provide. a good example of principled th is the derive package: - it uses a dsl such that the example of many of the derivations /specifies/ the actual derivation. it ties you to ghc. in theory another compiler could implement it, but in practice i doubt this will ever happen. (this is in contrast to various type system extensions which, though they might only be implemented by ghc at the moment, i could easily imagine being adopted by other compilers down the road and eventually standardized.) that's a pretty good point - the th api is pretty big and clunky. re-implementing it seems like it could be tough. however, there are only really only a few ways to slice the problem of representing haskell asts. i imagine that copying the th adts, and writing a converter to the internal ast representation would get you a good deal of the way there. this would be equivalent to the (not insignificant) effort of creating haskell-src-meta. it could also be simply re-implemented by pretty printing the th ast and using the compiler's internal parser. while i could be wrong, i don't see th as being that complicated of a compiler extension, from an implementation perspective. this is actually one of the benefits of \"keeping it simple\" and not having the fundamental layer be some theoretically appealing, statically verifiable templating system. the api isn't stable. when new language features are added to ghc and the template-haskell package is updated to support them, this often involves backwards-incompatible changes to the th datatypes. if you want your th code to be compatible with more than just one version of ghc you need to be very careful and possibly use code_removed. this is also a good point, but somewhat dramaticized. while there have been api additions lately, they haven't been extensively breakage inducing. also, i think that with the superior ast quoting i mentioned earlier, the api that actually needs to be used can be very substantially reduced. if no construction / matching needs distinct functions, and are instead expressed as literals, then most of the api disappears. moreover, the code you write would port more easily to ast representations for languages similar to haskell. in summary, i think that th is a powerful, semi-neglected tool. less hate could lead to a more lively eco-system of libraries, encouraging the implementation of more language feature prototypes. it's been observed that th is an overpowered tool, that can let you /do/ almost anything. anarchy! well, it's my opinion that this power can allow you to overcome most of its limitations, and construct systems capable of quite principled meta-programming approaches. it's worth the usage of ugly hacks to simulate the \"proper\" implementation, as this way the design of the \"proper\" implementation will gradually become clear. in my personal ideal version of nirvana, much of the language would actually move out of the compiler, into libraries of these variety. the fact that the features are implemented as libraries does not heavily influence their ability to faithfully abstract. what's the typical haskell answer to boilerplate code? abstraction. what're our favorite abstractions? functions and typeclasses! typeclasses let us define a set of methods, that can then be used in all manner of functions generic on that class. however, other than this, the only way classes help avoid boilerplate is by offering \"default definitions\". now here is an example of an unprincipled feature! minimal binding sets are not declarable / compiler checkable. this could lead to inadvertent definitions that yield bottom due to mutual recursion. despite the great convenience and power this would yield, you cannot specify superclass defaults, due to orphan instances these would let us fix the numeric hierarchy gracefully! going after th-like capabilities for method defaults led to while this is cool stuff, my only experience debugging code using these generics was nigh-impossible, due to the size of the type induced for and adt as complicated as an ast. in other words, this went after the features provided by th, but it had to lift an entire domain of the language, the construction language, into a type system representation. while i can see it working well for your common problem, for complex ones, it seems prone to yielding a pile of symbols far more terrifying than th hackery. th gives you value-level compile-time computation of the output code, whereas generics forces you to lift the pattern matching / recursion part of the code into the type system. while this does restrict the user in a few fairly useful ways, i don't think the complexity is worth it. i think that the rejection of th and lisp-like metaprogramming led to the preference towards things like method-defaults instead of more flexible, macro-expansion like declarations of instances. the discipline of avoiding things that could lead to unforseen results is wise, however, we should not ignore that haskell's capable type system allows for more reliable metaprogramming than in many other environments (by checking the generated code).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["not", "critical"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["th-like", "entire"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "learning elm really helped me learn haskell which is something i'm continuing to do, but elm helped a lot. so i can see why a haskell shop would want to use elm for their frontend work. this makes total sense.that said, my initial enthusiasm for using elm, aside from a gateway-drug to haskell, has waned. i just do not have enough confidence in adopting elm for our internal project nor to recommend it to other companies.the last release of elm was 1 year and 8 months ago. the new release is purported to break many things. however, this new release is unknown, it's really unknown when it's going to be released and aside from a few insiders and contributors no one else seem to know what to expect.elm applies some interesting principles (type safety, purity, etc.) that helps to reason about your code. but, it's direction is driven by one person. that in itself is not bad, however, there is very little communication coming out of him (the last blog update by him was 1.5 years ago). because of that, i started looking at reason and what fb and others are doing.i think it makes no sense to invest months or years into something like elm at this point and any advantages elm might have had initially, is coming to parity with other solutions.i still think if you want to get your hands dirty with functional programming, play around with elm. the pragmatic studio elm lesson is great starting point. but look elsewhere for any serious projects.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["interesting"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["very little"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "question 1: do erlang, python and haskell loose speed due to using arbitrary length integers or don't they as long as the values are less than maxint? this is unlikely. i cannot say much about erlang and haskell (well, maybe a bit about haskell below) but i can point a lot of other bottlenecks in python. every time the program tries to execute an operation with some values in python, it should verify whether the values are from the proper type, and it costs a bit of time. your code_removed function just allocates a list with code_removed various times, and runtime, code_removed-styled memory allocation is way slower than iterating on a range with a counter as you do in c. notably, the code_removed is called multiple times and so allocates a lot of lists. also, let us not forget that python is interpreted and the cpython interpreter has no great focus on being optimized. edit: oh, well, i note that you are using python 3 so code_removed does not return a list, but a generator. in this case, my point about allocating lists is half-wrong: the function just allocates code_removed objects, which are inefficient nonetheless but not as inefficient as allocating a list with a lot of items. question 2: why is haskell so slow? is there a compiler flag that turns off the brakes or is it my implementation? (the latter is quite probable as haskell is a book with seven seals to me.) are you using hugs? hugs is a considerably slow interpreter. if you are using it, maybe you can get a better time with ghc - but i am only cogitating hypotesis, the kind of stuff a good haskell compiler does under the hood is pretty fascinating and way beyond my comprehension:) question 3: can you offer me some hints how to optimize these implementations without changing the way i determine the factors? optimization in any way: nicer, faster, more \"native\" to the language. i'd say you are playing an unfunny game. the best part of knowing various languages is to use them the most different way possible:) but i digress, i just do not have any recommendation for this point. sorry, i hope someone can help you in this case:) question 4: do my functional implementations permit lco and hence avoid adding unnecessary frames onto the call stack? as far as i remember, you just need to make sure that your recursive call is the last command before returning a value. in other words, a function like the one below could use such optimization: code_removed however, you would not have such optimization if your function were such as the one below, because there is an operation (multiplication) after the recursive call: code_removed i separated the operations in some local variables for make it clear which operations are executed. however, the most usual is to see these functions as below, but they are equivalent for the point i am making: code_removed note that it is up to the compiler/interpreter to decide if it will make tail recursion. for example, the python interpreter does not do it if i remember well (i used python in my example only because of its fluent syntax). anyway, if you find strange stuff such as factorial functions with two parameters (and one of the parameters has names such as code_removed, code_removed etc.) now you know why people do it:)", "aspectos": {"AvailabilityAndScalability": ["other"], "Maintainability": [], "Performance": ["loose"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "thomas, actually the original code that runs isn't polymorphic, even when compiled without optimisations (with ghc-7.*; it is polymorphic without optimisations with 6.12.3 - with optimisations, it's monomorphic for all of them). it's using code_removed (except for code_removed, which is code_removed by code_removed) without type signatures, since nothing except code_removed is exported. if you force polymorphic code, that's a good deal slower than code_removed (about 2\u00d7 for me).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["polymorphic", "monomorphic"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "going through the tutorial paper a tutorial on (co)algebras and (co)induction should give you some insight about co-algebra in computer science. below is a citation of it to convince you, in general terms, a program in some programming language manipulates data. during the development of computer science over the past few decades it became clear that an abstract description of these data is desirable, for example to ensure that one's program does not depend on the particular representation of the data on which it operates. also, such abstractness facilitates correctness proofs. this desire led to the use of algebraic methods in computer science, in a branch called algebraic specification or abstract data type theory. the object of study are data types in themselves, using notions of techniques which are familiar from algebra. the data types used by computer scientists are often generated from a given collection of (constructor) operations,and it is for this reason that \"initiality\" of algebras plays such an important role. standard algebraic techniques have proved useful in capturing various essential aspects of data structures used in computer science. but it turned out to be difficult to algebraically describe some of the inherently dynamical structures occurring in computing. such structures usually involve a notion of state, which can be transformed in various ways. formal approaches to such state-based dynamical systems generally make use of automata or transition systems, as classical early references. during the last decade the insight gradually grew that such state-based systems should not be described as algebras, but as so-called co-algebras. these are the formal dual of algebras, in a way which will be made precise in this tutorial. the dual property of \"initiality\" for algebras, namely finality turned out to be crucial for such co-algebras. and the logical reasoning principle that is needed for such final co-algebras is not induction but co-induction. prelude, about category theory. category theory should be rename theory of functors. as categories are what one must define in order to define functors. (moreover, functors are what one must define in order to define natural transformations.) what's a functor? it's a transformation from one set to another which preserving their structure. (for more detail there is a lot of good description on the net). what's is an f-algebra? it's the algebra of functor. it's just the study of the universal propriety of functor. how can it be link to computer science? program can be view as a structured set of information. program's execution correspond to modification of this structured set of information. it sound good that execution should preserve the program structure. then execution can be view as the application of a functor over this set of information. (the one defining the program). why f-co-algebra? program are dual by essence as they are describe by information and they act on it. then mainly the information which compose program and make them changed can be view in two way. data which can be define as the information being processed by the program. state which can be define as the information being shared by the program. then at this stage, i'd like to say that, f-algebra is the study of functorial transformation acting over data's universe (as been defined here). f-co-algebras is the study of functorial transformation acting on state's universe (as been defined here). during the life of a program, data and state co-exist, and they complete each other. they are dual.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["logical", "dual"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "+1, perhaps it is good to point out that, since all data is immutable, protection of fields is, though possible, not nearly as important as in oop languages with mutable data types.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["not important"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}}, {"comentario": "i'm trying to understand monads as well. it's my version: monads are about making abstractions about repetitive things. firstly, monad itself is a typed interface (like an abstract generic class), that has two functions: bind and return that have defined signatures. and then, we can create concrete monads based on that abstract monad, of course with specific implementations of bind and return. additionally, bind and return must fulfill a few invariants in order to make it possible to compose/chain concrete monads. why create the monad concept while we have interfaces, types, classes and other tools to create abstractions? because monads give more: they enforce rethinking problems in a way that enables to compose data without any boilerplate.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["firstly", "type"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "> as for vt-d, i believe the unlocked \"k\" processors from intel all have vt-d disabled for some reason.this was only the case up to haswell cpus. they stopped crippling iommu capabilities since haswell refresh (i7-4790k).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["crippling"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "there's a bigger reason than that: recap, one of the main haskell designers tried to come up with a type system for erlang but couldn't cover the inter-process communication, probably because a process which has another process' pid is allowed to send it literally any type of message.in elixir, you notice the dynamic typing mostly when you're defining callbacks that take mfa-style function specs, e.g. def handle_click(m, f, a)...last point, you are right about dialyzer error messages, but people are working on it right now. look for messages in this discussion from _asummers.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["inter-process"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "first of all, a disclaimer: i've never done any haskell web development, so i don't speak from experience. if you look at the web category on hackage, there are lots of web-related packages. i think most haskell web application run on a custom server (possibly using apache's code_removed or iis's advanced request routing as a front end). however, there are also some fastcgi bindings. the most prominent haskell webserver/framework/datastorage infrastruction is happstack, which is interesting for several reasons, the most obvious being that it stores all its state in-memory and doesn't use a relational database. another more recent webserver interface is hack, which i don't know much about except that the 1 minute tutorial looks interesting. there are many more webservers/frameworks in haskell, but these two are just the ones i know of the top of my head.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["more recent"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "hand-writing the loops is not always necessary, you can often use a fusion framework like code_removed's to achieve the same. which is easier and/or gives better performance depends on what you're used to (i rarely use code_removeds, i'm used to writing loops, so i usually find that easier, if you're used to using code_removeds, you'll find that easier), and the structure of the computation (you can always fiddle with hand-written loops to try to squeeze out more, but if you let the fusion framework write the loops, you're tied to what has been done before, but it's not easy to beat a good framework).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "it's not a very good explanation. \"floated out\" simply means that in: code_removed if code_removed does not mention x then it can be floated out of the lambda: code_removed which means it will only be computed once,1 which could save a lot of time if code_removed is expensive. however, ghc is conservative about performing optimisations like this, since they can introduce space leaks. (though it does do so for the second definition if you give it a type signature, as daniel fischer points out in his answer.) this isn't about automatic optimisation, though. the first snippet defines code_removed outside of the lambda, whereas the second defines it inside (the lambda is implicit in code_removed, which is equivalent to code_removed), which is what the quote is saying. even that's not really relevant, however; what's relevant is that in the first snippet, code_removed occurs outside the lambda, and so its result is shared among all applications of the lambda (in that code, the \"lambda\" arises from the partial application of code_removed). in the latter, it's inside the lambda, and so likely to be recomputed for every application of code_removed. the end result is that the former implementation caches the values and so is far more efficient than the latter. note that the first snippet's efficiency is dependent on the fact that code_removed doesn't recurse directly, but instead through code_removed, and therefore benefits from the memoisation. it's related to eta-expansion; the latter snippet is an eta-expansion of the first. but the statement you quoted doesn't explain what's going on at all. 1 note that this is implementation-specific behaviour, and not part of haskell's semantics. however, all reasonable implementations will behave in this manner.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["n't", "about automatic", "though", "dependent"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "first, i understand the how of iteratees, well enough that i could probably write a simplistic and buggy implementation without referring back to any existing ones. what i'd really like to know is why people seem to find them so fascinating, or under what circumstances their benefits justify their complexity. comparing them to lazy i/o there is a very clear benefit, but that seems an awful lot like a straw man to me. i never felt comfortable about lazy i/o in the first place, and i avoid it except for the occasional code_removed or code_removed, mostly in very simple programs. in real-world scenarios i generally use traditional i/o interfaces with control abstractions appropriate to the task. in that context i just don't see the benefit of iteratees, or to what task they are an appropriate control abstraction. most of the time they seem more like unnecessary complexity or even a counterproductive inversion of control. i've read a fair number of articles about them and sources that make use of them, but have not yet found a compelling example that actually made me think anything along the lines of \"oh, yea, i'd have used them there too.\" maybe i just haven't read the right ones. or perhaps there is a yet-to-be-devised interface, simpler than any i've yet seen, that would make them feel less like a swiss army chainsaw. am i just suffering from not-invented-here syndrome or is my unease well-founded? or is it perhaps something else entirely?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["traditional", "yet-to-be-devised", "simple"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "a few years ago, a pretty girl in our department decided to study computer science part-time. many people were surprised to discover one of the introductory courses was being taught using haskell as a/the programming language! although i didn't have experience with haskell, i had some background in lisp and other functional programming languages and was able to help her with her exercises. no, there's no happy end to this story: she dropped out, married somebody else and i haven't seen her in a long time. but i think the anecdote shows how knowledge can be useful when you least expect it. in more practical terms: you may have noticed that cpu speeds hit a wall some years ago, and now the most practical way to pull more performance from computers is by installing multiple cpus. now it so happens that most if not all of the programming languages you know are essentially single tasking, and subject to the von neumann bottleneck. an obvious solution is parallel programming, but that can be very painful if the parallel parts of your program end up sharing state, i.e. memory - and this is most often the case. it turns out that functional programming is a style that allows you to mostly circumvent the problems of parallel programming with shared state. stated differently, it's fairly easy to write programs in the fp style that are \"naturally\" thread safe and suitable for parallel processing. depending on the language, compiler and hardware you may even find (as i recently did) parts of your program running in parallel without ever having done any explicit coding for parallelism. i'm frequently wrong, but my guess is that functional programming will turn out to be one of the hot programming paradigms of the future as parallel programming becomes more important and more difficult. haskell may not turn out to be the language of choice - my personal favorite is currently clojure - but it may well be worthwhile to take a look at one or more fp languages.", "aspectos": {"AvailabilityAndScalability": ["subject"], "Maintainability": [], "Performance": ["more"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> julia may be more interesting (and it offers types!) plus much more focus om performance for iterative operations (which haskell is lacking). though, each time i tried it, i had to go back to python - again, due to maturity of its data science ecosystem.i definitely agree that the julia ecosystem is still maturing and not everything is as developed, however i've often found that the lack of maturity is less of an issue in julia because the flexability of the language through generics, parametric types and macros makes a lot of the infrastructure needed in python unessessary in julia. obviously your milage may vary in this regard though.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["much more"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> terrible book.definitely overstated and not good advice for beginners.my advice to beginners would be:- read all the haskell books available at your disposal. (in addition to lyah and the hutton book, i would say learning haskell from first principles and get programming with haskell are great, when you hit something that doesn't make sense in one source, try referencing it in another source.- when you have some experience writing programs in haskell, refer to some older books like real world haskell. there may be a few issues compiling the examples, but nearly all the techniques in the book are still widely used and you learn about the language has progressed in the last few years. this gives you a compass to read and maintain older haskell source code).- read as much haskell code as you can from popular libraries (pandoc, xmonad, and smaller libs as well).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this argument gets brought up a lot, but in my experience the benefits of fp usually stem much more from reducing complexity than from increasing performance, and that also applies to single-threaded programs.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["increase"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i don't quite get how messages and method calls interact. could the process intercept the method call by explicitly receiving or somehow influence the process module to do something else?channels are a great idea! what capabilities (send on channel/receive on channel) can you forward to other processes? as cloud haskell explain, in distributed systems we must not allow send on channel to be forwarded.regarding channels, both linear channels and mailbox types for unordered interactions are interesting ideas worth looking into.great project!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["unordered"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "as a german who worked as a software dev in the netherlands for 2 years, i could't disagree more. the dutch speak a great english, even the homeless. i've never heard a better american style english anywhere else in europe and i found the dutch english often more clean than even received pronounciation.same goes for the code bases, they had the usual mess that codebases have but variable names weren't an issue.i find your example of childs vs children to be bike shedding, the hard part about coding isn't the variable names. if you read haskell you would probably find \"c\" for child and \"cs\" for children, simply to keep the code terse.while i strongly condone the form of backlash you received, i am still happy that there is pushback.(sorry)we as software devs battle complexity on a daily basis, and we achieve many of the things we achieve only because of collaboration. introducing an additional translation step into the process of coding sounds like a complexity nightmare, a debugging nightmare and a communications nightmare.when working in an international team you still have to talk about the stuff, and as long as something like this doesn't ship with a perfect star trek like universal natlang translator people still have to settle on one language, except that the code they are looking at is now code they've never seen before.kudos for the effort, go do it as a hobby but don't be suprised that people get mad just by the very thought of being forced by management to work with something that puts even more complexity onto their shoulders.and i'm happy that people want collaboration so bad that they are willing to speak and work in a language that they don't understand well in order to connect with peers from all over the world.and don't take it personal that others don't digg the idea of having to work with something like this. it's a cool idea, it didn't work. move on and try the next cool idea, one day one of them will stick. you're not the only one to have worked on something and then figured out a year into the project that there is no demand/ its technically unfeasible / there is some obscure paper from the 70s that had the same idea but discovered a fundamental flaw and dropped it.to quote allan key:if you don't fail at least 90 percent of the time, you're not aiming high enough.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["fundamental"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> i think the best answer is \"the one you're interested in\" or maybe if you have a goal then use that?ding ding ding, this is the correct answer. something you have a vested interest in will always be infinitely easier to learn than some random thing someone else (who likely _is_ interested in it) suggests because they said it was easy.for example, while not exactly a \u201csuper simple\u201d topic, at work part of my responsibilities include maintaining/developing etl jobs for copying data from a few data warehouses to local app dbs. i absolutely dread anytime i have to spend any amount of time working on these, i find it boring, the software terrible, the problems tedious. and, i\u2019m certain if i spent a fair amount of time really learning the technologies/patterns/etc, it wouldn\u2019t be nearly as much of a chore. and, given i\u2019m not working with google level terabytes of data, only a few 100 or so gigs, the scope of what i\u2019d have to learn likely isn\u2019t terribly difficult. the problem is though, i have absolutely no interest in doing so, i only work on them because i inherited them, and if i were to need to do the same thing from scratch, i\u2019d likely try something other than \u201centerprise\u201d etl frameworks, or more realistically try my damndest to find someone that actually likes doing this kind of thing so then i don\u2019t have to worry about it.contrasted to about a little over a year ago, i got super interested in ci/cd and containerization technologies. i started having no experience with ci, docker, and really only having deployed things to heroku. however, i was fairly quickly able to get up to speed with the basics of the technologies, and then a short time after that i became the \u201cdocker & ci\u201d guy at work, i found that i was able to quickly and (hopefully) competently answer almost any question/issue coworkers were encountering. i now spend a fair amount of time configuring ci and containerizing older apps in our portfolio just because i thought it was fun/interesting to do, which provided me with even more opportunities to learn and find gaps in my knowledge. but, to some others, spending any amount of time configuring ci, fighting with a legacy codebase to get it\u2019s test suite to run in a containerized/ci environment, and building security scanning practices likely sounds absolutely dreadful, tedious, or a waste of time.so, whatever you have an actual interest in learning completely will be the easiest, whether that be machine learning, full blown functional programming in haskell, enterprise java oop, application architecture, compiler/language development, or even something as deceptively \u201csimple\u201d as building cli tooling. anything someone advertises to you as \u201ceasiest to learn\u201d is something that person themselves are interested in, which is why to them it was easy, but if you don\u2019t give a shit about it, it likely will be a chore and far from the \u201ceasiest\u201d.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["really", "only"], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}}, {"comentario": "full disclosure: i'm one of the lead developers of snap. first of all, let's talk about what snap is. right now the snap team maintains five different projects on hackage: snap-core, snap-server, heist, snap, and xmlhtml. snap-server is a web server that exposes the api defined by snap-core. heist is a templating system. xmlhtml is an xml/html parsing and rendering library used by heist. snap is an umbrella project that glues them all together and provides the powerful snaplets api that makes web apps composable and modular. yesod has a host of projects on hackage. most (all?) of them are listed in the yesod category. some of the notable ones are yesod-core, warp, persistent, and hamlet. the reality of haskell web development is that it's much less of an exclusive-or choice than seems to be perceived. in general the projects are very loosely coupled and fairly interchangeable. you could build a website using warp (the yesod team's web server), heist (the snap team's template system), and acid-state (the happstack project's persistence system). you could also use snap-server with hamlet or persistent. that said, the two projects definitely have some differences. the biggest difference i can point out objectively is that yesod projects typically make heavy use of template haskell and quasiquoting to create concise dsls, while snap projects stick to building combinator libraries that favor composability. just about any other differences i can think of will be subjectively biased towards snap. the umbrella packages named after both projects are obviously going to make specific choices for the above mentioned components, and these choices will be reflected in the project dependencies. but that still doesn't mean that you can't pull in something different and use it as well. snap does have sessions and authentication, interfaces to several databases, and nice form handling (here and here) using digestive-functors that includes prepackaged support for arbitrarily nested dynamically sizable lists. these are just some of the growing ecosystem of pluggable snaplets. the sessions and authentication snaplets are written in a way that is back-end agnostic. so with a small amount of glue code you should be able to use it with just about any persistence system you can think of. in the future, snap will stick with this policy as often as possible. for the most part i think the choice of snap vs yesod vs happstack is less an issue of features and more one of personal taste. whenever someone says that one of the frameworks doesn't have something that another one has, most of the time it will be pretty easy to pull in the missing functionality from the other framework by importing the necessary package. edit: for a more detailed comparison of the big three haskell web frameworks check out my recent blog post. for a rougher (but possibly more useful) comparison using some broader generalizations, see my haskell web framework comparison matrix", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["fairly"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "the operational perspective is valid but it doesn't help to answer the question, imo. if your answer to \"what is the problem?\" is \"the problem is our hard-to-predict evaluation strategy\", then the beginner's natural follow-up question is \"why not just use a normal evaluation strategy?\", and there's no good answer to that one (indeed many regard haskell's laziness as the wrong choice; in recent times we've seen post-haskell languages e.g. idris moving away from it, and the best-known industrial deployment of haskell uses a strict variant).meanwhile i find monads very useful in scala, even without any laziness in sight.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["best-known", "industrial"], "Securability": [], "Interoperability": ["hard-to-predict", "normal"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": -1}}, {"comentario": "@carl not just io, but it just happens that monads (already known to the math people) provides a way to address several of the \"hard parts\" of pure functional programming, and the state hard part pretty much solves everything else. so, one set of syntactic sugar gives a lot of benefits. it is, in essence, adding stateful things into haskell in a palletable manner.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["palletable"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "in the 2009-2012 period, the following things have happened: 2012: from 2012, the parallel haskell status updates began appearing in the parallel haskell digest. 2011: parallel and concurrent programming in haskell, a tutorial. version 1.1 released by simon marlow haskell and parallelism, mentioned in an article in the economist magazine, jun 2nd 2011. parallel tree scans via composition, an article by conal elliott numeric haskell, a tutorial on parallel array programming with repa, released works has begun on extending ghc eventlog and threadscope to support multi-process or distributed haskell systems parallel haskell digest: edition 2. the par-monad package and a monad for deterministic parallelism, simon marlow -- more control over pure parallelism than strategies/par/pseq. cloud haskell: erlang-style message passing between distributed haskell nodes. parallel haskell: embracing diversity, a talk by spj. real time edge detection in parallel haskell parallel haskell digest: news on parallel haskell composable parallel scanning haskell-mpi is released 2010: parallel futures for haskell, in ghc. the orc language, for concurrent job scheduling and scripting, was released. a new scalable thread event manager was merged into ghc. an improved approach to parallel sparks and strategies was developed. the nikola edsl for embedding gpu programs in haskell was developed. the llvm backend for ghc was merged in, with good performance improvements. ghc 6.12.x series: with parallel performance improvements microsoft announces 2 years of funding to support commercial users of parallel haskell google published their experience report on the use of haskell (pdf) intel announced the concurrent collections for haskell library, including scalability numbers -- scaling results for 32 and 48 cores sun/oracle bought us a machine and funded work on improving parallel performance. recent updates to the status of data parallelism in haskell msr released threadscope, a graphical profiler for parallel haskell programs the ghc runtime got extensively tuned for sparks and futures there was a good discussion on additional ways to improve parallel performance a collection of reading material on parallelism in haskell to help you get started the snap guys are getting 45k req/sec on their 4 way box, by using all the cores. even the erlang guys are taking notice. meanwhile, there is work to make the io manager more scalable -- now with a paper on the design:: pdf. we're out there teaching people too.. all.. over.. the... place. starling software wrote about their real time, multicore financial trading system in haskell. ericsson published a parallel language for dsp based on, and written in haskell galois published an implementation of orc, a concurrent workflow language, in haskell. and a new library for fast regular, parallel arrays appeared and haskell continues to do well on the quad-core shootout. snap, a multicore-enabled scalable web server with great performance numbers haskell-torrent - benchmarking a mulitcore-enabled bittorrent client in haskell haskell code was published at supercomputing 09 -- our first appearance at sc!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["parallel", "parallel"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there are at least 4 libraries that i am aware of providing lenses. the notion of a lens is that it provides something isomorphic to code_removed providing two functions: a getter, and a setter code_removed subject to three laws: first, that if you put something, you can get it back out code_removed second that getting and then setting doesn't change the answer code_removed and third, putting twice is the same as putting once, or rather, that the second put wins. code_removed note, that the type system isn't sufficient to check these laws for you, so you need to ensure them yourself no matter what lens implementation you use. many of these libraries also provide a bunch of extra combinators on top, and usually some form of template haskell machinery to automatically generate lenses for the fields of simple record types. with that in mind, we can turn to the different implementations: implementations fclabels fclabels is perhaps the most easily reasoned about of the lens libraries, because its code_removed can be directly translated to the above type. it provides a category instance for code_removed which is useful as it allows you to compose lenses. it also provides a lawless code_removed type which generalizes the notion of a lens used here, and some plumbing for dealing with isomorphisms. one hindrance to the adoption of code_removed is that the main package includes the template-haskell plumbing, so the package is not haskell 98, and it also requires the (fairly non-controversial) code_removed extension. data-accessor [edit: code_removed is no longer using this representation, but has moved to a form similar to that of code_removed. i'm keeping this commentary, though.] data-accessor is somewhat more popular than code_removed, in part because it is haskell 98. however, its choice of internal representation makes me throw up in my mouth a little bit. the type code_removed it uses to represent a lens is internally defined as code_removed consequently, in order to code_removed the value of a lens, you must submit an undefined value for the 'a' argument! this strikes me as an incredibly ugly and ad hoc implementation. that said, henning has included the template-haskell plumbing to automatically generate the accessors for you in a separate 'data-accessor-template' package. it has the benefit of a decently large set of packages that already employ it, being haskell 98, and providing the all-important code_removed instance, so if you don't pay attention to how the sausage is made, this package is actually pretty reasonable choice. lenses next, there is the lenses package, which observes that a lens can provide a state monad homomorphism between two state monads, by definining lenses directly as such monad homomorphisms. if it actually bothered to provide a type for its lenses, they would have a rank-2 type like: code_removed as a result, i rather don't like this approach, as it needlessly yanks you out of haskell 98 (if you want a type to provide to your lenses in the abstract) and deprives you of the code_removed instance for lenses, which would let you compose them with code_removed. the implementation also requires multi-parameter type classes. note, all of the other lens libraries mentioned here provide some combinator or can be used to provide this same state focalization effect, so nothing is gained by encoding your lens directly in this fashion. furthermore, the side-conditions stated at the start don't really have a nice expression in this form. as with 'fclabels' this does provide template-haskell method for automatically generating lenses for a record type directly in the main package. because of the lack of code_removed instance, the baroque encoding, and the requirement of template-haskell in the main package, this is my least favorite implementation. data-lens [edit: as of 1.8.0, these have moved from the comonad-transformers package to data-lens] my code_removed package provides lenses in terms of the store comonad. code_removed where code_removed expanded this is equivalent to code_removed you can view this as factoring out the common argument from the getter and the setter to return a pair consisting of the result of retrieving the element, and a setter to put a new value back in. this offers the computational benefit that the 'setter' here can recycle some of the work used to get the value out, making for a more efficient 'modify' operation than in the code_removed definition, especially when accessors are chained. there is also a nice theoretical justification for this representation, because the subset of 'lens' values that satisfy the 3 laws stated in the beginning of this response are precisely those lenses for which the wrapped function is a 'comonad coalgebra' for the store comonad. this transforms 3 hairy laws for a lens code_removed down to 2 nicely pointfree equivalents: code_removed this approach was first noted and described in russell o'connor's code_removed is to code_removed as code_removed is to code_removed: introducing multiplate and was blogged about based on a preprint by jeremy gibbons. it also includes a number of combinators for working with lenses strictly and some stock lenses for containers, such as code_removed. so the lenses in code_removed form a code_removed (unlike the code_removed package), are haskell 98 (unlike code_removed/code_removed), are sane (unlike the back end of code_removed) and provide a slightly more efficient implementation, code_removed provides the functionality for working with monadstate for those willing to step outside of haskell 98, and the template-haskell machinery is now available via code_removed. update 6/28/2012: other lens implementation strategies isomorphism lenses there are two other lens encodings worth considering. the first gives a nice theoretical way to view a lens as a way to break a structure into the value of the field, and 'everything else'. given a type for isomorphisms code_removed such that valid members satisfy code_removed, and code_removed we can represent a lens with: code_removed these are primarily useful as a way to think about the meaning of lenses, and we can use them as a reasoning tool to explain other lenses. van laarhoven lenses we can model lenses such that they can be composed with code_removed and code_removed, even without a code_removed instance by using code_removed as the type for our lenses. then defining a lens is as easy as: code_removed and you can validate for yourself that function composition is lens composition. i've recently written on how you can further generalize van laarhoven lenses to get lens families that can change the types of fields, just by generalizing this signature to code_removed this does have the unfortunate consequence that the best way to talk about lenses is to use rank 2 polymorphism, but you don't need to use that signature directly when defining lenses. the code_removed i defined above for code_removed is actually a code_removed. code_removed i've written a library that includes lenses, lens families, and other generalizations including getters, setters, folds and traversals. it is available on hackage as the code_removed package. again, a big advantage of this approach is that library maintainers can actually create lenses in this style in your libraries without incurring any lens library dependency whatsoever, by just supplying functions with type code_removed, for their particular types 'a' and 'b'. this greatly lowers the cost of adoption. since you don't need to actually use the package to define new lenses, it takes a lot of pressure off my earlier concerns about keeping the library haskell 98.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["other"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i would also like to stress some of the practical features of haskell, despite its mere beauty: gets in your way exactly where it should, and keeps out of your way otherwise. that's one of the interesting features, which is responsible for why haskell just works. has a great concurrency system, which is ready for high performance applications. provides the basis for new, innovative abstractions and design patterns, among them my personal favorite, functional reactive programming. makes even very complicated problems easy to tackle, because a lot of the things, which you need to think about in other languages (proper sequencing, locking, initialization, etc.), are much less of an issue in haskell. laziness is not simply an optimization. it allows you to solve problems in entirely new ways, which are much easier on the brain. no destructive updates, yet the same result with about the same performance. if you have the choice, i totally recommend learning haskell over any other language. it seems to make the optimal tradeoff between safety, level of abstractness and practicality among the existing languages.", "aspectos": {"AvailabilityAndScalability": ["optimal"], "Maintainability": [], "Performance": ["same"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "where they can be used, code_removed and code_removed give the best performance, so use them where possible and speed matters. strictness and laziness are important. where an argument needs to be evaluated anyway, make it strict, where you can start producing the result without, keep it lazy. ghc doesn't do many low-level optimisations yet, so be aware of bit-twiddling tricks to substitute other operations (division, primarily). avoid code_removed and code_removed where code_removed and code_removed will do the right thing. whether llvm beats the native code generator depends, but it's rare that the ncg is significantly faster.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["best", "many", "low-level"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "ok, i see your benchmarks, but whole branch prediction thing doesn't provide much performance. it introduces more problems than solving it. then why cpu manufactures even bothered integrating such thing in it?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["much"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "code_removed is a common solution: code_removed so, given a function with a domain the same as its range, code_removed, and an initial input code_removed, produce an infinite list of results in the form: code_removed and you can access the nth element of the list using code_removed: code_removed nb code_removed.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["same"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "yes! you are correct! now() or currenttime() or any method signature of such flavour is not exhibiting referential transparency in one way. but by instruction to the compiler it is parameterized by a system clock input. by output, now() might look like not following referential transparency. but actual behaviour of the system clock and the function on top of it is adheres to referential transparency.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential", "referential", "referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "welcome to stackoverflow, and congratulations for such a good start! reversing the list to access the far end is indeed a very haskellish solution (though it is rather inefficient, but using code_removed can be even worse if you need to do it multiple times... if performance is critical and you need to access a last element, then lists aren't a suitable type).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["critical"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "in haskell, the 'if (err) {... }' parts could be factored out into a new bind operator for a new monad stack. then, you don't have to write these checks every single time. the do notation is automatically converted into the corresponding monadic code, and the algebraic monad laws guarantee that the meaning of the code is preserved.for example, for the `if (err) {...}` cases, this is just the `exceptt` monad transformer.with regard to understandability, using error throwing code in haskell is really easy. implementing it is slightly more difficult, but so is implementing a c compiler. i mean, we shouldn't judge the utility of a thing based on whether the implementation of the thing could be understood by a child. by that measure, children would be incapable of using facebook, because they could not build it.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["incapable"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i've been looking for a decent guide to haskell for some time, but haven't been able to find one that seems interesting enough to read through and/or makes sense. i've had prior exposure to haskell a few years back, but i can't remember much about it. i remember the \"aha!\"-feeling was incredible when i finally got it, and it was actually fun to play with, so i'm looking to rediscover the lost art of haskell. i'm familiar with ruby and its functional programming tricks, so i think i'm not completely in the dark. any links?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["prior"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "monads are just a convenient framework for solving a class of recurring problems. first, monads must be functors (i.e. must support mapping without looking at the elements (or their type)), they must also bring a binding (or chaining) operation and a way to create a monadic value from an element type (code_removed). finally, code_removed and code_removed must satisfy two equations (left and right identities), also called the monad laws. (alternatively one could define monads to have a code_removed instead of binding.) the list monad is commonly used to deal with non-determinism. the bind operation selects one element of the list (intuitively all of them in parallel worlds), lets the programmer to do some computation with them, and then combines the results in all worlds to single list (by concatenating, or flattening, a nested list). here is how one would define a permutation function in the monadic framework of haskell: code_removed here is an example repl session: code_removed it should be noted that the list monad is in no way a side effecting computation. a mathematical structure being a monad (i.e. conforming to the above mentioned interfaces and laws) does not imply side effects, though side-effecting phenomena often nicely fit into the monadic framework.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["above", "mention"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i've been using r for 20 years, and i think the history does matter.r is an open source clone of s, which had some traction with rigorous statisticians via bell labs. so it had stats at its core. r was just a version of s that had less overhead and was easier to access.the explosive growth of r really is more about the explosive growth of stats and data analysis than anything else. r and s were sort of growing within the stats community anyway, and then when stats took off, so did r. i think it's open source quality and the fact that it is more similar to other programming platforms than sas or stata helped too as stats branched out into computer science.lisp is an interesting comparison with lessons for haskell. xlispstat was a competitor to r very early on but died out relatively quickly. i always was sad about that, because i loved lisp, and it was great having stats embedded in a broader language, but the reaction was uniformly the same: that lisp was just too weird, too hard to read, and too hard to program in. lisp has diminished in importance in computer science more broadly, but didn't die out in the same way xlispstat did in stats.haskell is suffering similar issues. the lack of ecosystem is partly because it's coming from the outside in, rather from the inside out, but part of it is because it is just perceived as odd. i love functional programming but am increasingly becoming convinced that any language that pushes too hard on one paradigm is going to lose out to one that is less pure. as great as functional approaches are, sometimes it's just easier to think and organize procedurally, and this is increasingly true as you get closer to the metal.the real elephant in the room is the poor performance of the languages currently dominating data science, whether that be r or python. the llvm basically made it possible to right a conceptually clean language that also exhibits good performance, so we don't have to choose between expressive and performant languages so much, unless you're talking about embedded systems or low-level systems programming. although many people don't want to program a glm (and maybe shouldn't be for integrity's sake) there are many times when going down to the likelihood function and optimization level for an unusual case shouldn't result in a huge performance hit. you shouldn't have to change to c or even rust for something that conceptually isn't that much lower level. things like julia and nim really make this possible, and is where things will probably eventually head (even if i'm not sure it will be either of those). i also wonder if we'll see things like rust taking off via higher-level extensions such as lia or gluon.my guess is that if \"functional\" languages will take off with stats, it will be through something like ocaml (especially if that gets its distributed/parallelism worked out quickly enough).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["poor", "good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "in my opinion code_removed and code_removed makes the code more fp than io. haskell is not a purely functional language because that \"looks better\". sometimes it does, often it doesn't. the reason for staying functional is not its syntax but its semantics. it equips us with referential transparency, which makes it far easier to prove invariants, allows very high-level optimisations, makes it easy to write general-purpose code etc.. none of this has much to do with syntax. monadic computations are still purely functional \u2013 regardless of whether you write them with code_removed notation or with code_removed, code_removed and code_removed, so we get haskell's benefits either way. however, notwithstanding the aforementioned fp-benefits, it is often more intuitive to think about algorithms from an imperative-like point of view \u2013 even if you're accustomed to how this is implemented through monads. in these cases, code_removed notation gives you this quick insight of \"order of computation\", \"origin of data\", \"point of modification\", yet it's trivial to manually desugar it in your head to the code_removed version, to grasp what's going on functionally. applicative style is certainly great in many ways, however it is inherently point-free. that is often a good thing, but especially in more complex problems it can be very helpful to give names to \"temporary\" variables. when using only \"fp\" haskell syntax, this requires either lambdas or explicitly named functions. both have good use cases, but the former introduces quite a bit of noise right in the middle of your code and the latter rather disrupts the \"flow\" since it requires a code_removed or code_removed placed somewhere else from where you use it. code_removed, on the other hand, allows you to introduce a named variable right where you need it, without introducing any noise at all.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["very high-level"], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "stevebmark's comment got me thinking about ui technology in general and computer science.the thing about ui... it's just, plain, _hard_.there's not much more to it then that. \"ui is hard\". user interfaces, no matter if they're text based or graphical, are perhaps the most frustrating field of computer science. they look simple. \"oh, this is just a bunch of boxes and text. i can bang that out in an hour!\" three weeks later. sound familiar? it's that illusion of simplicity that drives programmers crazy. ui has, as far as i can tell, the highest ratio of perceived simplicity to actual difficulty of any other computer science field.so here we are. we have several decades worth of computer science under our collective belts. over the plethora of decades that our field has existed we've: invented the transistor, made it the size of a handful of atoms, flew to the moon and back, beat humans at chess and go, can make video calls half way around the planet, and have crammed unthinkable amounts of technology into our pockets in the form of smart phones. my house bends to my very _voice_ thanks to modern computer science.but in all that time... ui is still hard.i don't think a lot of programmers stop to think about that. maybe, just maybe, all this thrashing about with ui libraries has more to do with the fact that ui, as a computer science problem, is perhaps one of the most complicated, impenetrable problems we've come across. the perceived simplicity of the problem so often blinds us to that fact.i believe it stems from a shared \"ancestor\" with multi-threading: concurrency. every programmer knows and fears the problem of multi-threading, but they don't fear ui in the same way. yet, these two problems are more alike than not. a ui is a system that is filled with concurrent, unpredictable, events and threads that could happen in any order. that's a multi-threaded system.so it's no surprise when viewed like this that ui is hard. it's very difficult for us to reason about a multi-threaded system. even the best engineers in the world make \"obvious\" (in hindsight) mistakes when they build concurrent systems. look at all the bugs that pop up when researchers attempt to do formal verification of concurrent primitives implementations.so if it's impossible for us to reason about ui, as a concurrent system, then what do we do?my time spent with rust, the programming language, has given me some theories. rust is most popularly known for its memory safety, but its true power lies in its type system. rust is the first language i've encountered to expose to the user an advanced type system in a practical way. languages like haskell et al have of course had these advanced type systems for _decades_. but rust offers them in a way that is digestible and ergonomic. for us common folk at least. it's perhaps the first chance that we as an industry will have at a widely used programming language with advanced typing and static analysis.that advanced typing system is what gives rust its true power. most salient to this discussion is its usage of the traits send and sync. these two traits allow us to communicate to other engineers and the compiler that \"this type is safe in these concurrent scenarios.\" suddenly the frightening world of concurrency blows apart. instead of being afraid, you can be fearless. write whatever code you want and then the compiler will check it and prove (in a limited sense) that your program is correct and safe.it's an incredible shift for programmers to have this power. send and sync are a small step in a new direction: being able to leverage static analysis by the compiler to assist programmers in designing their systems. before, in e.g. c, it was up to the programmer to think about all the state of their program in their head. at best we suck at that, especially in complex scenarios like concurrent systems (and ui!).now we have tools that can augment our mental facilities. in the same way you don't have to think as hard about memory in rust as you do in its ancestors, you don't have to think as hard about concurrent systems because the compiler and the libraries and types we build alleviate the number of problems we need to think about.i believe that it's possible this road that is leading to a brighter story for concurrent programming is also leading to a brighter story for ui. rather then having to think about _all_ the states that a ui and its backing state machines can be in, we instead build type systems that allow us to describe how we believe the system should look in our heads. and then the compiler will do the dirty work of proving our assumptions correct. our compilers will be 1000x better then us at considering an exponential number of states that a ui could be in given its concurrent and unpredictable nature.so just imagine a ui framework built on top of an advanced typing system. we could do insane things like using the typing system to say that certain view elements should only be visible given certain states in our model. for example, the logout view should never be visible when the user isn't in the loggedin state. and the advanced typing system, combined with the compiler's static analysis, checks all of our state machines to prove that logout will never be visible unless the loggedin state is active.it's crazy, right? but i think it's possible. just like rust's lifetime analysis can prove when certain objects will be alive so that the borrow checker can check all your references are alive and safe. i don't think it's so crazy to imagine a future where the compiler can determine the lifetimes of a view and make sure they aren't referenced in certain states.anyway, the most important thing i wanted to communicate is that ui is hard. really hard. and we shouldn't forget that. we should approach ui with the same caution and respect that we do multi-threaded programming. perhaps with that mindset less programmers will fall into the trap of frustration. that trap that has led so many to believe that it is our libraries and frameworks that are broken, and to go off and build yet-another-framework in the vain attempt to \"solve\" ui without making any real attempts to innovate on the core computer science problem that is ui.p.s. i'm not terribly good at communicating the strength of rust's type system and underlying compiler. there's just something magical about rust that makes it easy to write an api where a) it's obvious to users how to use it, and b) it's a compiler error to use it wrong. it's not any one thing and it's easy to compare rust to other languages. so i'm not people will reply with \"but language x has feature y just like rust; how dare you argue that rust is some kind of revolution!\" oh well.i'm also sure some will come along and take issue with my assertion that rust makes memory management easier. rust makes memory management easier only if you take the time to consider the full story. that is to say, it's quite easy to manage memory efficiently in, say, c. but to do it _without_ bugs? it takes _decades_ to write a c program with no memory bugs. yet i can write the same program in rust and the compiler will _ensure_ memory is managed correctly. (within certain limits, it's possible to leak memory, etc, etc.)", "aspectos": {"AvailabilityAndScalability": ["perceive", "perceive"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["formal"], "Interoperability": ["efficiently", "correctly"]}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": 1}}, {"comentario": "isn\u2019t this just like a type system?i suspect that other languages seem even better as subjects for this kind of formal verification. haskell and rust come to mind. for the same reasons, go and smalltalk strike me as less suitable. (for those people who think i'm just a go and smalltalk partisan.)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["formal"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}}, {"comentario": "> there's no wrapper, and \"interface\" is misleadingtrue. i used a convenient lie to make a point. if you're interested in learning monads you should definitely learn it from a proper source like haskell from first principles [0], an online course, or someone who really knows what they're talking about.as i only alluded to and others have pointed out: there's nothing about monads that's inherently sequential or having to do with ordering operations. that's just how the language defined the interpretation of the io monad. and it also happens that this is the primary topic of concern of tfa.you might even come to realize that much of what a monad isn't contradicts the entire premise of tfa... haskell doesn't even need the io monad and could implement io other ways just fine [1].[0] [1]", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "it has been quite some time now that rwh came out (almost 3 years). i was eager to get my copy after following the incremental writing of the book online (which is, i think, one of the best ways to write a book.) what a rewarding read in the midst of all the rather academic papers a haskell student usually encounters! it was a sturdy companion on quite some trips and i refer back to it regularly. still, my copy started to look pretty battered and even though most of the content is still valid, there has been an abundance of new topics in the haskell world that would be worth covering in a similar fashion. considering the impact rwh had (and still has,) i sincerely hope that there will be a sequel some day:) some of the topics for a sequel that would immediately come to my mind: iteratees more on concurrent programming in haskell merits and dangers of lazy evaluation possibly covering some common libraries that deal with this in particular lazy io new ghc features (e.g. the new i/o manager, llvm code generator) memoization .. what are the topics that the haskell community needs a rwh-style explanation for? this is a summary of the suggestions so far: concepts iteratees / lazy io arrows ghc event manager techniques generics (uniplate, syb) metaprogramming (template haskell) data structures (use of functional datastructures, designing data structures) edsls (designing edsls) memoization designing with monads best practices for imperative programming tools threadscope advanced ffi tools (c2hs, using haskell from c) cabal haddock hoogle tuning the runtime, esp. gc flags djinn libraries arrays and array programming (vector, repa, hmatrix) numerics (random numbers) parallel programming (the par monad) unicode and locales (text, text-icu) parsing (attoparsec, tagsoup) networking (snap, yesod) web stuff (templating) persistance (especially no-sql storage bindings) graphics (cairo, sdl, opengl) xml (haxml) crypto processors and systems stuff", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["similar"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this is a follow-up to my previous question on which i asked why stream fusion wasn't kicking in a certain program. turns out the problem was that certain functions weren't inlined, and an code_removed flag improved the performance by about code_removed (which showcases the importance of inlining!). now, notice that, on the original question, i hardcoded code_removed calls of code_removed at once. now, suppose that, instead, i create an code_removed function, which calls a function repeatedly: code_removed in this case, just adding an code_removed pragma to code_removed won't help, because afaik ghc doesn't inline recursive functions. is there any trick to force ghc to expand code_removed at compile time and, thus, recover expected performance?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["expect"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "let the below \"code_removed\" represent some piece of monadic data. a data type which advertises an code_removed: code_removed function, code_removed, knows how to create a monad, if only it had an code_removed: code_removed here we see function, code_removed, tries to evaluate a monad but gets rebuked. code_removed funtion, code_removed, finds a way to extract the code_removed by using code_removed. code_removed little does code_removed know, the monad and code_removed are in collusion. code_removed but what do they actually talk about? well, that depends on the monad. talking solely in the abstract has limited use; you have to have some experience with particular monads to flesh out the understanding. for instance, the data type maybe code_removed has a monad instance which will acts like the following... wherein, if the case is code_removed code_removed but for the case of code_removed code_removed so the maybe monad lets a computation continue if it actually contains the code_removed it advertises, but aborts the computation if it doesn't. the result, however is still a piece of monadic data, though not the output of code_removed. for this reason, the maybe monad is used to represent the context of failure. different monads behave differently. lists are other types of data with monadic instances. they behave like the following: code_removed in this case, the function knew how to make a list from it's input, but didn't know what to do with extra input and extra lists. the bind code_removed, helped code_removed out by combining the multiple outputs. i include this example to show that while code_removed is responsible for extracting code_removed, it also has access to the eventual bound output of code_removed. indeed, it will never extract any code_removed unless it knows the eventual output has the same type of context. there are other monads which are used to represent different contexts. here's some characterizations of a few more. the code_removed monad doesn't actually have an code_removed, but it knows a guy and will get that code_removed for you. the code_removed monad has a secret stash of code_removed that it will pass to code_removed under the table, even though code_removed just came asking for an code_removed. the code_removed monad is similar to code_removed, although it only lets code_removed look at code_removed. the point in all this is that any type of data which is declared itself to be a monad is declaring some sort of context around extracting a value from the monad. the big gain from all this? well, its easy enough to couch a calculation with some sort of context. it can get messy, however, when stringing together multiple context laden calculations. the monad operations take care of resolving the interactions of context so that the programmer doesn't have to. note, that use of the code_removed eases a mess by by taking some of the autonomy away from code_removed. that is, in the above case of code_removed for instance, code_removed no longer gets to decide what to do in the case of code_removed; it's encoded in code_removed. this is the trade off. if it was necessary for code_removed to decide what to do in the case of code_removed, then code_removed should have been a function from code_removed to code_removed. in this case, code_removed being a monad is irrelevant. note, however, that sometimes a data type does not export it's constructors (looking at you io), and if we want to work with the advertised value we have little choice but to work with it's monadic interface.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["monadic"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@dan i mean if you change the data type of a function in any language don't you have to do the same? i don't see how a language such as java or c++ would help you in this regard. if you say that you can use some sort of common interface that both types obey then you should have been doing that with typeclasses in haskell.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["common"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "use random and maybe even monadrandom to implement your shuffles. a few good answers exist here but that's really operational. here's what's going on behind the scenes. i. randomness is one of the first places in haskell that you encounter and have to handle impurity---which seems offensive, because shuffles and samples seem so simple and don't feel like they ought to be bundled up with printing to a physical screen or launching nukes, but often code_removed and referentially transparent randomness would be useless. code_removed so we need a different idea about randomness to make it pure. ii. a typical \"cheat\" in scientific code used to enhance reproducibility\u2014super important\u2014is to fix your random seed of an experiment so that others can verify that they get exactly the same results every time your code is run. this is exactly referential transparency! let's try it. code_removed where code_removed is a pseudorandom mapping from code_removeds to code_removed and code_removed is a pseudorandom mapping from code_removeds to code_removeds. note that both of these functions are totally deterministic (and referentially transparent), so code_removed is as well, but we can create an infinite, lazy pseudorandom stream like so code_removed again, this stream is deterministic based on the code_removed value, but an observer who sees only the stream and not the seed should be unable to predict its future values. iii. can we shuffle a list using a random stream of integers? sure we can, by using modular arithmetic. code_removed or, to make it more self-contained, we can precompose our stream generating function to get code_removed another \"seed consuming\" referentially transparent \"random\" function. iv. so this seems to be a repeating trend. in fact, if you browse the module code_removed you'll see lots of functions like what we wrote above (i've specialized some type classes) code_removed where code_removed is the type class of things which can be generated randomly and code_removed is a kind of code_removed. this is already enough actual working code to write the necessary shuffling function. code_removed and there's an code_removed function code_removed which will let us build a random seed. code_removed but you'll notice something annoying: we need to keep varying the gen if we want to make different random permutations code_removed this means you'll either have to do lots of code_removed bookkeeping or stay in io if you want different random numbers. this \"makes sense\" because of referential transparency again---a set of random numbers have to be random with respect to each other so you need to pass information from each random event on to the next. it's really annoying, though. can we do better? v. well, generally what we need is a way to have a function take in a random seed then output some \"randomized\" result and the next seed. code_removed the result type code_removed is a fairly general result. let's give it a name code_removed and we know that we can create meaningful code_removeds in code_removed, so there's an obvious function to convert code_removed types to code_removed code_removed and now it feels like we've got something useful---a notion of a random value of type code_removed, code_removed is just a function on code_removeds which returns the next code_removed so that later code_removed values won't all be identical. we can even make some machinery to compose random values and do this code_removed-passing automatically code_removed but that's a little silly since we're just throwing away code_removed. let's compose them such that the second random number actually depends materially on the first random value. code_removed we also ought to note that we can do \"pure\" things to code_removed values, for instance, multiplying a random number by 2: code_removed which we can abstract out as a functor instance code_removed and now we can create cool random effects like brownian motion code_removed vi. and this gets to the heart of the whole matter that i've been writing up to. randomness can exist in the code_removed monad perfectly well, but it can also exist on its own as a simpler code_removed monad. we can write the instance immediately. code_removed and since it's a monad, we get free code_removed notation code_removed and you could even get fancy and call code_removed a monad homomorphism, but that's a very different topic. so, to recap randomness in a referentially transparent language needs code_removeds carting code_removeds are is annoying there's a common pattern to \"lifting\" and \"binding\" random values which routes the code_removeds around naturally that pattern forms a monad and the really short answer is that you probably want to be using random and maybe even monadrandom to implement your shuffles. they'll come in handy for \"sampling\" generally. cheers!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["exactly referential", "referential", "again"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "can haskell provide some of the benefits of node.js, namely a clean solution to avoid blocking i/o without having recourse to multi-thread programming? yes, in fact events and threads are unified in haskell. you can program in explicit lightweight threads (e.g. millions of threads on a single laptop). or; you can program in an async event-driven style, based on scalable event notification. threads are actually implemented in terms of events, and run across multiple cores, with seamless thread migration, with documented performance, and applications. e.g. for massively concurrent job orchestration concurrent collections scaling on 32 or 48 cores tool support for profiling and debugging multi-threaded/multi-event programs. high performance event-driven web servers. interesting users: such as high-frequency trading. concurrent collections nbody on 32 cores in haskell you have both events and threads, and as it is all events under the hood. read the paper describing the implementation.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["document"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "dependent type theory and 'arbitrary' type functions my first answer to this question was high on concepts and low on details and reflected on the subquestion, 'what is going on?'; this answer will be the same but focused on the subquestion, 'can we get arbitrary type functions?'. one extension to the algebraic operations of sum and product are the so called 'large operators', which represent the sum and product of a sequence (or more generally, the sum and product of a function over a domain) usually written code_removed and code_removed respectively. see sigma notation. so the sum code_removed might be written code_removed where code_removed is some sequence of real numbers, for example. the product would be represented similarly with code_removed instead of code_removed. when you look from a distance, this kind of expression looks a lot like an 'arbitrary' function in code_removed; we are limited of course to expressible series, and their associated analytic functions. is this a candidate for a representation in a type theory? definitely! the class of type theories which have immediate representations of these expressions is the class of 'dependent' type theories: theories with dependent types. naturally we have terms dependent on terms, and in languages like haskell with type functions and type quantification, terms and types depending on types. in a dependent setting, we additionally have types depending on terms. haskell is not a dependently typed language, although many features of dependent types can be simulated by torturing the language a bit. curry-howard and dependent types the 'curry-howard isomorphism' started life as an observation that the terms and type-judging rules of simply-typed lambda calculus correspond exactly to natural deduction (as formulated by gentzen) applied to intuitionistic propositional logic, with types taking the place of propositions, and terms taking the place of proofs, despite the two being independently invented/discovered. since then, it has been a huge source of inspiration for type theorists. one of the most obvious things to consider is whether, and how, this correspondence for propositional logic can be extended to predicate or higher order logics. dependent type theories initially arose from this avenue of exploration. for an introduction to the curry-howard isomorphism for simply-typed lambda calculus, see here. as an example, if we want to prove code_removed we must prove code_removed and prove code_removed; a combined proof is simply a pair of proofs: one for each conjunct. in natural deduction: code_removed and in simply-typed lambda calculus: code_removed similar correspondences exist for code_removed and sum types, code_removed and function types, and the various elimination rules. an unprovable (intuitionistically false) proposition corresponds to an uninhabited type. with the analogy of types as logical propositions in mind, we can start to consider how to model predicates in the type-world. there are many ways in which this has been formalised (see this introduction to martin-l\u00f6f's intuitionistic type theory for a widely-used standard) but the abstract approach usually observes that a predicate is like a proposition with free term variables, or, alternatively, a function taking terms to propositions. if we allow type expressions to contain terms, then a treatment in lambda calculus style immediately presents itself as a possibility! considering only constructive proofs, what constitutes a proof of code_removed? we can think of it as a proof function, taking terms (code_removed) to proofs of their corresponding propositions (code_removed). so members (proofs) of the type (proposition) code_removed are 'dependent functions', which for each code_removed in code_removed give a term of type code_removed. what about code_removed? we need any member of code_removed, code_removed, together with a proof of code_removed. so members (proofs) of the type (proposition) code_removed are 'dependent pairs': a distinguished term code_removed in code_removed, together with a term of type code_removed. notation: i will use code_removed for actual statements about members of the class code_removed, and code_removed for type expressions corresponding to universal quantification over type code_removed. likewise for code_removed. combinatorial considerations: products and sums as well as the curry-howard correspondence of types with propositions, we have the combinatorial correspondence of algebraic types with numbers and functions, which is the main point of this question. happily, this can be extended to the dependent types outlined above! i will use the modulus notation code_removed to represent the 'size' of a type code_removed, to make explicit the correspondence outlined in the question, between types and numbers. note that this is a concept outside of the theory; i do not claim that there need be any such operator within the language. let us count the possible (fully reduced, canonical) members of type code_removed which is the type of dependent functions taking terms code_removed of type code_removed to terms of type code_removed. each such function must have an output for every term of code_removed, and this output must be of a particular type. for each code_removed in code_removed, then, this gives code_removed 'choices' of output. the punchline is code_removed which of course doesn't make huge deal of sense if code_removed is code_removed, but is applicable to algebraic types. similarly, a term of type code_removed is the type of pairs code_removed with code_removed, so given any code_removed in code_removed we can construct an appropriate pair with any member of code_removed, giving code_removed 'choices'. hence, code_removed with the same caveats. this justifies the common notation for dependent types in theories using the symbols code_removed and code_removed, and indeed many theories blur the distinction between 'for all' and 'product' and between 'there is' and 'sum', due to the above-mentioned correspondences. we are getting close! vectors: representing dependent tuples can we now encode numerical expressions like code_removed as type expressions? not quite. while we can informally consider the meaning of expressions like code_removed in haskell, where code_removed is a type and code_removed a natural number, it's an abuse of notation; this is a type expression containing a number: distinctly not a valid expression. on the other hand, with dependent types in the picture, types containing numbers is precisely the point; in fact, dependent tuples or 'vectors' are a very commonly-cited example of how dependent types can provide pragmatic type-level safety for operations like list access. a vector is just a list along with type-level information regarding its length: precisely what we are after for type expressions like code_removed. for the duration of this answer, let code_removed be the type of length-code_removed vectors of code_removed-type values. technically code_removed here is, rather than an actual natural number, a representation in the system of a natural number. we can represent natural numbers (code_removed) in peano style as either zero (code_removed) or the successor (code_removed) of another natural number, and for code_removed i write code_removed to mean the term in code_removed which represents code_removed. for example, code_removed is code_removed. then we have code_removed for any code_removed. nat types: promoting \u2115 terms to types now we can encode expressions like code_removed as types. this particular expression would give rise to a type which is of course isomorphic to the type of lists of code_removed, as identified in the question. (not only that, but from a category-theoretic point of view, the type function - which is a functor - taking code_removed to the above type is naturally isomorphic to the list functor.) one final piece of the puzzle for 'arbitrary' functions is how to encode, for code_removed expressions like code_removed so that we can apply arbitrary coefficients to a power series. we already understand the correspondence of algebraic types with numbers, allowing us to map from types to numbers and type functions to numerical functions. we can also go the other way! - taking a natural number, there is obviously a definable algebraic type with that many term members, whether or not we have dependent types. we can easily prove this outside of the type theory by induction. what we need is a way to map from natural numbers to types, inside the system. a pleasing realisation is that, once we have dependent types, proof by induction and construction by recursion become intimately similar - indeed they are the very same thing in many theories. since we can prove by induction that types exist which fulfil our needs, should we not be able to construct them? there are several ways to represent types at the term level. i will use here an imaginary haskellish notation with code_removed for the universe of types, itself usually considered a type in a dependent setting.1 likewise, there are also at least as many ways to notate 'code_removed-elimination' as there are dependent type theories. i will use a haskellish pattern-matching notation. we need a mapping, code_removed from code_removed to code_removed, with the property code_removed the following pseudodefinition suffices. code_removed so we see that the action of code_removed mirrors the behaviour of the successor code_removed, making it a kind of homomorphism. code_removed is a type function which 'adds one' to the number of members of a type; that is, code_removed for any code_removed with a defined size. for example code_removed (which is code_removed), is code_removed and the terms of this type are code_removed giving us exactly four elements: code_removed. likewise, for any code_removed, we have code_removed as required. many theories require that the members of code_removed are mere representatives of types, and an operation is provided as an explicit mapping from terms of type code_removed to their associated types. other theories permit the literal types themselves to be term-level entities. 'arbitrary' functions? now we have the apparatus to express a fully general power series as a type! the series code_removed becomes the type code_removed where code_removed is some suitable representation within the language of the function code_removed. we can see this as follows. code_removed just how 'arbitrary' is this? we are limited not only to integer coefficients by this method, but to natural numbers. apart from that, code_removed can be anything at all, given a turing complete language with dependent types, we can represent any analytic function with natural number coefficients. i haven't investigated the interaction of this with, for example, the case provided in the question of code_removed or what possible sense such negative and non-integer 'types' might have in this context. hopefully this answer goes some way to exploring how far we can go with arbitrary type functions.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["combinatorial"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i'd like to propose a more systematic approach to answering this question, and also to show examples that do not use any special tricks like the \"bottom\" values or infinite data types or anything like that. when do type constructors fail to have type class instances? in general, there are two reasons why a type constructor could fail to have an instance of a certain type class: cannot implement the type signatures of the required methods from the type class. can implement the type signatures but cannot satisfy the required laws. examples of the first kind are easier than those of the second kind because for the first kind, we just need to check whether one can implement a function with a given type signature, while for the second kind, we are required to prove that no implementation could possibly satisfy the laws. specific examples a type constructor that cannot have a functor instance because the type cannot be implemented: code_removed this is a contrafunctor, not a functor, because it uses the type parameter code_removed in a contravariant position. it is impossible to implement a function with type signature code_removed. a type constructor that is not a lawful functor even though the type signature of code_removed can be implemented: code_removed the curious aspect of this example is that we can implement code_removed of the correct type even though code_removed cannot possibly be a functor because it uses code_removed in a contravariant position. so this implementation of code_removed shown above is misleading - even though it has the correct type signature (i believe this is the only possible implementation of that type signature), the functor laws are not satisfied (this requires some simple computations to check). in fact, code_removed is only a profunctor, - it is neither a functor nor a contrafunctor. a lawful functor that is not applicative because the type signature of code_removed cannot be implemented: take the writer monad code_removed and remove the constraint that code_removed should be a monoid. it is then impossible to construct a value of type code_removed out of code_removed. a functor that is not applicative because the type signature of code_removed cannot be implemented: code_removed. a functor that is not lawful applicative even though the type class methods can be implemented: code_removed the type constructor code_removed is a functor because it uses code_removed only in covariant positions. code_removed the only possible implementation of the type signature of code_removed is a function that always returns code_removed: code_removed but this implementation does not satisfy the identity law for applicative functors. a functor that is code_removed but not a code_removed because the type signature of code_removed cannot be implemented. i do not know any such examples! a functor that is code_removed but not a code_removed because laws cannot be satisfied even though the type signature of code_removed can be implemented. this example has generated quite a bit of discussion, so it is safe to say that proving this example correct is not easy. but several people have verified this independently by different methods. see is `data poe a = empty | pair a a` a monad? for additional discussion. code_removed it is somewhat cumbersome to prove that there is no lawful code_removed instance. the reason for the non-monadic behavior is that there is no natural way of implementing code_removed when a function code_removed could return code_removed or code_removed for different values of code_removed. it is perhaps clearer to consider code_removed, which is also not a monad, and to try implementing code_removed for that. one will find that there is no intuitively reasonable way of implementing code_removed. code_removed in the cases indicated by code_removed, it seems clear that we cannot produce code_removed in any reasonable and symmetric manner out of six different values of type code_removed. we could certainly choose some arbitrary subset of these six values, -- for instance, always take the first nonempty code_removed - but this would not satisfy the laws of the monad. returning code_removed will also not satisfy the laws. a tree-like data structure that is not a monad even though it has associativity for code_removed - but fails the identity laws. the usual tree-like monad (or \"a tree with functor-shaped branches\") is defined as code_removed this is a free monad over the functor code_removed. the shape of the data is a tree where each branch point is a \"functor-ful\" of subtrees. the standard binary tree would be obtained with code_removed. if we modify this data structure by making also the leaves in the shape of the functor code_removed, we obtain what i call a \"semimonad\" - it has code_removed that satisfies the naturality and the associativity laws, but its code_removed method fails one of the identity laws. \"semimonads are semigroups in the category of endofunctors, what's the problem?\" this is the type class code_removed. for simplicity, i define the code_removed method instead of code_removed: code_removed the branch grafting is standard, but the leaf grafting is non-standard and produces a code_removed. this is not a problem for the associativity law but breaks one of the identity laws. when do polynomial types have monad instances? neither of the functors code_removed and code_removed can be given a lawful code_removed instance, although they are obviously code_removed. these functors have no tricks - no code_removed or code_removed anywhere, no tricky laziness/strictness, no infinite structures, and no type class constraints. the code_removed instance is completely standard. the functions code_removed and code_removed can be implemented for these functors but will not satisfy the laws of the monad. in other words, these functors are not monads because a specific structure is missing (but it is not easy to understand what exactly is missing). as an example, a small change in the functor can make it into a monad: code_removed is a monad. another similar functor code_removed is also a monad. constructions for polynomial monads in general, here are some constructions that produce lawful code_removeds out of polynomial types. in all these constructions, code_removed is a monad: code_removed where code_removed is any monoid code_removed where code_removed is any monad and code_removed is any monoid code_removed where code_removed and code_removed are any monads code_removed where code_removed is any monad the first construction is code_removed, the second construction is code_removed. the third construction is a component-wise product of monads: code_removed is defined as the component-wise product of code_removed and code_removed, and code_removed is defined by omitting cross-product data (e.g. code_removed is mapped to code_removed by omitting the second part of the tuple): code_removed the fourth construction is defined as code_removed i have checked that all four constructions produce lawful monads. i conjecture that there are no other constructions for polynomial monads. for example, the functor code_removed is not obtained through any of these constructions and so is not monadic. however, code_removed is monadic because it is isomorphic to the product of three monads code_removed, code_removed, and code_removed. also, code_removed is monadic because it is isomorphic to the product of code_removed and code_removed. the four constructions shown above will allow us to obtain any sum of any number of products of any number of code_removed's, for example code_removed and so on. all such type constructors will have (at least one) code_removed instance. it remains to be seen, of course, what use cases might exist for such monads. another issue is that the code_removed instances derived via constructions 1-4 are in general not unique. for example, the type constructor code_removed can be given a code_removed instance in two ways: by construction 4 using the monad code_removed, and by construction 3 using the type isomorphism code_removed. again, finding use cases for these implementations is not immediately obvious. a question remains - given an arbitrary polynomial data type, how to recognize whether it has a code_removed instance. i do not know how to prove that there are no other constructions for polynomial monads. i don't think any theory exists so far to answer this question.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["reasonable"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> it's genius and i wish all other languages gave you the ability to optionally choose between braces or whitespace. it could settle the whole python vs c syntax war once and for all!i really like haskell as a language, but the fact it isn't based on s-expression is the biggest issue i have with it. whitespace, braces, etc. are very minor quibbles: they're basically debates about language as a ui. the problem is, that same language is also the api we must adhere to when manipulating code programatically, e.g. writing interpreters/compilers/documentation generators/code formatters/linters/renderers to html or latex or whatever/static analysers/verifiers/model checkers/ides/refactoring tools/etc.i think it's telling that a language so heavily focused on language implementation (dsls, etc.) effectively has a single usable implementation (ghc), and a mountain of dead/niche implementations ( ).imagine we're given the path to a file containing haskell code, and we want to transform it in some way (e.g. replacing calls to one function with another function). the most basic thing we need to do is parse it, but my work on code analysis tools over the past few years has taught me that we can't even manage that reliably.we might naively reach for the ghc api, but that requires that we set a whole bunch of configuration options that we may not know (language extensions, package databases, commandline flags, etc. collectively referred to as \"dynflags\"); if we get those wrong, our program crashes saying `the impossible happened!`. we can't, in general, figure out what these should be; the only real solution is to invoke our program via cabal, and read in the needed values by emulating the commandline flags of ghc. this solution is useless if we have a string of code, without any associated cabal project.we might instead opt for a standalone library, like haskell-src-exts. the problem is, those libraries typically can't parse haskell code found \"in the wild\". language extensions are one problem, but another major blocker is widespread use of the c preprocessor (an unhygenic, unsafe macro system based on string substition; which would be largely unnecessary if haskell used an easily manipulated format like s-expressions instead).note that even ghc can't re-use its own asts: the template haskell extension provides its own ast representation, entirely separate to that used by the compiler's frontend!whilst there are layers on top of haskell like \"liskell\", which accept s-expressions and produce haskell code, they're solving the opposite problem: it's easy to convert from s-expressions, since they're so trivial to manipulate. the hard problem is being able to do anything useful with the mountain of existing code which isn't in a nice s-expression format, other than compile it with (some versions of) ghc, if invoked with the right options from (some version of) cabal; or maybe stack; maybe after running hpack; or who knows what else!i wrote up some of this at", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["n't", "even"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "i would recommend you erlang. it is not strong typed language and you should try it. it is very different approach to programming and you may find that there are problems where strong typing is not the best tool(tm). anyway erlang provides you tools for static type verification (typer, dialyzer) and you can use strong typing on parts where you gain benefits from it. it can be interesting experience for you but be prepared, it will be very different feeling. if you are looking for \"conceptually interesting paradigm\" you can found them in erlang, message passing, memory separation instead sharing, distribution, otp, error handling and error propagation instead of error \"prevention\" and so. erlang can be far away from your current experience but still brain tickling if you have experience with c and haskell.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["static"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}}, {"comentario": "curiously, was geniplate insufficient for your needs? wouldn't it have avoided the issue and provided better performance?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this tutorial was a real pleasure to read, and it even managed to teach me complex concepts like applicatives or monads without giving me a headache;)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["even"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "monads are to control flow what abstract data types are to data. in other words, many developers are comfortable with the idea of sets, lists, dictionaries (or hashes, or maps), and trees. within those data types there are many special cases (for instance insertionorderpreservingidentityhashmap). however, when confronted with program \"flow\" many developers haven't been exposed to many more constructs than if, switch/case, do, while, goto (grr), and (maybe) closures. so, a monad is simply a control flow construct. a better phrase to replace monad would be 'control type'. as such, a monad has slots for control logic, or statements, or functions - the equivalent in data structures would be to say that some data structures allow you to add data, and remove it. for example, the \"if\" monad: code_removed at its simplest has two slots - a clause, and a block. the code_removed monad is usually built to evaluate the result of the clause, and if not false, evaluate the block. many developers are not introduced to monads when they learn 'if', and it just isn't necessary to understand monads to write effective logic. monads can become more complicated, in the same way that data structures can become more complicated, but there are many broad categories of monad that may have similar semantics, but differing implementations and syntax. of course, in the same way that data structures may be iterated over, or traversed, monads may be evaluated. compilers may or may not have support for user-defined monads. haskell certainly does. ioke has some similar capabilities, although the term monad is not used in the language.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["similar"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i don't think it means that your language or application has failed you, especially if we consider quasiquotes. there are always trade-offs when it comes to syntax. some syntax better describes a certain domain, so you want to be able to switch to another syntax sometimes. quasiquotes allow you to elegantly switch between syntaxes. this is very powerful and is used by yesod and other apps. being able to write html generation code using syntax that feels like html is an amazing feature.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["certain"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "@tikhonjelvis there is no heuristic: you can figure it out from the cb-need strategy: do you have to evaluate a thunk before you can compute the whnf of that thunk? if so, you will end up in <<loop>> or its multi-threaded equivalent, if not, you won't. you might not be able to decide that statically, but that doesn't matter to the question at hand.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["cb-need"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@edwardkmett: i saw that the lense package only uses the exitcode-stdio-1.0 test suite interface. the cabal user guide states, that ``it is preferred that new test suites be written for the detailed-1.0 interface''. any comments on that?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["exitcode-stdio-1.0", "detailed-1.0"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "steps to understanding call/cc (for c programmers):code_removed presto, you have call/cc.shorter: allocate function frames on the stack, reify the return function argument closure and call it the continuation. to \"reify\" means to give reality to something that was previously hidden / implied.call/cc looks really awesome until you realize that it has / causes problems. one problem is that if you hold on to a reference to a continuation then you're actually preventing gc of all the stack frames captured by that continuation. then there are thread safety issues... any language that has variables (as opposed to lexical, immutable bindings) will have thread safety problems. imagine using closures as callbacks, and having said closures change variables they close over, and now imagine them racing against each other to modify the same variables. well, in a scheme continuations are strung-up closures, so now imagine multiple threads trying to call the same continuation. these thread-safety problems run deep, and will tend to push one towards haskell or rust.really, call/cc is a bit of a parlor trick:) -- a fascinating parlor trick, but still a parlor trick.if you want much much more detail, i recommend two great books that deal with this subject:code_removed in on lisp, paul graham has a chapter where he builds a set of macros that give you scheme-style continuations with minimal compromises in how you write lisp code.lisp in small pieces is all about writing lisp/scheme interpreters and compilers, so it touches on all of this depth and great detail.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["same", "scheme-style"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "tl;dr code_removed prologue the application operator code_removed of functions code_removed is canonically defined code_removed in terms of haskell-primitive function application code_removed (code_removed). composition code_removed is defined in terms of code_removed as code_removed and satisfies the equivalences code_removed code_removed code_removed is associative, and code_removed is its right and left identity. the kleisli triple in programming, a monad is functor type constructor with an instance of the monad type class. there are several equivalent variants of definition and implementation, each carrying slightly different intuitions about the monad abstraction. a functor is a type constructor code_removed of kind code_removed with an instance of the functor type class. code_removed in addition to following statically enforced type protocol, instances of the functor type class must obey the algebraic functor laws code_removed code_removed functor computations have the type code_removed a computation code_removed consists in results code_removed within context code_removed. unary monadic functions or kleisli arrows have the type code_removed kleisi arrows are functions that take one argument code_removed and return a monadic computation code_removed. monads are canonically defined in terms of the kleisli triple code_removed code_removed implemented as the type class code_removed the kleisli identity code_removed is a kleisli arrow that promotes a value code_removed into monadic context code_removed. extension or kleisli application code_removed applies a kleisli arrow code_removed to results of a computation code_removed. kleisli composition code_removed is defined in terms of extension as code_removed code_removed composes two kleisli arrows, applying the left arrow to results of the right arrow\u2019s application. instances of the monad type class must obey the monad laws, most elegantly stated in terms of kleisli composition: code_removed code_removed code_removed is associative, and code_removed is its right and left identity. identity the identity type code_removed is the identity function on types code_removed interpreted as a functor, code_removed in canonical haskell, the identity monad is defined code_removed option an option type code_removed encodes computation code_removed that may not yield a result code_removed, computation that may \u201cfail\u201d. the option monad is defined code_removed code_removed is applied only if code_removed yields a result. code_removed the natural numbers can be encoded as those integers greater than or equal to zero. code_removed the natural numbers are not closed under subtraction. code_removed the option monad covers a basic form of exception handling. code_removed list the list monad, over the list type code_removed and its additive monoid operation \u201cappend\u201d code_removed encodes nonlinear computation code_removed yielding a natural amount code_removed of results code_removed. code_removed extension concatenates code_removed all result lists code_removed from applications code_removed of a kleisli arrow code_removed to elements of code_removed into a single result list code_removed. let the proper divisors of a positive integer code_removed be code_removed then code_removed in defining the monad type class, instead of extension code_removed, the haskell standard uses its flip, the bind operator code_removed. code_removed for simplicitys sake, this explanation uses the type class hierarchy code_removed in haskell, the current standard hierarchy is code_removed because not only is every monad a functor, but every applicative is a functor and every monad an applicative, too. using the list monad, the imperative pseudocode code_removed roughly translates to the do block code_removed the equivalent monad comprehension code_removed and the expression code_removed do notation and monad comprehensions are syntactic sugar for nested bind expressions. the bind operator is used for local name binding of monadic results. code_removed where code_removed the guard function is defined code_removed where the unit type or \u201cempty tuple\u201d code_removed additive monads that support choice and failure can be abstracted over using a type class code_removed where code_removed and code_removed form a monoid code_removed code_removed and code_removed is the absorbing/annihilating zero element of additive monads code_removed if in code_removed code_removed is true, then the guard produces code_removed, and, by the definition of code_removed, the local constant function code_removed is applied to the result code_removed. if false, then the guard produces the list monad\u2019s code_removed code_removed, which yields no result for a kleisli arrow to be applied code_removed to. state infamously, monads are used to encode stateful computation. a state processor is a function code_removed that transitions a state code_removed and yields a result code_removed. the state code_removed can be anything. nothing, flag, count, array, handle, machine, world. the type of state processors is usually called code_removed the state processor monad is the kinded code_removed functor code_removed. kleisli arrows of the state processor monad are functions code_removed in canonical haskell, the lazy version of the state processor monad is defined code_removed a state processor is run by supplying an initial state: code_removed state access is provided by primitives code_removed and code_removed, methods of abstraction over stateful monads: code_removed code_removed declares a functional dependency of the state type code_removed on the monad code_removed; that a code_removed, for example, will determine the state type to be code_removed uniquely. code_removed with the unit type used analogously to code_removed in c. code_removed code_removed is often used with record field accessors. the state monad equivalent of the variable threading code_removed where code_removed, is the equally referentially transparent, but infinitely more elegant and practical code_removed code_removed is a computation of type code_removed, except for its effect equivalent to code_removed. code_removed the monad law of associativity can be written in terms of code_removed code_removed code_removed or code_removed like in expression-oriented programming (e.g. rust), the last statement of a block represents its yield. the bind operator is sometimes called a \u201cprogrammable semicolon\u201d. iteration control structure primitives from structured imperative programming are emulated monadically code_removed input/output code_removed the i/o world state processor monad is a reconciliation of pure haskell and the real world, of functional denotative and imperative operational semantics. a close analogue of the actual strict implementation: code_removed interaction is facilitated by impure primitives code_removed the impurity of code that uses code_removed primitives is permanently protocolized by the type system. because purity is awesome, what happens in code_removed, stays in code_removed. code_removed or, at least, should. the type signature of a haskell program code_removed expands to code_removed a function that transforms a world. epilogue the category whiches objects are haskell types and whiches morphisms are functions between haskell types is, \u201cfast and loose\u201d, the category code_removed. a functor code_removed is a mapping from a category code_removed to a category code_removed; for each object in code_removed an object in code_removed code_removed and for each morphism in code_removed a morphism in code_removed code_removed where code_removed, code_removed are objects in code_removed. code_removed is the homomorphism class of all morphisms code_removed in code_removed. the functor must preserve morphism identity and composition, the \u201cstructure\u201d of code_removed, in code_removed. code_removed the kleisli category of a category code_removed is given by a kleisli triple code_removed of an endofunctor code_removed (code_removed), an identity morphism code_removed (code_removed), and an extension operator code_removed (code_removed). each kleisli morphism in code_removed code_removed by the extension operator code_removed is given a morphism in code_removed\u2019s kleisli category code_removed composition in the kleisli category code_removed is given in terms of extension code_removed and satisfies the category axioms code_removed which, applying the equivalence transformations code_removed in terms of extension are canonically given code_removed monads can also be defined in terms not of kleislian extension, but a natural transformation code_removed, in programming called code_removed. a monad is defined in terms of code_removed as a triple over a category code_removed, of an endofunctor code_removed and two natural tranformations code_removed satisfying the equivalences code_removed the monad type class is then defined code_removed the canonical code_removed implementation of the option monad: code_removed the code_removed function code_removed is the code_removed of the list monad. code_removed implementations of code_removed can be translated from extension form using the equivalence code_removed the reverse translation from code_removed to extension form is given by code_removed philip wadler: monads for functional programming simon l peyton jones, philip wadler: imperative functional programming jonathan m. d. hill, keith clarke: an introduction to category theory, category theory monads, and their relationship to functional programming \u00b4 kleisli category eugenio moggi: notions of computation and monads what a monad is not but why should a theory so abstract be of any use for programming? the answer is simple: as computer scientists, we value abstraction! when we design the interface to a software component, we want it to reveal as little as possible about the implementation. we want to be able to replace the implementation with many alternatives, many other \u2018instances\u2019 of the same \u2018concept\u2019. when we design a generic interface to many program libraries, it is even more important that the interface we choose have a variety of implementations. it is the generality of the monad concept which we value so highly, it is because category theory is so abstract that its concepts are so useful for programming. it is hardly suprising, then, that the generalisation of monads that we present below also has a close connection to category theory. but we stress that our purpose is very practical: it is not to \u2018implement category theory\u2019, it is to find a more general way to structure combinator libraries. it is simply our good fortune that mathematicians have already done much of the work for us! from generalising monads to arrows by john hughes", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["statically enforce", "generic"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i'm going to order this guide by the level of skill you have in haskell, going from an absolute beginner right up to an expert. note that this process will take many months (years?), so it is rather long. absolute beginner firstly, haskell is capable of anything, with enough skill. it is very fast (behind only c and c++ in my experience), and can be used for anything from simulations to servers, guis and web applications. however there are some problems that are easier to write for a beginner in haskell than others. mathematical problems and list process programs are good candidates for this, as they only require the most basic of haskell knowledge to be able to write. firstly, some good guides to learning the very basics of haskell are the happy learn haskell tutorial and the first 6 chapters of learn you a haskell. while reading these, it is a very good idea to also be solving simple problems with what you know. another two good resources are haskell programming from first principles, and programming in haskell. they both come with exercises for each chapter, so you have small simple problems matching what you learned on the last few pages. a good list of problems to try is the haskell 99 problems page. these start off very basic, and get more difficult as you go on. it is very good practice doing a lot of those, as they let you practice your skills in recursion and higher order functions. i would recommend skipping any problems that require randomness as that is a bit more difficult in haskell. check this so question in case you want to test your solutions with quickcheck (see intermediate below). once you have done a few of those, you could move on to doing a few of the project euler problems. these are sorted by how many people have completed them, which is a fairly good indication of difficulty. these test your logic and haskell more than the previous problems, but you should still be able to do the first few. a big advantage haskell has with these problems is integers aren't limited in size. to complete some of these problems, it will be useful to have read chapters 7 and 8 of learn you a haskell as well. beginner after that you should have a fairly good handle on recursion and higher order functions, so it would be a good time to start doing some more real world problems. a very good place to start is real world haskell (online book, you can also purchase a hard copy). i found the first few chapters introduced too much too quickly for someone who has never done functional programming/used recursion before. however with the practice you would have had from doing the previous problems you should find it perfectly understandable. working through the problems in the book is a great way of learning how to manage abstractions and building reusable components in haskell. this is vital for people used to object-orientated (oo) programming, as the normal oo abstraction methods (oo classes) don't appear in haskell (haskell has type classes, but they are very different to oo classes, more like oo interfaces). i don't think it is a good idea to skip chapters, as each introduces a lot new ideas that are used in later chapters. after a while you will get to chapter 14, the dreaded monads chapter (dum dum dummmm). almost everyone who learns haskell has trouble understanding monads, due to how abstract the concept is. i can't think of any concept in another language that is as abstract as monads are in functional programming. monads allows many ideas (such as io operations, computations that might fail, parsing,...) to be unified under one idea. so don't feel discouraged if after reading the monads chapter you don't really understand them. i found it useful to read many different explanations of monads; each one gives a new perspective on the problem. here is a very good list of monad tutorials. i highly recommend the all about monads, but the others are also good. also, it takes a while for the concepts to truly sink in. this comes through use, but also through time. i find that sometimes sleeping on a problem helps more than anything else! eventually, the idea will click, and you will wonder why you struggled to understand a concept that in reality is incredibly simple. it is awesome when this happens, and when it does, you might find haskell to be your favorite imperative programming language:) to make sure that you are understanding haskell type system perfectly, you should try to solve 20 intermediate haskell exercises. those exercises using fun names of functions like \"furry\" and \"banana\" and helps you to have a good understanding of some basic functional programming concepts if you don't have them already. nice way to spend your evening with list of paper covered with arrows, unicorns, sausages and furry bananas. intermediate once you understand monads, i think you have made the transition from a beginner haskell programmer to an intermediate haskeller. so where to go from here? the first thing i would recommend (if you haven't already learnt them from learning monads) is the various types of monads, such as reader, writer and state. again, real world haskell and all about monads gives great coverage of this. to complete your monad training learning about monad transformers is a must. these let you combine different types of monads (such as a reader and state monad) into one. this may seem useless to begin with, but after using them for a while you will wonder how you lived without them. now you can finish the real world haskell book if you want. skipping chapters now though doesn't really matter, as long as you have monads down pat. just choose what you are interested in. with the knowledge you would have now, you should be able to use most of the packages on cabal (well the documented ones at least...), as well as most of the libraries that come with haskell. a list of interesting libraries to try would be: parsec: for parsing programs and text. much better than using regexps. excellent documentation, also has a real world haskell chapter. quickcheck: a very cool testing program. what you do is write a predicate that should always be true (eg code_removed). you then pass the predicate the quickcheck, and it will generate a lot of random values (in this case lists) and test that the predicate is true for all results. see also the online manual. hunit: unit testing in haskell. gtk2hs: the most popular gui framework for haskell, lets you write gtk applications in haskell. happstack: a web development framework for haskell. doesn't use databases, instead a data type store. pretty good docs (other popular frameworks would be snap and yesod). also, there are many concepts (like the monad concept) that you should eventually learn. this will be easier than learning monads the first time, as your brain will be used to dealing with the level of abstraction involved. a very good overview for learning about these high level concepts and how they fit together is the typeclassopedia. applicative: an interface like monads, but less powerful. every monad is applicative, but not vice versa. this is useful as there are some types that are applicative but are not monads. also, code written using the applicative functions is often more composable than writing the equivalent code using the monad functions. see functors, applicative functors and monoids from the learn you a haskell guide. foldable,traversable: typeclasses that abstract many of the operations of lists, so that the same functions can be applied to other container types. see also the haskell wiki explaination. monoid: a monoid is a type that has a zero (or mempty) value, and an operation, notated code_removed that joins two monoids together, such that code_removed and code_removed. these are called identity and associativity laws. many types are monoids, such as numbers, with code_removed and code_removed. this is useful in many situations. arrows: arrows are a way of representing computations that take an input and return an output. a function is the most basic type of arrow, but there are many other types. the library also has many very useful functions for manipulating arrows - they are very useful even if only used with plain old haskell functions. arrays: the various mutable/immutable arrays in haskell. st monad: lets you write code with a mutable state that runs very quickly, while still remaining pure outside the monad. see the link for more details. frp: functional reactive programming, a new, experimental way of writing code that handles events, triggers, inputs and outputs (such as a gui). i don't know much about this though. paul hudak's talk about yampa is a good start. there are a lot of new language features you should have a look at. i'll just list them, you can find lots of info about them from google, the haskell wikibook, the haskellwiki.org site and ghc documentation. multiparameter type classes/functional dependencies type families existentially quantified types phantom types gadts others... a lot of haskell is based around category theory, so you may want to look into that. a good starting point is category theory for computer scientist. if you don't want to buy the book, the author's related article is also excellent. finally you will want to learn more about the various haskell tools. these include: ghc (and all its features) cabal: the haskell package system darcs: a distributed version control system written in haskell, very popular for haskell programs. haddock: a haskell automatic documentation generator while learning all these new libraries and concepts, it is very useful to be writing a moderate-sized project in haskell. it can be anything (eg a small game, data analyser, website, compiler). working on this will allow you to apply many of the things you are now learning. you stay at this level for ages (this is where i'm at). expert it will take you years to get to this stage (hello from 2009!), but from here i'm guessing you start writing phd papers, new ghc extensions, and coming up with new abstractions. getting help finally, while at any stage of learning, there are multiple places for getting information. these are: the #haskell irc channel the mailing lists. these are worth signing up for just to read the discussions that take place - some are very interesting. other places listed on the haskell.org home page conclusion well this turned out longer than i expected... anyway, i think it is a very good idea to become proficient in haskell. it takes a long time, but that is mainly because you are learning a completely new way of thinking by doing so. it is not like learning ruby after learning java, but like learning java after learning c. also, i am finding that my object-orientated programming skills have improved as a result of learning haskell, as i am seeing many new ways of abstracting ideas.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["how", "more", "less powerful"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "have a look at this answer about lists vs arrays: stackoverflow.com/questions/8196667/haskell-arrays-vs-lists vectors have mostly the same performance as arrays, but a larger api.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["mostly", "same"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i'll add as an aside that only replacing the filter-and-length with a fold (i.e. keeping lists and not using vectors) actually gives me slightly worse performance than the original code when not using llvm: ca. 2.6s. with llvm i get ca. 1.4s, which is about the same improvement as going to vectors without using llvm.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["slightly bad"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i would start with haskell programming from first principles, as it is recommended by many and it looks good (i have to admit i started with lyah but content-wise, hpffp is much better).i also recommend reading these web documents as a supplement: am now reading haskell high performance programming ( and while the book is more intermediate (it assumes that you can find the documentation and read the haskell code yourself), i think it is a good overview of how to use modern haskell in real projects.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "my personal guess is that most people need \"warm up\" time to make progress on their projects, the time needed to build up the mental model of the whole domain. this can go from hours to days to weeks depending on the person and the type of mental model. but some people have certain domains where they can just instantly build up that model in their head and immediately begin making serious progress. you sound like you're one of the rare ones that can do this for a large number of domains (3d algorithms, project architecture, database structure, feature interaction). i'm only like that with a few very specific domains and i suspect most other devs are like me in that sense, so we stand in awe when someone has that natural in-built capability. (i think this not only goes for making progress but also learning new concepts, as i have seen other graduate students who can blaze through certain things like haskell where i struggle as through molasses.) if this theory is true, then you probably aren't spending more than 3-5 hours on projects like this per week, but you're making the same progress most of us would need 2-5 weeks for.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["whole", "certain", "few", "very specific", "natural", "in-built"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "this code does not compile: code_removed this is expected because it's ambiguous. the two possibilities are code_removed and code_removed and the compiler doesn't know which code_removed to pick. however, this code does compile: code_removed why? why isn't haskell confused here, in a similar manner as in the example above, about which code_removed to pick (for code_removed or code_removed)?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["similar"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "haskell forces you to manage effects explicitly, even for e.g. input/output. in a production system this is probably a good idea (most of your functions shouldn't be doing i/o and you probably do want to flag up a function that is), but when you're just trying to get started with \"hello world\" it's a confusing extra complication.if that was your problem, it might be easiest to start by doing things in the repl (ghci) where you don't need to be doing i/o, and only start writing standalone haskell programs once you're a bit more comfortable with the language. but i'm just guessing - maybe you found some other aspect to be a barrier?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["explicitly"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "haskell programming from first principles is costly but extremely good: beginner material in the haskell wikibook is pretty solid:", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this is rather explicitly not what the asker requested, \"i really tried to implement the same algorithm as similar as possible in the four languages\". to quote a comment on one of the many deleted answers similar to yours \"it's pretty obvious you can get faster speeds with a better algorithm regardless of language.\"", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["fast"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "as what has already been mentioned by others, what behind the mystery is branch predictor. i'm not trying to add something but explaining the concept in another way. there is a concise introduction on the wiki which contains text and diagram. i do like the explanation below which uses a diagram to elaborate the branch predictor intuitively. in computer architecture, a branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. the purpose of the branch predictor is to improve the flow in the instruction pipeline. branch predictors play a critical role in achieving high effective performance in many modern pipelined microprocessor architectures such as x86. two-way branching is usually implemented with a conditional jump instruction. a conditional jump can either be \"not taken\" and continue execution with the first branch of code which follows immediately after the conditional jump, or it can be \"taken\" and jump to a different place in program memory where the second branch of code is stored. it is not known for certain whether a conditional jump will be taken or not taken until the condition has been calculated and the conditional jump has passed the execution stage in the instruction pipeline (see fig. 1). based on the described scenario, i have written an animation demo to show how instructions are executed in a pipeline in different situations. without the branch predictor. without branch prediction, the processor would have to wait until the conditional jump instruction has passed the execute stage before the next instruction can enter the fetch stage in the pipeline. the example contains three instructions and the first one is a conditional jump instruction. the latter two instructions can go into the pipeline until the conditional jump instruction is executed. it will take 9 clock cycles for 3 instructions to be completed. use branch predictor and don't take a conditional jump. let's assume that the predict is not taking the conditional jump. it will take 7 clock cycles for 3 instructions to be completed. use branch predictor and take a conditional jump. let's assume that the predict is not taking the conditional jump. it will take 9 clock cycles for 3 instructions to be completed. the time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. as a result, making a pipeline longer increases the need for a more advanced branch predictor. as you can see, it seems we don't have a reason not to use branch predictor. it's quite a simple demo that clarifies the very basic part of branch predictor. if those gifs are annoying, please feel free to remove them from the answer and visitors can also get the demo from git", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["high", "effective", "longer"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "could anyone give some pointers on why the impure computations in haskell are modelled as monads? i mean monad is just an interface with 4 operations, so what was the reasoning to modelling side-effects in it?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["just"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "where do you find a reference saying the c spec guarantees \"int is at least 32 bits\"? the only guarantees i know of are the minimum magnitudes of code_removed and code_removed (-32767 and 32767, which practically impose a requirement that code_removed be at least 16 bits). code_removed is required to be at least as large as an code_removed, and the range requirements mean code_removed is at least 32 bits.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["minimum"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i have seen several sources echo the opinion that \"haskell is gradually becoming a dependently-typed language\". the implication seems to be that with more and more language extensions, haskell is drifting in that general direction, but isn't there yet. there are basically two things i would like to know. the first is, quite simply, what does \"being a dependently-typed language\" actually mean? (hopefully without being too technical about it.) the second question is... what's the drawback? i mean, people know we're heading that way, so there must be some advantage to it. and yet, we're not there yet, so there must be some downside stopping people going all the way. i get the impression that the problem is a steep increase in complexity. but, not really understanding what dependent typing is, i don't know for sure. what i do know is that every time i start reading about a dependently-typed programming language, the text is utterly incomprehensible... presumably that's the problem. (?)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["steep"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "as my first programming language, i decided to learn haskell. i'm an analytic philosophy major, and haskell allowed me to quickly and correctly create programs of interest, for instance, transducers for natural language parsing, theorem provers, and interpreters. although i've only been programming for two and a half months, i found haskell's semantics and syntax much easier to learn than more traditional imperative languages, and feel comfortable (now) with the majority of its constructs. programming in haskell is like sorcery, however, and i would like to broaden my knowledge of programming. i would like to choose a new programming language to learn, but i do not have enough time to pick up an arbitrary language, drop it, and repeat. so i thought i would pose the question here, along with several stipulations about the type of language i am looking for. some are subjective, some are intended to ease the transition from haskell. strong type system. one of my favorite parts of programming in haskell is writing type declarations. this helps structure my thoughts about individual functions and their relationship to the program as a whole. it also makes informally reasoning about the correctness of my program easier. i'm concerned with correctness, not efficiency. emphasis on recursion rather than iteration. i use iterative constructs in haskell, but implement them recursively. however, it is much easier to understand the structure of a recursive function than a complicated iterative procedure, especially when using combinators and higher-order functions like maps, folds and bind. rewarding to learn. haskell is a rewarding language to work in. it's a little like reading kant. my experience several years ago with c, however, was not. i'm not looking for c. the language should enforce a conceptually interesting paradigm, which in my entirely subjective opinion, the c-likes do not. weighing the answers: these are just notes, of course. i'd just like to reply to everyone who gave well-formed responses. you have been very helpful. 1) several responses indicated that a strong, statically typed language emphasizing recursion means another functional language. while i want to continue working strongly with haskell, camccann and larsmans correctly pointed out that another such language would \"ease the transition too much.\" these comments have been very helpful, because i am not looking to write haskell in caml! of the proof assistants, coq and agda both look interesting. in particular, coq would provide a solid introduction to constructive logic and formal type theory. i've spent a little time with first-order predicate and modal logic (mendellsohn, enderton, some of hinman), so i would probably have a lot of fun with coq. 2) others heavily favored lisp (common lisp, scheme and clojure). from what i gather, both common lisp and scheme have excellent introductory material (on lisp and the reasoned schemer, sicp). the material in sicp causes me to lean towards scheme. in particular, scheme through sicp would cover a different evaluation strategy, the implementation of laziness, and a chance to focus on topics like continuations, interpreters, symbolic computation, and so on. finally, as others have pointed out, lisp's treatment of code/data would be entirely new. hence, i am leaning heavily towards option (2), a lisp. 3) third, prolog. prolog has a wealth of interesting material, and its primary domain is exactly the one i'm interested in. it has a simple syntax and is easy to read. i can't comment more at the moment, but after reading an overview of prolog and skimming some introductory material, it ranks with (2). and it seems like prolog's backtracking is always being hacked into haskell! 4) of the mainstream languages, python looks the most interesting. tim yates makes the languages sound very appealing. apparently, python is often taught to first-year cs majors; so it's either conceptually rich or easy to learn. i'd have to do more research. thank you all for your recommendations! it looks like a lisp (scheme, clojure), prolog, or a proof assistant like coq or agda are the main langauages being recommended.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["not"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["different", "primary"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "@semicolon code_removed actually shares some of the same problems as code_removed; however, for some reason, extant libraries have mostly managed to avoid the temptation to do weird things in code_removed. i admit i have no technical explanation for this outcome. for your second question, you may like to read what is the monomorphism restriction?.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["however", "mostly"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "it's about branch prediction. what is it? a branch predictor is one of the ancient performance improving techniques which still finds relevance into modern architectures. while the simple prediction techniques provide fast lookup and power efficiency they suffer from a high misprediction rate. on the other hand, complex branch predictions \u2013either neural based or variants of two-level branch prediction \u2013provide better prediction accuracy, but they consume more power and complexity increases exponentially. in addition to this, in complex prediction techniques the time taken to predict the branches is itself very high \u2013ranging from 2 to 5 cycles \u2013which is comparable to the execution time of actual branches. branch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption, and low complexity with minimum resources. there really are three different kinds of branches: forward conditional branches - based on a run-time condition, the pc (program counter) is changed to point to an address forward in the instruction stream. backward conditional branches - the pc is changed to point backward in the instruction stream. the branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again. unconditional branches - this includes jumps, procedure calls and returns that have no specific condition. for example, an unconditional jump instruction might be coded in assembly language as simply \"jmp\", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as \"jmpne\" would redirect the instruction stream only if the result of a comparison of two values in a previous \"compare\" instructions shows the values to not be equal. (the segmented addressing scheme used by the x86 architecture adds extra complexity, since jumps can be either \"near\" (within a segment) or \"far\" (outside the segment). each type has different effects on branch prediction algorithms.) static/dynamic branch prediction: static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code. references: branch predictor a demonstration of self-profiling branch prediction review branch prediction", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["ancient", "exponentially"], "Reliability": ["low"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i've only been learning for about a week, but i think if you're a nerd for language design, you will appreciate it on an aesthetic level as a very tight design around a powerful concept. common lisp also has multiple dispatch, but i feel the integration of it into all the nooks and crannies of julia really pays off. julia's performance doesn't appear as a side effect of building on the llvm or because they over-optimized the core, as it does in many young performance-oriented languages. instead, it appears as a tangible benefit of a multiple-dispatch oriented design that makes it easy to add information to the system to improve performance without compromising the clarity of a sketch.i have often felt that there are many discontinuities between \"pretty\" haskell as it is taught and pragmatic haskell. i haven't used julia enough in anger to say it for sure, but i see in the way it works great potential for the pragmatic code to be as beautiful as the high-level and abstract code.for a long time i have felt that haskell represented the most mathematical language. julia really shows that there are other ways of building a mathematical language with taste and style. it's oriented to practitioners and applied math folks rather than computer scientists and pure mathematicians. i have enjoyed seeing the differences between these systems quite a bit, and i think julia has a bright future as a practical, daily-use system for science.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["great"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "essentially, it's about doing io in a functional style, correctly and efficiently. that's all, really. correct and efficient are easy enough using quasi-imperative style with strict io. functional style is easy with lazy io, but it's technically cheating (using code_removed under the hood) and can have issues with resource management and efficiency. in very, very general terms, a lot of pure functional code follows a pattern of taking some data, recursively expanding it into smaller pieces, transforming the pieces in some fashion, then recombining it into a final result. the structure may be implicit (in the call graph of the program) or an explicit data structure being traversed. but this falls apart when io is involved. say your initial data is a file handle, the \"recursively expand\" step is reading a line from it, and you can't read the entire file into memory at once. this forces the entire read-transform-recombine process to be done for each line before reading the next one, so instead of the clean \"unfold, map, fold\" structure they get mashed together into explicitly recursive monadic functions using strict io. iteratees provide an alternative structure to solve the same problem. the \"transform and recombine\" steps are extracted and, instead of being functions, are changed into a data structure representing the current state of the computation. the \"recursively expand\" step is given the responsibility of obtaining the data and feeding it to an (otherwise passive) iteratee. what benefits does this offer? among other things: because an iteratee is a passive object that performs single steps of a computation, they can be easily composed in different ways--for instance, interleaving two iteratees instead of running them sequentially. the interface between iteratees and enumerators is pure, just a stream of values being processed, so a pure function can be freely spliced in between them. data sources and computations are oblivious to each other's internal workings, decoupling input and resource management from processing and output. the end result is that a program can have a high-level structure much closer to what a pure functional version would look like, with many of the same benefits to compositionality, while simultaneously having efficiency comparable to the more imperative, strict io version. as for being \"worth the complexity\"? well, that's the thing--they're really not that complex, just a bit new and unfamiliar. the idea's been floating around for only, what, a couple years? give it some time for things to shake out as people use iteratee-based io in larger projects (e.g., with things like snap), and for more examples/tutorials to appear. it's likely that, in hindsight, the current implementations will seem very rough around the edges. somewhat related: you may want to read this discussion about functional-style io. iteratees aren't mentioned all that much, but the central issue is very similar. in particular this solution, which is both very elegant and goes even further than iteratees in abstracting incremental io.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["comparable"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["pure"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "the two pieces of code do very different things. code_removed creates a list of 123456790 code_removed (lazily), takes the remainder modulo 4 of each (involving first a check whether the code_removed is small enough to wrap a raw machine integer, then after the division a sign-check, since code_removed returns non-negative results only - though in ghc-7.6.1, there is a primop for that, so it's not as much of a brake to use code_removed as it was before), shifts the code_removed 1 left the appropriate number of bits, which involves a conversion to \"big\" code_removeds and a call to gmp, takes the bitwise and with code_removed - yet another call to gmp - and checks whether the result is 0, which causes another call to gmp or a conversion to small integer, not sure what ghc does here. then, if the result is nonzero, a new list cell is created where that code_removed is put in, and consumed by code_removed. that's a lot of work done, most of which unnecessarily complicated due to the defaulting of unspecified number types to code_removed. the c code code_removed (i took the liberty of fixing the return type of code_removed), does much much less. it takes an code_removed, compares it to another, if smaller, takes the bitwise and of the first code_removed with 3(1), shifts the code_removed 1 to the left the appropriate number of bits, takes the bitwise and of that and the first code_removed, and if nonzero increments another code_removed, then increments the first. those are all machine ops, working on raw machine types. if we translate that code to haskell, code_removed we get a much closer result: code_removed ghc's native code generator isn't a particularly good loop optimiser, so using the llvm backend makes a big difference here, but even the native code generator doesn't do too badly. okay, i have done the optimisation of replacing a modulus calculation with a power-of-two modulus with a bitwise and by hand, ghc's native code generator doesn't do that (yet), so with ```remcode_removed.&. 3`, the native code generator produces code that takes (here) 1.42 seconds to run, but the llvm backend does that optimisation, and produces the same code as with the hand-made optimisation. now, let us turn to gspr's question while llvm didn't have a massive effect on the original code, it really did on the modified (i'd love to learn why...). well, the original code used code_removeds and lists, llvm doesn't know too well what to do with these, it can't transform that code into loops. the modified code uses code_removeds and the code_removed package rewrites the code to loops, so llvm does know how to optimise that well, and that shows. (1) assuming a normal binary computer. that optimisation is done by ordinary c compilers even without any optimisation flag, except on the very rare platforms where a code_removed instruction is faster than a shift.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["hand-made"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "designing large programs in haskell is not that different from doing it in other languages. programming in the large is about breaking your problem into manageable pieces, and how to fit those together; the implementation language is less important. that said, in a large design it's nice to try and leverage the type system to make sure you can only fit your pieces together in a way that is correct. this might involve newtype or phantom types to make things that appear to have the same type be different. when it comes to refactoring the code as you go along, purity is a great boon, so try to keep as much of the code as possible pure. pure code is easy to refactor, because it has no hidden interaction with other parts of your program.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["no", "hidden"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i talk a bit about this in engineering large projects in haskell and in the design and implementation of xmonad. engineering in the large is about managing complexity. the primary code structuring mechanisms in haskell for managing complexity are: the type system use the type system to enforce abstractions, simplifying interactions. enforce key invariants via types (e.g. that certain values cannot escape some scope) that certain code does no io, does not touch the disk enforce safety: checked exceptions (maybe/either), avoid mixing concepts (word, int, address) good data structures (like zippers) can make some classes of testing needless, as they rule out e.g. out of bounds errors statically. the profiler provide objective evidence of your program's heap and time profiles. heap profiling, in particular, is the best way to ensure no unnecessary memory use. purity reduce complexity dramatically by removing state. purely functional code scales, because it is compositional. all you need is the type to determine how to use some code -- it won't mysteriously break when you change some other part of the program. use lots of \"model/view/controller\" style programming: parse external data as soon as possible into purely functional data structures, operate on those structures, then once all work is done, render/flush/serialize out. keeps most of your code pure testing quickcheck + haskell code coverage, to ensure you are testing the things you can't check with types. ghc + rts is great for seeing if you're spending too much time doing gc. quickcheck can also help you identify clean, orthogonal apis for your modules. if the properties of your code are difficult to state, they're probably too complex. keep refactoring until you have a clean set of properties that can test your code, that compose well. then the code is probably well designed too. monads for structuring monads capture key architectural designs in types (this code accesses hardware, this code is a single-user session, etc.) e.g. the x monad in xmonad, captures precisely the design for what state is visible to what components of the system. type classes and existential types use type classes to provide abstraction: hide implementations behind polymorphic interfaces. concurrency and parallelism sneak code_removed into your program to beat the competition with easy, composable parallelism. refactor you can refactor in haskell a lot. the types ensure your large scale changes will be safe, if you're using types wisely. this will help your codebase scale. make sure that your refactorings will cause type errors until complete. use the ffi wisely the ffi makes it easier to play with foreign code, but that foreign code can be dangerous. be very careful in assumptions about the shape of data returned. meta programming a bit of template haskell or generics can remove boilerplate. packaging and distribution use cabal. don't roll your own build system. (edit: actually you probably want to use stack now for getting started.). use haddock for good api docs tools like graphmod can show your module structures. rely on the haskell platform versions of libraries and tools, if at all possible. it is a stable base. (edit: again, these days you likely want to use stack for getting a stable base up and running.) warnings use code_removed to keep your code clean of smells. you might also look at agda, isabelle or catch for more assurance. for lint-like checking, see the great hlint, which will suggest improvements. with all these tools you can keep a handle on complexity, removing as many interactions between components as possible. ideally, you have a very large base of pure code, which is really easy to maintain, since it is compositional. that's not always possible, but it is worth aiming for. in general: decompose the logical units of your system into the smallest referentially transparent components possible, then implement them in modules. global or local environments for sets of components (or inside components) might be mapped to monads. use algebraic data types to describe core data structures. share those definitions widely.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["polymorphic", "many"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i'm new with haskell and have trouble with its package. i want to import system.random but could not find module `system.random' then i tried to import system but could not find module `system'. it is a member of the hidden package `haskell98-2.0.0.0'. i tried to search this problem, but those solutions still don't work. as this said, i tried to install cabal on my mac os x using macport, but error: the following dependencies were not installed: ghc error: status 1 encountered during processing. i have installed haskell platform and can use ghci in command-line. ghci, version 7.2.1 then i tried to use code_removed as this one says. but this time, i can't even run ghci. top level: ambiguous interface for `prelude': it was found in multiple packages: base haskell98-2.0.0.0 so, what can i do without using cabal?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["ambiguous"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "wouldn't be my first recommendation for a good haskell book. i really enjoyed haskell: first principles. i'm sure that will get mentioned a lot here.still, as a free resource it does cover some fun things. i just felt the book wasn't practical.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "start writing code. you'll learn necessary concepts as you go. beyond the language, to use haskell effectively, you need to learn some real-world tools and techniques. things to consider: cabal, a tool to manage dependencies, build and deploy haskell applications*. ffi (foreign function interface) to use c libraries from your haskell code**. hackage as a source of others' libraries. how to profile and optimize. automatic testing frameworks (quickcheck, hunit). *) cabal-init helps to quick-start. **) currently, my favourite tool for ffi bindings is bindings-dsl.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["foreign"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@goose, if you are considering using this technique for \"every function\", you are not really writing haskell. it's a decent technique for certain module interfaces (cf. parsec.token), but after that you are going to want to drop into idiomatic haskell -- many little combinators with, say, 1-3 pithy parameters (eg. not bools) each. i get the comfortable appeal of writing haskell like python, but you will find more satisfaction out of the language by doing it our way.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["certain"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "for my personal computing needs i recently upgraded from the combination of an ancient i7 920 quad core desktop and a quad core haswell laptop to a ryzen 2700x desktop and a pile of lovely disposable x220 thinkpads.on the one hand, for software that's not complete garbage in terms of optimization (scientific software, video/audio software, games, my own code) the difference is staggering, i hadn't felt a change this drastic since i moved from pentium 1 to pentium 3. on the other hand, i now know that there is no amount of resources that will make a modern web browser or electron app run well.the good news is that now that i feel i deserve good performance i've made an effort to get rid of most of the crap. apart from disabling js etc. by default and blocking everything i possibly can i have no solution for the browsers, sadly, but everything else is gone. the thinkpads all run minimalistic arch linux setups and mostly work as thin clients, so overall every system i use is snappy and responsive, for the first time in a decade. i shouldn't have needed a hardware upgrade to return to common sense in computing, but it is good to know that with some discipline and a low tolerance for garbage it is still (mostly) possible to have a reasonable computing experience. now, if only there was a usable browser out there...", "aspectos": {"AvailabilityAndScalability": ["low"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["minimalistic"], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}}, {"comentario": "i think you wish for a pretty bad thing. feature you want slightly increases handiness of type inference, especially for top-level functions. but signatures of top-level declarations represent essential design contracts. they are api, they are documentation, they are beacons for strangers foraying into your code, thus they have to be rock-solid and clear. yes, haskell allows type constraints for return types. but this is mostly for temporary results in let-blocks. and yes, you may use code_removed syntax with xscopedtypevariables extension (yet it isn't applicable to point-free functions).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["slightly"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "one reason for avoiding template haskell is that it as a whole isn't type-safe, at all, thus going against much of \"the spirit of haskell.\" here are some examples of this: you have no control over what kind of haskell ast a piece of th code will generate, beyond where it will appear; you can have a value of type code_removed, but you don't know if it is an expression that represents a code_removed or a code_removed or whatever. th would be more reliable if one could express that a function may only generate expressions of a certain type, or only function declarations, or only data-constructor-matching patterns, etc. you can generate expressions that don't compile. you generated an expression that references a free variable code_removed that doesn't exist? tough luck, you'll only see that when actually using your code generator, and only under the circumstances that trigger the generation of that particular code. it is very difficult to unit test, too. th is also outright dangerous: code that runs at compile-time can do arbitrary code_removed, including launching missiles or stealing your credit card. you don't want to have to look through every cabal package you ever download in search for th exploits. th can access \"module-private\" functions and definitions, completely breaking encapsulation in some cases. then there are some problems that make th functions less fun to use as a library developer: th code isn't always composable. let's say someone makes a generator for lenses, and more often than not, that generator will be structured in such a way that it can only be called directly by the \"end-user,\" and not by other th code, by for example taking a list of type constructors to generate lenses for as the parameter. it is tricky to generate that list in code, while the user only has to write code_removed. developers don't even know that th code can be composed. did you know that you can write code_removed? code_removed is just a monad, so you can use all of the usual functions on it. some people don't know this, and because of that, they create multiple overloaded versions of essentially the same functions with the same functionality, and these functions lead to a certain bloat effect. also, most people write their generators in the code_removed monad even when they don't have to, which is like writing code_removed; you are giving a function more \"environment\" than it needs, and clients of the function are required to provide that environment as an effect of that. finally, there are some things that make th functions less fun to use as an end-user: opacity. when a th function has type code_removed, it can generate absolutely anything at the top-level of a module, and you have absolutely no control over what will be generated. monolithism. you can't control how much a th function generates unless the developer allows it; if you find a function that generates a database interface and a json serialization interface, you can't say \"no, i only want the database interface, thanks; i'll roll my own json interface\" run time. th code takes a relatively long time to run. the code is interpreted anew every time a file is compiled, and often, a ton of packages are required by the running th code, that have to be loaded. this slows down compile time considerably.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["own"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "stevebmark's comment got me thinking about ui technology in general and computer science.the thing about ui... it's just, plain, _hard_.there's not much more to it then that. \"ui is hard\". user interfaces, no matter if they're text based or graphical, are perhaps the most frustrating field of computer science. they look simple. \"oh, this is just a bunch of boxes and text. i can bang that out in an hour!\" three weeks later. sound familiar? it's that illusion of simplicity that drives programmers crazy. ui has, as far as i can tell, the highest ratio of perceived simplicity to actual difficulty of any other computer science field.so here we are. we have several decades worth of computer science under our collective belts. over the plethora of decades that our field has existed we've: invented the transistor, made it the size of a handful of atoms, flew to the moon and back, beat humans at chess and go, can make video calls half way around the planet, and have crammed unthinkable amounts of technology into our pockets in the form of smart phones. my house bends to my very _voice_ thanks to modern computer science.but in all that time... ui is still hard.i don't think a lot of programmers stop to think about that. maybe, just maybe, all this thrashing about with ui libraries has more to do with the fact that ui, as a computer science problem, is perhaps one of the most complicated, impenetrable problems we've come across. the perceived simplicity of the problem so often blinds us to that fact.i believe it stems from a shared \"ancestor\" with multi-threading: concurrency. every programmer knows and fears the problem of multi-threading, but they don't fear ui in the same way. yet, these two problems are more alike than not. a ui is a system that is filled with concurrent, unpredictable, events and threads that could happen in any order. that's a multi-threaded system.so it's no surprise when viewed like this that ui is hard. it's very difficult for us to reason about a multi-threaded system. even the best engineers in the world make \"obvious\" (in hindsight) mistakes when they build concurrent systems. look at all the bugs that pop up when researchers attempt to do formal verification of concurrent primitives implementations.so if it's impossible for us to reason about ui, as a concurrent system, then what do we do?my time spent with rust, the programming language, has given me some theories. rust is most popularly known for its memory safety, but its true power lies in its type system. rust is the first language i've encountered to expose to the user an advanced type system in a practical way. languages like haskell et al have of course had these advanced type systems for _decades_. but rust offers them in a way that is digestible and ergonomic. for us common folk at least. it's perhaps the first chance that we as an industry will have at a widely used programming language with advanced typing and static analysis.that advanced typing system is what gives rust its true power. most salient to this discussion is its usage of the traits send and sync. these two traits allow us to communicate to other engineers and the compiler that \"this type is safe in these concurrent scenarios.\" suddenly the frightening world of concurrency blows apart. instead of being afraid, you can be fearless. write whatever code you want and then the compiler will check it and prove (in a limited sense) that your program is correct and safe.it's an incredible shift for programmers to have this power. send and sync are a small step in a new direction: being able to leverage static analysis by the compiler to assist programmers in designing their systems. before, in e.g. c, it was up to the programmer to think about all the state of their program in their head. at best we suck at that, especially in complex scenarios like concurrent systems (and ui!).now we have tools that can augment our mental facilities. in the same way you don't have to think as hard about memory in rust as you do in its ancestors, you don't have to think as hard about concurrent systems because the compiler and the libraries and types we build alleviate the number of problems we need to think about.i believe that it's possible this road that is leading to a brighter story for concurrent programming is also leading to a brighter story for ui. rather then having to think about _all_ the states that a ui and its backing state machines can be in, we instead build type systems that allow us to describe how we believe the system should look in our heads. and then the compiler will do the dirty work of proving our assumptions correct. our compilers will be 1000x better then us at considering an exponential number of states that a ui could be in given its concurrent and unpredictable nature.so just imagine a ui framework built on top of an advanced typing system. we could do insane things like using the typing system to say that certain view elements should only be visible given certain states in our model. for example, the logout view should never be visible when the user isn't in the loggedin state. and the advanced typing system, combined with the compiler's static analysis, checks all of our state machines to prove that logout will never be visible unless the loggedin state is active.it's crazy, right? but i think it's possible. just like rust's lifetime analysis can prove when certain objects will be alive so that the borrow checker can check all your references are alive and safe. i don't think it's so crazy to imagine a future where the compiler can determine the lifetimes of a view and make sure they aren't referenced in certain states.anyway, the most important thing i wanted to communicate is that ui is hard. really hard. and we shouldn't forget that. we should approach ui with the same caution and respect that we do multi-threaded programming. perhaps with that mindset less programmers will fall into the trap of frustration. that trap that has led so many to believe that it is our libraries and frameworks that are broken, and to go off and build yet-another-framework in the vain attempt to \"solve\" ui without making any real attempts to innovate on the core computer science problem that is ui.p.s. i'm not terribly good at communicating the strength of rust's type system and underlying compiler. there's just something magical about rust that makes it easy to write an api where a) it's obvious to users how to use it, and b) it's a compiler error to use it wrong. it's not any one thing and it's easy to compare rust to other languages. so i'm not people will reply with \"but language x has feature y just like rust; how dare you argue that rust is some kind of revolution!\" oh well.i'm also sure some will come along and take issue with my assertion that rust makes memory management easier. rust makes memory management easier only if you take the time to consider the full story. that is to say, it's quite easy to manage memory efficiently in, say, c. but to do it _without_ bugs? it takes _decades_ to write a c program with no memory bugs. yet i can write the same program in rust and the compiler will _ensure_ memory is managed correctly. (within certain limits, it's possible to leak memory, etc, etc.)", "aspectos": {"AvailabilityAndScalability": ["perceive", "perceive"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["formal"], "Interoperability": ["efficiently", "correctly"]}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": 1}}, {"comentario": "hardly worth replying, but i don't see the similarity. a 6-year-old understands perfectly well what a prime number is, and you can write a program to test for primality in half a line of haskell (though the performance will not be good). now what's a \"free will\"?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["not good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "ok, so having watched a little of the node.js presentation that @gawi pointed me at, i can say a bit more about how haskell compares to node.js. in the presentation, ryan describes some of the benefits of green threads, but then goes on to say that he doesn't find the lack of a thread abstraction to be a disadvantage. i'd disagree with his position, particularly in the context of haskell: i think the abstractions that threads provide are essential for making server code easier to get right, and more robust. in particular: using one thread per connection lets you write code that expresses the communication with a single client, rather that writing code that deals with all the clients at the same time. think of it like this: a server that handles multiple clients with threads looks almost the same as one that handles a single client; the main difference is there's a code_removed somewhere in the former. if the protocol you're implementing is at all complex, managing the state machine for multiple clients simultaneously gets quite tricky, whereas threads let you just script the communication with a single client. the code is easier to get right, and easier to understand and maintain. callbacks on a single os thread is cooperative multitasking, as opposed to preemptive multitasking, which is what you get with threads. the main disadvantage with cooperative multitasking is that the programmer is responsible for making sure that there's no starvation. it loses modularity: make a mistake in one place, and it can screw up the whole system. this is really something you don't want to have to worry about, and preemption is the simple solution. moreover, communication between callbacks isn't possible (it would deadlock). concurrency isn't hard in haskell, because most code is pure and so is thread-safe by construction. there are simple communication primitives. it's much harder to shoot yourself in the foot with concurrency in haskell than in a language with unrestricted side effects.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["moreover possible"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "was writing a long answer with a full run-through of my irc logs of the experiments leading up to the final code (this was in early 2008), but i accidentally all the text:) not that much of a loss though - for the most part daniel's analysis is spot on. here's what i started with: code_removed the differences mostly come down to the order in which the refactorings happened. instead of code_removed i started with code_removed, and i kept that initial 2 right up until the very last version, where i squeezed in a code_removed and changed the code_removed at the end into code_removed. the \"make the map needlessly complex\" step didn't happen (that early). i used liftm2 instead of lifta2 the obfuscated code_removed function was put in before replacing liftm2 with applicative combinators. that's also when all the spaces disappeared. even my \"final\" version had lots of code_removed for function composition left over. replacing all of those with code_removed apparently happened some time in the months between that and uncyclopedia. btw, here's an updated version that no longer mentions the number code_removed: code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["much"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "what do they mean by saying that code_removed? the function code_removed could be defined as code_removed i.e. taking a function and an argument and returning the result of the application. equivalently, thanks to currying, we can interpret that as taking only code_removed and returning a function of code_removed. code_removed here, we can note that the function code_removed maps any input code_removed to code_removed -- that's also what code_removed does! so, we can simplify the definition to code_removed now, this is the same as the identity function definition code_removed, so we might as well write code_removed in which cases is that statement true? does that mean i can use one instead of the other? the equation holds always, but there are two caveats. the first one is that code_removed has a more restricted type than the one of code_removed, since code_removed holds only for a function code_removed, not for any value code_removed. this means that you can replace code_removed with code_removed, but not vice versa. when writing code_removed one could make the implicit type argument explicit and write that, for any types code_removed and code_removed code_removed the other caveat is that, in the presence of higher-ranked function, code_removed receives some special handling during type checking, while code_removed does not. this is point 3 blow. in the base, what is meant by saying that code_removed is \"slightly magical (it can return unlifted types)\" and \"being wired in\"? normally, in polymorphic functions such as code_removed the type variable code_removed can be instantiated to other types, but only under some restrictions. for instance, code_removed can be instantiated to code_removed, but can not be instantiated to another polymorphic type code_removed. this keeps the type system predicative, which helps greatly during type inference. usually, this is not an issue in everyday programming. however, some functions use rank-2 types, e.g. code_removed code_removed if we write code_removed the type system can type check that. but if we use the common idiom code_removed then the type inference engine has to take the type of code_removed code_removed and choose code_removed which is polymorphic, hence forbidden. since this idiom is too common, the ghc developers decided to add a special case to the typing of code_removed to allow this. since this is a bit ad-hoc, if you define your own code_removed (possibly under another name), and try to type check code_removed this will fail since it does not use the special case. further, code_removed can not be instantiated to unboxed types such as code_removed, or unboxed tuples code_removed. these are ghc extensions which allow writing functions which pass a \"raw\" integer, without the usual thunk wrapper. this can change the semantics, e.g. making functions stricter than they are. unless you want to squeeze more performance from some numeric code, you can ignore these. (i'm leaving this part here, but lisyarus already covered it more precisely.) code_removed basically, code_removed is code_removed, but with a more restrictive type. code_removed can be used on arguments of any type, code_removed instead takes a function argument. code_removed note that code_removed, so the type of code_removed is indeed a special case. and what about \"different types in different scenarios\"? i thought that since haskell is a strongly typed language, once you define a type signature, that signature is retained until the end of time. is that not true? are there cases where one can change a function's type? in the code of the libraries which define code_removed, ghc has to play some tricks to get the special typing rules to work for the other libraries and programs. for that, apparently it is required not to use code_removed in said library. unless you are developing ghc or the code_removed module which happens to define code_removed, you can ignore this. it is an implementation detail internal to the compiler, not something that the user of the compiler and libraries must know.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["more"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "both code_removed and code_removed are non-strict in their performance of io. the difference is that, with code_removed, the result remains in io (according to the type system). with regular strict code_removed, the types make clear that io is being performed, as well as when it happens. with code_removed the type still indicates that io is happening, but not when it happens. with code_removed not only do you not know when io will happen, you don't even know that it's going on.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["non-strict"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i think it's mainly for consistency so that all clauses can be read in the same manner, so to speak; i.e. every rhs is at the same position in the type of the function. i think would mask quite a few silly errors if you allowed this, too. there's also a slight semantic quirk: say the compiler padded out such clauses to have the same number of patterns as the other clauses; i.e. your example would become code_removed now consider if the second line had instead been code_removed; in the absence of the previous clause, code_removed would be code_removed, but thanks to the eta-expansion performed here, it's code_removed \u2014 so code_removed does not actually define code_removed to be code_removed! this seems confusing enough to justify banning such clauses, imo.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["same"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> so it's a wrapper that implements a particular interface? then why, oh why, do we have so many people who spout...its because its actually a mathematical concept. and that's the mathematical definition.so haskell decided to use the same name. now some people feel, should i explain the math concept, or its concrete representation in haskell.also, its a bit more involved as an interface. in that its not enough to implement the common methods for the interface. you also have to prove that your implementation for each exhibit certain properties, specifically there needs to be an identity value which act as a neutral element, and they must be associative.those laws are where things get more mathematical. because its rare in comp-sci to talk about laws and properties of functions.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["particular"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "> not only that but you can expect to get better performance from the jit than aot because the jit can perform optimisations which are impossible for the compiler.i can\u2019t help myself, but the jvm performs at par with managed aot languages (go, haskell, ocaml, etc) and strictly slower than the unmanaged aot languages (c, c++, rust). the jvm does outperform various aot java compilers, but that\u2019s probably an artifact of the decades of optimizations that went into the jvm; the same investment in an aot compiler would close the gap to within the margin of error. anyway, sorry for my compulsive nitpicking; hopefully it was interesting.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@snim2 i'm not perfect.:p take solace in the fact that the dirty mutableness doesn't affect the referential transparency of the result. if you pass the same 'lastmeasurement' in twice, you get a stale next measurement and return the same result.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i saw inverse of the absurd function earlier today, and while it's clear to me that any possible implementation of code_removed will never terminate (after all, it's impossible to construct code_removed), i don't understand why the same isn't true of code_removed. consider the ghc implementation: code_removed code_removed, it seems to me, is endlessly unraveling the infinite series of code_removed newtype wrappers, and would never return even if you could find a code_removed to pass it. an implementation that would be indistinguishable would be something like: code_removed given that, why do we say that code_removed is a proper function that deserves to live in data.void, but code_removed is a function that cannot possibly be defined? is it something like the following? code_removed is a total function, giving a non-bottom result for any input in its (empty) domain, whereas code_removed is partial, giving bottom results for some (indeed all) inputs in its domain.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["empty"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "i don't recommend learn you a haskell or real world haskell. check out haskell programming from first principles", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i'm not talking about hamlet. the web-routes package was originally written for happstack which has essentially the same routing interface that snap has. you'll probably need a little glue code, but that's pretty much always going to be the case.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["essentially", "same", "rout"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i personally see node.js and programming with callbacks as unnecessarily low-level and a bit unnatural thing. why program with callbacks when a good runtime such as the one found in ghc may handle callbacks for you and do so pretty efficiently? in the meantime, ghc runtime has improved greatly: it now features a \"new new io manager\" called mio where \"m\" stands for multicore i believe. it builds on foundation of existing io manager and its main goal is to overcome the cause of 4+ cores performance degradation. performance numbers provided in this paper are pretty impressive. see yourself: with mio, realistic http servers in haskell scale to 20 cpu cores, achieving peak performance up to factor of 6.5x compared to the same servers using previous versions of ghc. the latency of haskell servers is also improved: [...] under a moderate load, reduces expected response time by 5.7x when compared with previous versions of ghc and: we also show that with mio, mcnettle (an sdn controller written in haskell) can scale effectively to 40+ cores, reach a thoroughput of over 20 million new requests per second on a single machine, and hence become the fastest of all existing sdn controllers. mio has made it into ghc 7.8.1 release. i personally see this as a major step forward in haskell performance. it would be very interesting to compare existing web applications performance compiled by the previous ghc version and 7.8.1.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["peak", "exist"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@jonharrop let's not forget that while mloc is a good metric when you compare projects in similar languages, it doesn't make much sense for cross-language comparison, especially with languages like haskell, where code reuse and modularity is much more easy & safe compared to some languages out there.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "thanks. that's a really excellent way to describe things, probably the best comment on this thread.there's always a tradeoff between how much intelligence you put into a runtime vs how much you have to ship with the app. in the limit wasm would turn into \"download and run an entire language runtime with every web page\", which is clearly suboptimal. most likely compilation to js will continue for the forseeable future when possible for that reason.one idea that could probably work very well is to write a wasm interpreter for graalvm. graalvm has very high level constructs but can also support low level manually memory managed code. they have one for llvm bitcode already, but wasm would probably be simpler to implement and with a more stable bytecode format. then c/rust/exceptionless c++ could ship artifacts as wasm files, scripting languages can ship source code, static managed languages like java or haskell (eta) can ship jars, and they can all interoperate and be compiled together.i don't see a route to getting there with current wasm runtimes or just the existing featureset of wasm though. as a portable isa for distribution of limited, os neutral c-ish libraries it seems reasonable enough. as a future vm for everything i can't see them beating graalvm anytime soon. graalvm has the shared high level constructs, but it is able to also (eventually) compile low level wasm/llvm style code down to what a typical gcc like compiler would create.", "aspectos": {"AvailabilityAndScalability": ["always"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["manually"]}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "in this context, you're specializing to an argument more than a signature. i don't know that the type specialization process makes much sense here. one option might be to use a proxy behind the scenes to get specialization while presenting this weird new interface to the world (i'm not entirely sold on it yet).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["weird", "new"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "this doesn't happen in a vacuum. if you demand a type involving code_removed and you supply two candidates for code_removed, it will be necessary to check that they are equal. but we're reduced to second-guessing the solving strategy in order to predict the success or failure of typechecking, which saddens me.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["solve"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "this can be accomplished in the same manner as edward suggests with a tiny implementation of code_removed. first, let's get the language extensions and imports out of the way. code_removed code_removed is only for your example problem. tiny dict we can make our own tiny implementation of code_removed. code_removed uses a gadt and code_removed to capture any constraint in the constructor for a gadt. code_removed code_removed and code_removed reintroduce the constraint by pattern matching on the gadt. we only need to be able to reason about terms with one or two sources of constraints. code_removed infinitely differentiable types now we can talk about infinitely differentiable types, whose derivatives must also be differentiable code_removed code_removed takes a proxy for the type, and recovers the dictionary for taking the second derivative. the proxy allows us to easily specify which type's code_removed we are talking about. we can get to deeper dictionaries by applying code_removed: code_removed capturing the dictonary the polynomial functor types, products, sums, constants, and zero, are all infinitely differentiable. we will define the code_removed witnesses for each of these types code_removed zero and constants don't require any additional knowledge to capture their derivative's code_removed code_removed sum and product both require the dictionaries from both of their component's derivatives to be able to deduce the dictionary for their derivative. code_removed recovering the dictionary we can recover the dictionary for constraints that we otherwise wouldn't have adequate information to deduce. code_removed would normally only let use get to code_removed, but not to either code_removed or code_removed. code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["same"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i would like to broaden my knowledge of programming. (...) i thought i would pose the question here, along with several stipulations about the type of language i am looking for. some are subjective, some are intended to ease the transition from haskell. strong type system. (...) it also makes informally reasoning about the correctness of my program easier. i'm concerned with correctness, not efficiency. emphasis on recursion rather than iteration. (...) you may be easing the transition a bit too much here, i'm afraid. the very strict type system and purely functional style are characteristic of haskell and pretty much anything resembling a mainstream programming language will require compromising at least somewhat on one of these. so, with that in mind, here are a few broad suggestions aimed at retaining most of what you seem to like about haskell, but with some major shift. disregard practicality and go for \"more haskell than haskell\": haskell's type system is full of holes, due to nontermination and other messy compromises. clean up the mess and add more powerful features and you get languages like coq and agda, where a function's type contains a proof of its correctness (you can even read the function arrow code_removed as logical implication!). these languages have been used for mathematical proofs and for programs with extremely high correctness requirements. coq is probably the most prominent language of the style, but agda has a more haskell-y feel (as well as being written in haskell itself). disregard types, add more magic: if haskell is sorcery, lisp is the raw, primal magic of creation. lisp-family languages (also including scheme and clojure) have nearly unparalleled flexibility combined with extreme minimalism. the languages have essentially no syntax, writing code directly in the form of a tree data structure; metaprogramming in a lisp is easier than non-meta programming in some languages. compromise a bit and move closer to the mainstream: haskell falls into the broad family of languages influenced heavily by ml, any of which you could probably shift to without too much difficulty. haskell is one of the strictest when it comes to correctness guarantees from types and use of functional style, where others are often either hybrid styles and/or make pragmatic compromises for various reasons. if you want some exposure to oop and access to lots of mainstream technology platforms, either scala on the jvm or f# on.net have a lot in common with haskell while providing easy interoperability with the java and.net platforms. f# is supported directly by microsoft, but has some annoying limitations compared to haskell and portability issues on non-windows platforms. scala has direct counterparts to more of haskell's type system and java's cross-platform potential, but has a more heavyweight syntax and lacks the powerful first-party support that f# enjoys. most of those recommendations are also mentioned in other answers, but hopefully my rationale for them offers some enlightenment.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["not", "cross-platform"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i guess you haven't used rust, or ocaml, or haskell.in those cases, errors are even more like normal values because they're returned using generic types (optional/maybe, result/either), not using hacky multiple return stuff.for example, in go you might have a function that returns (string, error), but you can't define a method on that type that was returned, so e.g. you can't have:code_removed this would let you right such code as:code_removed on the other hand, in rust or haskell you'd return a generic sum type which is either an error or a value and which can be treated as an actually normal value.this leads to the languages i mentioned above having the ability to have much cleaner and more concise error handling than go.the fact that go has multiple returns, not tuples or sum types, results in its errors being really awkward to use values, among their other flaws.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["other"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "you can also make zippers in scheme using delimited continuations, which allows you to derive them generically.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["delimit"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "that's only true because you have not specified the locale in the parser input. that's bad coding style and a huge design flaw in java -- its inherent localization. personally, i put \"tz=utc lc_all=c\" everywhere i use java to avoid that. in addition you should avoid every localized version of an implementation unless you are directly interacting with a user and explicitly want it. don't to any calculations including localizations, always use locale.root and utc timezones unless absolutely necessary.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["huge"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i have a program that uses code_removed, and to improve performance i decided to make some record fields strict. this resulted in much worse performance. here's the complete module that i'm changing: code_removed note that the only way to construct a code_removed is by using the code_removed function which is strict in all the code_removeds. with this code my program (sorry, i can't share it) runs in 163s. now change a single line, e.g., code_removed i.e., the code_removed field is now marked as strict. my program now takes 198s to run. so making that one field strict increases the running time by about 20%. how is this possible? the code for the code_removed function should be the same regardless since it is already strict. the code for the code_removed selector should be a bit simpler since it no longer has to evaluate. i've experimented with code_removed and code_removed on and off. it doesn't make any noticeable difference. i'm using ghc 7.8.3. has anyone seen something similar? any bright ideas what might cause it?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["much bad", "strict"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@dflemstr is right, but not explicit about the following point. some authors put internals of a package in a code_removed module and then don't expose that module via cabal, thereby making it inaccessible to client code. this is a bad thing1. exposed code_removed modules help to communicate different levels of abstraction implemented by a module. the alternatives are: expose implementation details in the same module as the abstraction. hide implementation details by not exposing them in module exports or via cabal. (1) makes the documentation confusing, and makes it hard for the user to tell the transition between his code respecting a module's abstraction and breaking it. this transition is important: it is analogous to removing a parameter to a function and replacing its occurrences with a constant, a loss of generality. (2) makes the above transition impossible and hinders the reuse of code. we would like to make our code as abstract as possible, but (cf. einstein) no more so, and the module author does not have as much information as the module user, so is not in a position to decide what code should be inaccessible. see the link for more on this argument, as it is somewhat peculiar and controversial. exposing code_removed modules provides a happy medium which communicates the abstraction barrier without enforcing it, allowing users to easily restrict themselves to abstract code, but allowing them to \"beta expand\" the module's use if the abstraction breaks down or is incomplete. 1 there are, of course, complications to this puristic judgement. an internal change can now break client code, and authors now have a larger obligation to stabilize their implementation as well as their interface. even if it is properly disclaimed, users is users and gotsta be supported, so there is some appeal to hiding the internals. it begs for a custom version policy which differentiates between code_removed and interface changes, but fortunately this is consistent with (but not explicit in) the versioning policy. \"real code\" is also notoriously lazy, so exposing an code_removed module can provide an easy out when there was an abstract way to define code that was just \"harder\" (but ultimately supports the community's reuse). it can also discourage reporting an omission in the abstract interface that really should be pushed to the author to fix.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["abstract"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i've to admit that i don't know much about functional programming. i read about it from here and there, and so came to know that in functional programming, a function returns the same output, for same input, no matter how many times the function is called. it's exactly like a mathematical function which evaluates to the same output for the same value of the input parameters which involves in the function expression. for example, consider this: code_removed no matter how many times you use code_removed, its value will always be code_removed. as such, wherever you've written code_removed, you can replace it with code_removed, without altering the value of the whole expression. this property is referred to as referential transparency of an expression. as wikipedia says (link), conversely, in functional code, the output value of a function depends only on the arguments that are input to the function, so calling a function f twice with the same value for an argument x will produce the same result f(x) both times. can a time function (which returns the current time) exist in functional programming? if yes, then how can it exist? does it not violate the principle of functional programming? it particularly violates referential transparency which is one of the property of functional programming (if i correctly understand it). or if no, then how can one know the current time in functional programming?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential", "referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there is a new security flaw called branchscope: cs.ucr.edu/~nael/pubs/asplos18.pdf", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["new"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "we're definitely moving in the direction. someone already mentioned rust, and typescript is gaining traction in web dev. banks like barclays and standard chartered already have haskell teams, and i've noticed more and more haskell jobs popping up over the years (in london). scala is already realtively popular.formal verification is used in some niche areas (bae, galois). proof engineer is a real role some companies are looking to fill.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["already popular.formal"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}}, {"comentario": "yes code_removed is part of the code_removed typeclass, and everyone seems to feel you can't define code_removed etc for your type, but i strongly disagree. code_removed i think code_removed would be nicer, or we could even just use the type code_removed directly, but... this is very much like the cartesian product of two monoids, groups, rings or whatever in maths, and there's a standard way of defining a numeric structure on it, which would be sensible to use. code_removed now we've overloaded code_removed in an obvious way, but also gone the whole hog and overloaded code_removed and all the other code_removed functions in the same, obvious, familiar way mathematics does it for a pair. i just don't see the problem with this. in fact i think it's good practice. code_removed code_removed - notice that code_removed is applied to numeric literals like code_removed, so this was interpreted in that context as code_removed. this is also quite nice and handy.", "aspectos": {"AvailabilityAndScalability": ["whole"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@adam: pretty much. a general purpose language which is pure usually offers some facility to get at the \"world state\" (i.e. things like the current time, files in a directory etc.) without breaking referential transparency. in haskell that's the io monad and in clean it's the world type. so in those languages a function which needs the current time would either take it as an argument or it would need to return an io action instead of its actual result (haskell) or take the world state as its argument (clean).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@yitz - in fact real world hardware isn't somewhere between lazy and strict - it's even more eager than eager, trying to evaluate things concurrently and ahead of time. and of course for simple computations, repeating a computation is often much faster than reading the precomputed result from memory - several arithmetic/logic instructions can run per cycle, whereas a single read of uncached main memory takes hundreds of cycles - making the whole premise of the single redex/memoization optimisation of outermost evaluation somewhat flawed.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["somewhat"], "Performance": ["single"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "'so it's a wrapper that implements a particular interface? then why, oh why, do we have so many people who spout, \"a monad is just a monoid in the category of endofunctors, what's the problem?\"'\"monad\" seems to be just beyond the complexity event horizon where it is difficult for people to get a really clean idea of what it is, so instead we've got dozens of ideas of what they are floating around, probably a good two-thirds of them with fundamental errors in them, which then contributes to the general haze surrounding the ideas.i've got a mostly-written blog post on deck with the tentative title \"functors and monads for people who have read too many tutorials\", for which around 80% of it isn't explaining what they are, but systematically walking through all the errors i've seen (some of which are in the type notation for haskell itself; the \"[a]\" abbreviation for what should be \"[] a\", if not \"list a\", alone has done untold damage to comprehension) before finally getting down to what the things are.(functor in particular is so trivial it's hard to believe it's that trivial when you finally really get it. monad legitimately has a bit of a twist in it, and some of the specific uses of that interface take that twist and hammer it home to produce some very funky code, so the fact that it's a bit foggy isn't that big a surprise. the fog that functor has picked up by association with monad is much, much larger than the concept itself, though.)\"so it's a way of imperatively declaring execution sequence dependencies that lets you reason as if there's only pure functions most of the time.\"it turns out no, that's just one use of them. a very big one, a very natural one, and the one that drove their prominence in the current debate... but it's not actually what the interface is \"about\" per se. for a good counterexample, consider the parsing monad implementations that \"declaratively\" [1] create a parser. it's not really about declaring execution sequences.(there's also a non-trivial amount of confusion that arises from the fact that monad and laziness have a lot of interaction. the monad interface in a strict language would be used differently than it can be in haskell.)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["particular"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "meh, everyone has a preferred type of language they find least surprising. to many ruby is the least surprising, and matz used \"principle of [his] least surprise\" as a guiding principle when designing it, but many other people find it enigmatic and confusing. some people find haskell the least surprising and most consistent, others say java is. every language has caveats and inconsistencies, even go. like how go has generics, but only for two or three built-in types. it seems to be more about the person trying out the language than the language itself.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["guide"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there are some great answers below, but i'd suggest you not think of things like this as \"oo\" features. in haskell, for example, the main unit of encapsulation and hiding of implementation is the module, and is not tied to any specific data structure. modular design was a good thing before it was ever used in object oriented programming! similarly, type classes in haskell specifically reject the oo-ish idea of writing the data structure and its behaviors in one place, but still effectively separate interface and implementation.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["still separate"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i'd expect this idiom to be applicable not just to linear structures (and hence \"loops\"), but also to branching (tree-like) structures. i wonder how often the code_removed pattern corresponds to accumulation parameters and, more generally, with the continuation-encoding strategites that mitch wand explored in the paper continuation-based program transformation strategies (one of my all-time favorite papers). in these cases, the code_removed function has a particular meaning, which can then be used to derive efficient code from an elegant specification.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["continuation-based"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "simple version for folks obsessed with bullet lists (failed to find one, so have to write it by myself): data - creates new algebraic type with value constructors can have several value constructors value constructors are lazy values can have several fields affects both compilation and runtime, have runtime overhead created type is a distinct new type can have its own type class instances when pattern matching against value constructors, will be evaluated at least to weak head normal form (whnf) * used to create new data type (example: address { zip:: string, street:: string } ) newtype - creates new \u201cdecorating\u201d type with value constructor can have only one value constructor value constructor is strict value can have only one field affects only compilation, no runtime overhead created type is a distinct new type can have its own type class instances when pattern matching against value constructor, can be not evaluated at all * used to create higher level concept based on existing type with distinct set of supported operations or that is not interchangeable with original type (example: meter, cm, feet is double) type - creates an alternative name (synonym) for a type (like typedef in c) no value constructors no fields affects only compilation, no runtime overhead no new type is created (only a new name for existing type) can not have its own type class instances when pattern matching against data constructor, behaves the same as original type used to create higher level concept based on existing type with the same set of supported operations (example: string is [char]) [*] on pattern matching laziness: code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["not"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "code_removed source: haskell programming from first principles, by chris allen and julie moronuki", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "ghc's base now supports streams which is why the results are similar. uvector's terrible performance in -o0 is expected because it completely relies on streaming to get any decent performance. also, your comments indicate you use uvector but your module import indicates you use vector. in any case it'd be nice to look at data.vector.unboxed performance rather than data.vector", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["terrible", "decent", "data.vector.unboxed", "data.vector"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there is one obvious and sensible continuation of your intuitive series, and that is to recognize that an explicitly undefined case needs to be represented as such. the correct type for code_removed is thus code_removed, with code_removed.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["obvious"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "snap has pretty good momentum. first of all, it was the most downloaded web framework on hackage last year even though the project didn't launch publicly until may. second, since the 0.3 release in december, we've seen a big increase in activity. libraries for sessions, auth, mongodb, the xmlhtml library, and more are all being worked on by people who are for the most part new contributors in 2011. you can also usually find 30 or more people in the #snapframework irc channel. it is definitely an active project.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["big"], "Reliability": [], "Deployability": [], "Securability": ["session", ","], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}}, {"comentario": "i've added some text on decomposition of design to modules. your goal is to identify logically related functions into modules that have referentially transparent interfaces with other parts of the system, and to use purely functional data types as soon as possible, as much as possible, to model the outside world safely. the xmonad design document covers a lot of this: xmonad.wordpress.com/2009/09/09/\u2026", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["referentially transparent"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "worth mentioning a haswell system with qdr i helped build. i discovered that it was needed to use an older version of libpsm to avoid a bandwidth boost tweak that increased latency which isn't the competitive advantage of ib qdr. also highly disappointing they down clocked haswell as soon as avx2 was touched. given no temperature increase, there isn't a thermal argument for it just for using more of the micro instructions on the die. was an early system, and needed to use end-of-life centos for the correct library versions.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["increase", "no"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this is solely my own opinion. it's ugly to use. code_removed just does not look nice. superficial, sure, but it contributes. it's even uglier to write. quoting works sometimes, but a lot of the time you have to do manual ast grafting and plumbing. the api is big and unwieldy, there's always a lot of cases you don't care about but still need to dispatch, and the cases you do care about tend to be present in multiple similar but not identical forms (data vs. newtype, record-style vs. normal constructors, and so on). it's boring and repetitive to write and complicated enough to not be mechanical. the reform proposal addresses some of this (making quotes more widely applicable). the stage restriction is hell. not being able to splice functions defined in the same module is the smaller part of it: the other consequence is that if you have a top-level splice, everything after it in the module will be out of scope to anything before it. other languages with this property (c, c++) make it workable by allowing you to forward declare things, but haskell doesn't. if you need cyclic references between spliced declarations or their dependencies and dependents, you're usually just screwed. it's undisciplined. what i mean by this is that most of the time when you express an abstraction, there is some kind of principle or concept behind that abstraction. for many abstractions, the principle behind them can be expressed in their types. for type classes, you can often formulate laws which instances should obey and clients can assume. if you use ghc's new generics feature to abstract the form of an instance declaration over any datatype (within bounds), you get to say \"for sum types, it works like this, for product types, it works like that\". template haskell, on the other hand, is just macros. it's not abstraction at the level of ideas, but abstraction at the level of asts, which is better, but only modestly, than abstraction at the level of plain text.* it ties you to ghc. in theory another compiler could implement it, but in practice i doubt this will ever happen. (this is in contrast to various type system extensions which, though they might only be implemented by ghc at the moment, i could easily imagine being adopted by other compilers down the road and eventually standardized.) the api isn't stable. when new language features are added to ghc and the template-haskell package is updated to support them, this often involves backwards-incompatible changes to the th datatypes. if you want your th code to be compatible with more than just one version of ghc you need to be very careful and possibly use code_removed. there's a general principle that you should use the right tool for the job and the smallest one that will suffice, and in that analogy template haskell is something like this. if there's a way to do it that's not template haskell, it's generally preferable. the advantage of template haskell is that you can do things with it that you couldn't do any other way, and it's a big one. most of the time the things th is used for could otherwise only be done if they were implemented directly as compiler features. th is extremely beneficial to have both because it lets you do these things, and because it lets you prototype potential compiler extensions in a much more lightweight and reusable way (see the various lens packages, for example). to summarize why i think there are negative feelings towards template haskell: it solves a lot of problems, but for any given problem that it solves, it feels like there should be a better, more elegant, disciplined solution better suited to solving that problem, one which doesn't solve the problem by automatically generating the boilerplate, but by removing the need to have the boilerplate. * though i often feel that code_removed has a better power-to-weight ratio for those problems that it can solve. edit 23-04-14: what i was frequently trying to get at in the above, and have only recently gotten at exactly, is that there's an important distinction between abstraction and deduplication. proper abstraction often results in deduplication as a side effect, and duplication is often a telltale sign of inadequate abstraction, but that's not why it's valuable. proper abstraction is what makes code correct, comprehensible, and maintainable. deduplication only makes it shorter. template haskell, like macros in general, is a tool for deduplication.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["general"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there is a key difference between java and haskell that you are missing. in java, the type information is not lost when upcasting, so you can downcast again and do other useful non-code_removedy things later (conditioned on choosing the right type to downcast to). in haskell, once you've upcast, the type information is lost and you cannot downcast again. so you might as well just have a list of code_removeds. see also code_removed, which offers a richer interface than \"just code_removed\".", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["rich"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i wouldn't make such a small point of that \"glue code.\" the template haskell that you refer to below is what makes that \"glue code\" possible in a safe, concise manner. i wrote a small blog post to address that: yesodweb.com/blog/yesod-template-haskell", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["safe", "concise", "possible"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "it may be important to take a look how indexing is used in dependent types (eg in agda). this can explain how indexing helps in general, then translate this experience to monads. indexing permits to establish relationships between particular instances of types. then you can reason about some values to establish whether that relationship holds. for example (in agda) you can specify that some natural numbers are related with code_removed, and the type tells which numbers they are. then you can require that some function is given a witness that code_removed, because only then the function works correctly - and without providing such witness the program will not compile. as another example, given enough perseverance and compiler support for your chosen language, you could encode that the function assumes that a certain list is sorted. indexed monads permit to encode some of what dependent type systems do, to manage side effects more precisely.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["more precisely"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "> it sounds like you haven't experienced too many of those kinds of paradigm shifts. all you know is the math-y kind.you know that hn readers are about the 99th percentile of \"willingness to learn random new cs concepts\", right? most programmers know one language. in fact, most programmers have only ever worked for one company, on one product, for their whole productive careers so far. your idea of an \"average\" programmer is, in fact, a rare programmer.> if you delve into the smalltalk image and class library, it does teach you oop!that is the exact equivalent of reading a textbook on the subject, except it's not presented in prerequisite order, so it's slightly harder to digest.a system that teaches is a system that allows you to notice the micro-skills you're missing faster than a textbook. a textbook is the brute-force approach.smalltalk is not a system that teaches. it's just a system. you can get out what you put into delving through it, but you can do that just as well with any random system. to be pedagogical, a system has to accelerate that process.> we're awesome! we're the superior learners, which is why we're superior, but alas poor us, it also makes us suck at teaching.er, no: people that \"know haskell\" (category theory) generally suck at teaching haskell (category theory) because people suck at teaching by default, because they haven't learned the meta-skill of teaching. and even those that do, haven't yet put in the effort to factor their mental-model of a given skill to turn it into a teachable skill.the people that can teach you something about haskell (category theory), are, y'know, teachers, that have learned haskell (category theory) and then applied educational principles to their understanding of it in order to be able to teach it well.has nothing to do with haskell, other than haskell actually having a relatively-difficult skill in it for people coming from a sweng background to learn. other languages are easier or harder for such people to learn, because the skills they require are more or less natural given a sweng background; and, comparatively, people with a cs or physics or electrical engineering background have other backgrounds that make different languages have a different skill-gulf. haskell (category theory) is easy for mathematicians. assembly is easy for electrical engineers. prolog is easy for db systems programmers. etc. nothing special about any of them\u2014they're just different points in knowledge-space, that different people start out closer or further from because of their backgrounds.> try and produce stuff.i do! not in haskell, though. despite writing the above, i have literally never used haskell once in my life. i'm just talking about it as a specific application of the general principle of skill-gulfs.> try and reach people.why?in all of the above, nobody ever said why anyone is trying to teach anyone else monads. honestly, i think people just shouldn't bother. no \"amateur teacher\" is attempting to teach anyone else graph theory, or linear algebra, or the x86 isa. professional teachers, at universities, do that, because those are skills independent of any programming language. people generally understand that teaching these skills is the job of professional teachers, and that you have to apply yourself as a student, full-time, to learn them.well, category theory is such a skill.in short: stop trying to teach people monads. petition more schools to teach people monads (category theory), outside of the context of any particular language. then haskell is just a language, with no skill gulf.to say that you should \"reach people\" with an explanation of monads, is like expecting rdbms docs to \"reach people\" with an explanation of relational algebra. it's not their job. you're supposed to come in with that skill. their job is to provide you a thing that you know you want\u2014a solution for a problem you know you have\u2014given that the skills you already possess give you the ability to evaluate that solution.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["educational", "general"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "basically no. the closest thing in rust is traits. but then this is like saying that haskell basically has ocaml functors (functions from modules to modules) as typeclasses which isn\u2019t true.some of what functors do can be done with typeclasses/traits. eg a functor might take a module with a type and compare function and produce a type of maps fron that type. meanwhile in haskell/rust you get the compare function from a typeclass/trait.on the other hand you can only have one trait/typeclass implementation per type which requires newtype wrapper awkwardness if you want an alternative. another problem is that traits tend to be basically small but functors can be big. eg let\u2019s say you want to write an application for transferring files over various protocols. you might implement a module per protocol which would include things like the type for the configuration, how to read the config, how to make a connection, how to pool connections, how to request a file, how to get chunks of it and so on. these things may not fit so well into a nice typeclass and some haskell people certainly don\u2019t like typeclasses that don\u2019t correspond to mathematical things. in ocaml the file transferring program might be based on a fuynctor applied to each protocol.a second thing rust/haskell don\u2019t have is a way to make a typeclass at runtime whereas one can do that in ocaml, e.g. it\u2019s basically impossible to make a safe type for arithmetic mod n in haskell/rust if n must be known at runtime. it is actually possible with reflect in haskell but that is horrific. it would be nice if one could do something like:code_removed but you can\u2019t. on the other hand not having any way to implicitly know how to serialise or compare things in ocaml is sad.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["various"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@kizzx2: there's a ghc ticket to have it added. from what i've understood, this transformation can result in additional allocations of closure objects. this means worse performance in some cases, but as johan tibell suggests in his blog post this can be avoided if the resulting wrapper can be inlined.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["bad"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i'm the author of code_removed - it was one of my very early endeavors in haskell and while i've never actually found or been notified of any problems with that version, it's almost certainly not as well-thought-out as the others. its purpose is indeed for use mostly with ioref, stref, et al. it could be used in state/statet for a \"pure\" interface, but is really not worth the trouble of doing so when there are so many other options out there (including just plain \"map\", which has 'minview' and 'maxview' functions).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["pure"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "that microsoft calls vb a form of rapid development is just marketing, imo. having a graphical builder gives you the ability to easily add widgets to an application in an intuitive manner, but that's pretty much it. anything else can be done as easily with just a text editor.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["intuitive"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i have a server process implemented in haskell that acts as a simple in-memory db. client processes can connect then add and retrieve data. the service uses more memory than i would expect, and i'm attempting to work out why. the crudest metric i have is linux \"top\". when i start the process i see an \"virt\" image size of ~27mb. after running a client to insert 60,000 data items, i see an image size of ~124mb. running the process to capture gc statistics (+rts -s), i see initially code_removed and on adding the 60k items i see the live bytes grow smoothly to code_removed this appears to be telling me that the heap has ~63mb of live data. this could well be consistent with numbers from top, by the time you add on stack space, code space, gc overhead etc. so i attempted to use the heap profiler to work out what's making up this 63mb. the results are confusing. running with \"+rts -h\", and looking at the generated hp file, the last and largest snapshot has: code_removed all of the other numbers in the snapshot are much smaller than this. adding these up gives the peak memory usage as ~6mb, as reflected in the chart output: why is this inconsistent with the live bytes as shown in the gc statistics? it's hard to see how my data structures could be requiring 63mb, and the profiler says they are not. where is the memory going? thanks for any tips or pointers on this. tim", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["crude"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "followup comment: from haskell programming from first principles, \"applicative instances, unlike functors, are not guaranteed to have a unique implementation for a given datatype.\" so that answers part of my question above, though i still wonder if the applicative instance choice for lists changed at some point.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "after much striving, i think i finally understand the monad. after rereading my own lengthy critique of the overwhelmingly top voted answer, i will offer this explanation. there are three questions that need to be answered to understand monads: why do you need a monad? what is a monad? how is a monad implemented? as i noted in my original comments, too many monad explanations get caught up in question number 3, without, and before really adequately covering question 2, or question 1. why do you need a monad? pure functional languages like haskell are different from imperative languages like c, or java in that, a pure functional program is not necessarily executed in a specific order, one step at a time. a haskell program is more akin to a mathematical function, in which you may solve the \"equation\" in any number of potential orders. this confers a number of benefits, among which is that it eliminates the possibility of certain kinds of bugs, particularly those relating to things like \"state\". however, there are certain problems that are not so straightforward to solve with this style of programming. some things, like console programming, and file i/o, need things to happen in a particular order, or need to maintain state. one way to deal with this problem is to create a kind of object that represents the state of a computation, and a series of functions that take a state object as input, and return a new modified state object. so let's create a hypothetical \"state\" value, that represents the state of a console screen. exactly how this value is constructed is not important, but let's say it's an array of byte length ascii characters that represents what is currently visible on the screen, and an array that represents the last line of input entered by the user, in pseudocode. we've defined some functions that take console state, modify it, and return a new console state. code_removed so to do console programming, but in a pure functional manner, you would need to nest a lot of function calls inside eachother. code_removed programming in this way keeps the \"pure\" functional style, while forcing changes to the console to happen in a particular order. but, we'll probably want to do more than just a few operations at a time like in the above example. nesting functions in that way will start to become ungainly. what we want, is code that does essentially the same thing as above, but is written a bit more like this: code_removed this would indeed be a more convenient way to write it. how do we do that though? what is a monad? once you have a type (such as code_removed) that you define along with a bunch of functions designed specifically to operate on that type, you can turn the whole package of these things into a \"monad\" by defining an operator like code_removed (bind) that automatically feeds return values on its left, into function parameters on its right, and a code_removed operator that turns normal functions, into functions that work with that specific kind of bind operator. how is a monad implemented? see other answers, that seem quite free to jump into the details of that.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["pure", "functional"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "question 1: do erlang, python and haskell loose speed due to using arbitrary length integers or don't they as long as the values are less than maxint? this is unlikely. i cannot say much about erlang and haskell (well, maybe a bit about haskell below) but i can point a lot of other bottlenecks in python. every time the program tries to execute an operation with some values in python, it should verify whether the values are from the proper type, and it costs a bit of time. your code_removed function just allocates a list with code_removed various times, and runtime, code_removed-styled memory allocation is way slower than iterating on a range with a counter as you do in c. notably, the code_removed is called multiple times and so allocates a lot of lists. also, let us not forget that python is interpreted and the cpython interpreter has no great focus on being optimized. edit: oh, well, i note that you are using python 3 so code_removed does not return a list, but a generator. in this case, my point about allocating lists is half-wrong: the function just allocates code_removed objects, which are inefficient nonetheless but not as inefficient as allocating a list with a lot of items. question 2: why is haskell so slow? is there a compiler flag that turns off the brakes or is it my implementation? (the latter is quite probable as haskell is a book with seven seals to me.) are you using hugs? hugs is a considerably slow interpreter. if you are using it, maybe you can get a better time with ghc - but i am only cogitating hypotesis, the kind of stuff a good haskell compiler does under the hood is pretty fascinating and way beyond my comprehension:) question 3: can you offer me some hints how to optimize these implementations without changing the way i determine the factors? optimization in any way: nicer, faster, more \"native\" to the language. i'd say you are playing an unfunny game. the best part of knowing various languages is to use them the most different way possible:) but i digress, i just do not have any recommendation for this point. sorry, i hope someone can help you in this case:) question 4: do my functional implementations permit lco and hence avoid adding unnecessary frames onto the call stack? as far as i remember, you just need to make sure that your recursive call is the last command before returning a value. in other words, a function like the one below could use such optimization: code_removed however, you would not have such optimization if your function were such as the one below, because there is an operation (multiplication) after the recursive call: code_removed i separated the operations in some local variables for make it clear which operations are executed. however, the most usual is to see these functions as below, but they are equivalent for the point i am making: code_removed note that it is up to the compiler/interpreter to decide if it will make tail recursion. for example, the python interpreter does not do it if i remember well (i used python in my example only because of its fluent syntax). anyway, if you find strange stuff such as factorial functions with two parameters (and one of the parameters has names such as code_removed, code_removed etc.) now you know why people do it:)", "aspectos": {"AvailabilityAndScalability": ["other"], "Maintainability": [], "Performance": ["loose"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "first: the term monad is a bit vacuous if you are not a mathematician. an alternative term is computation builder which is a bit more descriptive of what they are actually useful for. you ask for practical examples: example 1: list comprehension: code_removed this expression returns the doubles of all odd numbers in the range from 1 to 10. very useful! it turns out this is really just syntactic sugar for some operations within the list monad. the same list comprehension can be written as: code_removed or even: code_removed example 2: input/output: code_removed both examples use monads, aka computation builders. the common theme is that the monad chains operations in some specific, useful way. in the list comprehension, the operations are chained such that if an operation returns a list, then the following operations are performed on every item in the list. the io monad on the other hand performs the operations sequentially, but passes a \"hidden variable\" along, which represents \"the state of the world\", which allows us to write i/o code in a pure functional manner. it turns out the pattern of chaining operations is quite useful and is used for lots of different things in haskell. another example is exceptions: using the code_removed monad, operations are chained such that they are performed sequentially, except if an error is thrown, in which case the rest of the chain is abandoned. both the list-comprehension syntax and the do-notation are syntactic sugar for chaining operations using the code_removed operator. a monad is basically just a type that supports the code_removed operator. example 3: a parser this is a very simple parser which parses either a quoted string or a number: code_removed the operations code_removed, code_removed, etc. are pretty simple. they either match or don't match. the magic is the monad which manages the control flow: the operations are performed sequentially until a match fails, in which case the monad backtracks to the latest code_removed and tries the next option. again, a way of chaining operations with some additional, useful semantics. example 4: asynchronous programming the above examples are in haskell, but it turns out f# also supports monads. this example is stolen from don syme: code_removed this method fetches a web page. the punch line is the use of code_removed - it actually waits for the response on a separate thread, while the main thread returns from the function. the last three lines are executed on the spawned thread when the response have been received. in most other languages you would have to explicitly create a separate function for the lines that handle the response. the code_removed monad is able to \"split\" the block on its own and postpone the execution of the latter half. (the code_removed syntax indicates that the control flow in the block is defined by the code_removed monad.) how they work so how can a monad do all these fancy control-flow thing? what actually happens in a do-block (or a computation expression as they are called in f#), is that every operation (basically every line) is wrapped in a separate anonymous function. these functions are then combined using the code_removed operator (spelled code_removed in haskell). since the code_removed operation combines functions, it can execute them as it sees fit: sequentially, multiple times, in reverse, discard some, execute some on a separate thread when it feels like it and so on. as an example, this is the expanded version of the io-code from example 2: code_removed this is uglier, but it's also more obvious what is actually going on. the code_removed operator is the magic ingredient: it takes a value (on the left side) and combines it with a function (on the right side), to produce a new value. this new value is then taken by the next code_removed operator and again combined with a function to produce a new value. code_removed can be viewed as a mini-evaluator. note that code_removed is overloaded for different types, so every monad has its own implementation of code_removed. (all the operations in the chain have to be of the type of the same monad though, otherwise the code_removed operator won't work.) the simplest possible implementation of code_removed just takes the value on the left and applies it to the function on the right and returns the result, but as said before, what makes the whole pattern useful is when there is something extra going on in the monad's implementation of code_removed. there is some additional cleverness in how the values are passed from one operation to the next, but this requires a deeper explanation of the haskell type system. summing up in haskell-terms a monad is a parameterized type which is an instance of the monad type class, which defines code_removed along with a few other operators. in layman's terms, a monad is just a type for which the code_removed operation is defined. in itself code_removed is just a cumbersome way of chaining functions, but with the presence of the do-notation which hides the \"plumbing\", the monadic operations turns out to be a very nice and useful abstraction, useful many places in the language, and useful for creating your own mini-languages in the language. why are monads hard? for many haskell-learners, monads are an obstacle they hit like a brick wall. it's not that monads themselves are complex, but that the implementation relies on many other advanced haskell features like parameterized types, type classes, and so on. the problem is that haskell i/o is based on monads, and i/o is probably one of the first things you want to understand when learning a new language - after all, it's not much fun to create programs which don't produce any output. i have no immediate solution for this chicken-and-egg problem, except treating i/o like \"magic happens here\" until you have enough experience with other parts of language. sorry. excellent blog on monads:", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["pure", "functional"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "let's say using ffi we defined a function code_removed which lies about its purity, in that whenever its result is forced it prints the string. so that we don't run into the caching problems in michal's answer, we can define these functions to take an extra code_removed argument. code_removed on an implementation level this will work as long as cse is not too aggressive (which it is not in ghc because that can lead to unexpected memory leaks, it turns out). now that we have things defined this way, there are many awkward usage questions that alexis points out\u2014but we can solve them using a monad: code_removed basically, we just stuff all of alexis's awkward usage questions into a monad, and as long as we use the monadic interface, everything stays predictable. in this sense code_removed is just a convention\u2014because we can implement it in haskell there is nothing fundamental about it. that's from the operational vantage point. on the other hand, haskell's semantics in the report are specified using denotational semantics alone. and, in my opinion, the fact that haskell has a precise denotational semantics is one of the most beautiful and useful qualities of the language, allowing me a precise framework to think about abstractions and thus manage complexity with precision. and while the usual abstract code_removed monad has no accepted denotational semantics (to the lament of some of us), it is at least conceivable that we could create a denotational model for it, thus preserving some of the benefits of haskell's denotational model. however, the form of i/o we have just given is completely incompatible with haskell's denotational semantics. simply put, there are only supposed to be two distinguishable values (modulo fatal error messages) of type code_removed: code_removed and \u22a5. if we treat ffi as the fundamentals of i/o and use the code_removed monad only \"as a convention\", then we effectively add a jillion values to every type\u2014to continue having a denotational semantics, every value must be adjoined with the possibility of performing i/o prior to its evaluation, and with the extra complexity this introduces, we essentially lose all our ability to consider any two distinct programs equivalent except in the most trivial cases\u2014that is, we lose our ability to refactor. of course, because of code_removed this is already technically the case, and advanced haskell programmers do need to think about the operational semantics as well. but most of the time, including when working with i/o, we can forget about all that and refactor with confidence, precisely because we have learned that when we use code_removed, we must be very careful to ensure it plays nicely, that it still affords us as much denotational reasoning as possible. if a function has code_removed, i automatically give it 5 or 10 times more attention than regular functions, because i need to understand the valid patterns of use (usually the type signature tells me everything i need to know), i need to think about caching and race conditions, i need to think about how deep i need to force its results, etc. it's awful[1]. the same care would be necessary of ffi i/o. in conclusion: yes it's a convention, but if you don't follow it then we can't have nice things. [1] well actually i think it's pretty fun, but it's surely not practical to think about all those complexities all the time.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["monadic", "thus"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@carl, strong typing is not for security, and not for the other shiny trinkets you like to play! it's just in sake of beauty.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["not"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}}, {"comentario": "yes, for such things there should be possible to stop the program, so we have 'undefined' and 'error' as i said. divide by zero and evaluating a function \"outside its domain\" are logical design flaws. but i do not see the meaning of using exceptions in the mechanics of a program (in haskell).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["logical"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "essentially, and practically, monads allow callback nesting (with a mutually-recursively-threaded state (pardon the hyphens)) (in a composable (or decomposable) fashion) (with type safety (sometimes (depending on the language))) ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) e.g. this is not a monad: code_removed but monads enable such code. the monad is actually the set of types for: code_removed. which is essentially inessential, and practically impractical. so now i can use it: code_removed or break it up: code_removed or ignore certain results: code_removed or simplify a trivial case from: code_removed to (using \"right identity\"): code_removed or jam them back together: code_removed the practicality of these abilities doesn't really emerge, or become clear until you try to solve really messy problems like parsing, or module/ajax/resource loading. can you imagine thousands of lines of indexof/substring logic? what if frequent parsing steps were contained in little functions? functions like code_removed, code_removed,code_removed, or code_removed? and what if those functions gave you the result in a callback, without having to mess with regex groups, and arguments.slice? and what if their composition/decomposition was well understood? such that you could build big parsers from the bottom up? so the ability to manage nested callback scopes is incredibly practical, especially when working with monadic parser combinator libraries. (that is to say, in my experience) don't get hung up on: - category-theory - maybe-monads - monad laws - haskell -!!!!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["composable", "nesting"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the way i see it, the various code_removed nonfunctions really should only be used in cases where you want to do something that respects referential transparency but whose implementation would otherwise require augmenting the compiler or runtime system to add a new primitive capability. it's easier, more modular, readable, maintainable and agile to use the unsafe stuff than to have to modify the language implementation for things like that. ffi work often intrinsically requires you to do this sort of thing.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": ["new", "primitive"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@danportin: can you say more about what you are trying to achieve with a second language? you say \"programming in haskell is like sorcery\" - what do you mean by that? presumably it's not sorcery from your point of view, since you are coding useful things in it. are you asking for a more mainstream language, e.g. that would be easier to get a job with? or do you have a particular problem domain in mind?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["particular"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "on ubuntu 13.10, ghc 7.6.3 running code_removed i got code_removed. when i checked there were 305 different flags passes to code_removed, by the looks of things most of them were dependencies. i've not a clue what caused it to not work when passed to code_removed but i managed to dodge it by using this line of bash instead: code_removed. it does the same as the script above, filtering out --hash-size and --reduce-memory-overheads.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["i"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@gawi i don't think that sounds very easy to program - without preemption, you have to deal with the possibility of starvation and long latencies. basically threads are the right abstraction for a web server - there's no need to deal with asynchronous i/o and all the difficulties that go along with that, just do it in a thread. incidentally, i wrote a paper about web servers in haskell which you might find interesting: haskell.org/~simonmar/papers/web-server-jfp.pdf", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["long"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "their type is the same, just switched around, which is irrelevant. their interface and results are the same, except for the nasty p/np problem (read: infinite lists).;) the optimization due to the implementation is the only difference in practice, as far as i can tell.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["same"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@yitz - in fact real world hardware isn't somewhere between lazy and strict - it's even more eager than eager, trying to evaluate things concurrently and ahead of time. and of course for simple computations, repeating a computation is often much faster than reading the precomputed result from memory - several arithmetic/logic instructions can run per cycle, whereas a single read of uncached main memory takes hundreds of cycles - making the whole premise of the single redex/memoization optimisation of outermost evaluation somewhat flawed.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["somewhat"], "Performance": ["single"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "your haskell implementation could be greatly sped up by using some functions from haskell packages. in this case i used primes, which is just installed with 'cabal install primes';) code_removed timings: your original program: code_removed improved implementation code_removed as you can see, this one runs in 38 milliseconds on the same machine where yours ran in 16 seconds:) compilation commands: code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["greatly"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the package code_removed does not export the data constructor code_removed. i guess this was different when lyah was written. using the monadwriter typeclass in ghci instead, you create writers using the code_removed function. for example, in a ghci session i can do code_removed now code_removed is a function that creates writers. i can ask for its type: code_removed which tells me that the inferred type is not a function that returns a particular writer, but rather anything that implements the code_removed type class. i can now use it: code_removed (input actually entered all on one line). here i've specified the type of code_removed to be code_removed. now i can run it: code_removed and you see that we log all of the intermediate operations. why is the code written like this? why bother to create the code_removed type class at all? the reason is to do with monad transformers. as you correctly realised, the simplest way to implement code_removed is as a newtype wrapper on top of a pair: code_removed you can declare a monad instance for this, and then write the function code_removed which simply logs its input. now suppose you want a monad that has logging capabilities, but also does something else - say it can read from an environment too. you'd implement this as code_removed now because the writer is inside the code_removed monad transformer, if you want to log output you can't use code_removed (because that only operates with unwrapped writers) but you have to use code_removed, which \"lifts\" the code_removed function through the code_removed so that it can access the inner writer monad. if you wanted two layers transformers (say you wanted to add error handling as well) then you'd need to use code_removed. this quickly gets unwieldy. instead, by defining a type class we can make any monad transformer wrapper around a writer into an instance of writer itself. for example, code_removed that is, if code_removed is a monoid, and code_removed is a code_removed, then code_removed is also a code_removed. this means that we can use the code_removed function directly on the transformed monad, without having to bother with explicitly lifting it through the monad transformer.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["log"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "my question is, is it possible to have a functional approach to gui programming? the key words you are looking for are \"functional reactive programming\" (frp). conal elliott and some others have made a bit of a cottage industry out of trying to find the right abstraction for frp. there are several implementations of frp concepts in haskell. you might consider starting with conal's most recent \"push-pull functional reactive programming\" paper, but there are several other (older) implementations, some linked from the haskell.org site. conal has a knack for covering the entire domain, and his paper can be read without reference to what came before. to get a feel for how this approach can be used for gui development, you might want to look at fudgets, which while it is getting a bit long in the tooth these days, being designed in the mid 90s, does present a solid frp approach to gui design.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["entire"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "an enlightenment is a realization that culminates only from all of a set of micro-skills being attainedthere are lots of disciplines/areas of human knowledge and culture where most of the micro-skills have inherent rewards for learning them.when faced with someone starting on the path to an enlightenment, who asks you to simply summarize the path for them, there's no way to actually usefully tell them.i think that has to do more with not being motivated enough to try hard enough combined with the difficulty of summarizing. it's one thing to try to explain a paradigm-shifting insight or system to someone who has never paradigm shifted to learn something. the thing about haskell outreach, are such failures even in the face of an audience who has previously undergone such a paradigm shift.you don't make the joke to be snarky. you make the joke because you wish that, this time, it would work, and the learner would skip the path and achieve the enlightenmenthow is this different from laziness? smalltalkers similarly gave up trying to convey how their environment was different, many of them with such snarky jokes. then years later, chris granger comes along with light table, and transmits what it is quite clearly and succinctly.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["inherent"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "sorry, i don't really know my math, so i'm curious how to pronounce the functions in the applicative typeclass knowing your math, or not, is largely irrelevant here, i think. as you're probably aware, haskell borrows a few bits of terminology from various fields of abstract math, most notably category theory, from whence we get functors and monads. the use of these terms in haskell diverges somewhat from the formal mathematical definitions, but they're usually close enough to be good descriptive terms anyway. the code_removed type class sits somewhere between code_removed and code_removed, so one would expect it to have a similar mathematical basis. the documentation for the code_removed module begins with: this module describes a structure intermediate between a functor and a monad: it provides pure expressions and sequencing, but no binding. (technically, a strong lax monoidal functor.) hmm. code_removed not quite as catchy as code_removed, i think. what all this basically boils down to is that code_removed doesn't correspond to any concept that's particularly interesting mathematically, so there's no ready-made terms lying around that capture the way it's used in haskell. so, set the math aside for now. if we want to know what to call code_removed it might help to know what it basically means. so what's up with code_removed, anyway, and why do we call it that? what code_removed amounts to in practice is a way to lift arbitrary functions into a code_removed. consider the combination of code_removed (arguably the simplest non-trivial code_removed) and code_removed (likewise the simplest non-trivial data type). code_removed the function code_removed lets us lift code_removed from working on code_removed to working on code_removed. but what if we want to lift code_removed? code_removed well, that's not what we want at all! in fact, it's pretty much useless. we can try to be clever and sneak another code_removed into code_removed through the back... code_removed ...but that's no good. for one thing, it's wrong. for another thing, it's ugly. we could keep trying, but it turns out that there's no way to lift a function of multiple arguments to work on an arbitrary code_removed. annoying! on the other hand, we could do it easily if we used code_removed's code_removed instance: code_removed now, that's a lot of hassle just to translate a simple function--which is why code_removed provides a function to do it automatically, code_removed. the 2 in its name refers to the fact that it works on functions of exactly two arguments; similar functions exist for 3, 4, and 5 argument functions. these functions are better, but not perfect, and specifying the number of arguments is ugly and clumsy. which brings us to the paper that introduced the applicative type class. in it, the authors make essentially two observations: lifting multi-argument functions into a code_removed is a very natural thing to do doing so doesn't require the full capabilities of a code_removed normal function application is written by simple juxtaposition of terms, so to make \"lifted application\" as simple and natural as possible, the paper introduces infix operators to stand in for application, lifted into the code_removed, and a type class to provide what's needed for that. all of which brings us to the following point: code_removed simply represents function application--so why pronounce it any differently than you do the whitespace \"juxtaposition operator\"? but if that's not very satisfying, we can observe that the code_removed module also provides a function that does the same thing for monads: code_removed where code_removed is, of course, short for \"apply\". since any code_removed can be code_removed, and code_removed needs only the subset of features present in the latter, we can perhaps say that if code_removed weren't an operator, it should be called code_removed. we can also approach things from the other direction. the code_removed lifting operation is called code_removed because it's a generalization of the code_removed operation on lists. what sort of function on lists would work like code_removed? there's what code_removed does on lists, of course, but that's not particularly useful on its own. in fact, there's a perhaps more natural interpretation for lists. what comes to mind when you look at the following type signature? code_removed there's something just so tempting about the idea of lining the lists up in parallel, applying each function in the first to the corresponding element of the second. unfortunately for our old friend code_removed, this simple operation violates the monad laws if the lists are of different lengths. but it makes a fine code_removed, in which case code_removed becomes a way of stringing together a generalized version of code_removed, so perhaps we can imagine calling it code_removed? this zipping idea actually brings us full circle. recall that math stuff earlier, about monoidal functors? as the name suggests, these are a way of combining the structure of monoids and functors, both of which are familiar haskell type classes: code_removed what would these look like if you put them in a box together and shook it up a bit? from code_removed we'll keep the idea of a structure independent of its type parameter, and from code_removed we'll keep the overall form of the functions: code_removed we don't want to assume that there's a way to create an truly \"empty\" code_removed, and we can't conjure up a value of an arbitrary type, so we'll fix the type of code_removed as code_removed. we also don't want to force code_removed to need a consistent type parameter, so now we have this: code_removed what's the result type for code_removed? we have two arbitrary types we know nothing about, so we don't have many options. the most sensible thing is to just keep both: code_removed at which point code_removed is now clearly a generalized version of code_removed on lists, and we can reconstruct code_removed easily: code_removed this also shows us that code_removed is related to the identity element of a code_removed, so other good names for it might be anything suggesting a unit value, a null operation, or such. that was lengthy, so to summarize: code_removed is just a modified function application, so you can either read it as \"ap\" or \"apply\", or elide it entirely the way you would normal function application. code_removed also roughly generalizes code_removed on lists, so you can read it as \"zip functors with\", similarly to reading code_removed as \"map a functor with\". the first is closer to the intent of the code_removed type class--as the name suggests--so that's what i recommend. in fact, i encourage liberal use, and non-pronunciation, of all lifted application operators: code_removed, which lifts a single-argument function into a code_removed code_removed, which chains a multi-argument function through an code_removed code_removed, which binds a function that enters a code_removed onto an existing computation all three are, at heart, just regular function application, spiced up a little bit.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["full"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "thanks. that's a really excellent way to describe things, probably the best comment on this thread.there's always a tradeoff between how much intelligence you put into a runtime vs how much you have to ship with the app. in the limit wasm would turn into \"download and run an entire language runtime with every web page\", which is clearly suboptimal. most likely compilation to js will continue for the forseeable future when possible for that reason.one idea that could probably work very well is to write a wasm interpreter for graalvm. graalvm has very high level constructs but can also support low level manually memory managed code. they have one for llvm bitcode already, but wasm would probably be simpler to implement and with a more stable bytecode format. then c/rust/exceptionless c++ could ship artifacts as wasm files, scripting languages can ship source code, static managed languages like java or haskell (eta) can ship jars, and they can all interoperate and be compiled together.i don't see a route to getting there with current wasm runtimes or just the existing featureset of wasm though. as a portable isa for distribution of limited, os neutral c-ish libraries it seems reasonable enough. as a future vm for everything i can't see them beating graalvm anytime soon. graalvm has the shared high level constructs, but it is able to also (eventually) compile low level wasm/llvm style code down to what a typical gcc like compiler would create.", "aspectos": {"AvailabilityAndScalability": ["always"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["manually"]}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@richardc nowhere mentioned that erlang is faster:) it has different goals, not speed!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["not"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> where do i do that?\"i assume 'diversity of thought' refers to expressed thoughts...\"> first, i am struggling over how to identify 'diversity of thought' during the interview process.i think we've covered this pretty well, so your struggle isn't over the \"how\" - but the \"why\".> is it something different than \"can come up with innovative solutions\" or \"out of the box thinking\" or \"creative problem solver\"?it is no different, with one exception: it is measured in relation to your existing organization. if all your programmers are proponents of the functional programming paradigm, hiring another haskell programmer, while relatively novel to the rest of the industry - likely does little to increase your organizations diversity in thinking (without additional screening parameters).> these seem like two different interpretations of that phrase...they are: one is selecting for proxies, presumably as a shortcut. the other is directly addressing what is desired. i'm always amazed at how proponents for such selection mechanisms are totally oblivious to how ridiculously prejudice it is.>...i lean towards ubernostrum's down-voted comment that \"diversity of thought\" seems often used as a euphemism for \"put up with assholes\" (my interpretation).clearly.> which means you end up biased towards rules lawyers. which may be what you want, but bear in mind that you are presenting one performance goal while you have withheld a secret goal that you are actually looking for.boom, point proven. you have at that point learned something about that candidate's way of thinking, select on it or don't. if that was a hidden goal then it worked, if it wasn't then disregard.> here's a less secret goal: the test is meant to see if you know what modern c++ is like...not a diversity of thought test.>...and if you have a good idea of what the posix mindset is like (so you don't end up asking pointless rules-lawyer questions).that is a diversity of thought test. is the candidate willing to, in the face of ambiguity, insert his own opinion instead of speaking up?> which of these possible secret goals should the interviewee try to optimize?as i said earlier: the one that, in your experience, indicates an ability to do the task that the candidate is hired for. should there be a tie, the one that arrived at a solution that you did not anticipate. and no, that doesn't mean you should hire a guy who insists on sorting files using node.js, just because he was the only one... you can't determine rationale based only on language selection. if he does it in shell script, ask why. you may learn that binary compatibility concerns are higher on his priority list due to some past experience that you wouldn't have considered.>...the essential problem remains - does \"diversity of thought\" differ from \"highly competent and creative problem solver\"?yes, but first i'll point out that \"highly competent\" is an unrelated concept. because effectively nobody has unbounded useful creativity over an entire problem domain, you want to select individuals who's constraints overlap as little as possible - thereby covering more of the problem domain. personal example: i took over a database from the engineering department because the guy maintaining it retired. i was horrified when i looked inside, the architect was obviously a plc programmer - using triggers and views to form a hellish logic ladder. i was trying to figure out how i'd be able to untangle everything into a more tradition normalized database when i got a request from one of the engineers to insert a new trigger to account for some upcoming process change, i told him how much i didn't want to do that and asked if i could spend a day with him in order to get a better grasp on their problem domain - he was annoyed, but agreed. well it turns out the old engineer wasn't totally insane, the problem domain was pretty much unbounded and constantly changing: new metrics, new datatypes, new requirements - totally normal for their department. whereas i would have used a domain-key normal form in that situation, he just created a new table and added a trigger. both styles work, each has different weaknesses and strengths. neither of us would have arrived at the other's solution. diversity of thought.> in my description, the first argument is a filename. the contents of the file are a set of lines, terminated by a n.lol, even your attempt at clarification adds confusion. the ambiguity this time: is the set of lines terminated by n, or is each line in the set terminated by n, or is the file terminated by n? yes, i'm pretty confident that i know what you mean - but i have seen 0x1f used for stuff like this in production, bad things would have happened had i just made an assumption.> otherwise the desire to sort the contents makes no sense.sure it does: if instead of interpreting the explicit mention of ' n' to mean line termination within the file, one interpreted it as the termination of the first parameter. again, one can guess the intent due to convention - but it is ambiguously phrased and immediately led to two competing possibilities of intent in my mind. maybe that is because i think differently from you...", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["new", "totally normal"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["entire", "more", "much unbounded"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "> where do i do that?\"i assume 'diversity of thought' refers to expressed thoughts...\"> first, i am struggling over how to identify 'diversity of thought' during the interview process.i think we've covered this pretty well, so your struggle isn't over the \"how\" - but the \"why\".> is it something different than \"can come up with innovative solutions\" or \"out of the box thinking\" or \"creative problem solver\"?it is no different, with one exception: it is measured in relation to your existing organization. if all your programmers are proponents of the functional programming paradigm, hiring another haskell programmer, while relatively novel to the rest of the industry - likely does little to increase your organizations diversity in thinking (without additional screening parameters).> these seem like two different interpretations of that phrase...they are: one is selecting for proxies, presumably as a shortcut. the other is directly addressing what is desired. i'm always amazed at how proponents for such selection mechanisms are totally oblivious to how ridiculously prejudice it is.>...i lean towards ubernostrum's down-voted comment that \"diversity of thought\" seems often used as a euphemism for \"put up with assholes\" (my interpretation).clearly.> which means you end up biased towards rules lawyers. which may be what you want, but bear in mind that you are presenting one performance goal while you have withheld a secret goal that you are actually looking for.boom, point proven. you have at that point learned something about that candidate's way of thinking, select on it or don't. if that was a hidden goal then it worked, if it wasn't then disregard.> here's a less secret goal: the test is meant to see if you know what modern c++ is like...not a diversity of thought test.>...and if you have a good idea of what the posix mindset is like (so you don't end up asking pointless rules-lawyer questions).that is a diversity of thought test. is the candidate willing to, in the face of ambiguity, insert his own opinion instead of speaking up?> which of these possible secret goals should the interviewee try to optimize?as i said earlier: the one that, in your experience, indicates an ability to do the task that the candidate is hired for. should there be a tie, the one that arrived at a solution that you did not anticipate. and no, that doesn't mean you should hire a guy who insists on sorting files using node.js, just because he was the only one... you can't determine rationale based only on language selection. if he does it in shell script, ask why. you may learn that binary compatibility concerns are higher on his priority list due to some past experience that you wouldn't have considered.>...the essential problem remains - does \"diversity of thought\" differ from \"highly competent and creative problem solver\"?yes, but first i'll point out that \"highly competent\" is an unrelated concept. because effectively nobody has unbounded useful creativity over an entire problem domain, you want to select individuals who's constraints overlap as little as possible - thereby covering more of the problem domain. personal example: i took over a database from the engineering department because the guy maintaining it retired. i was horrified when i looked inside, the architect was obviously a plc programmer - using triggers and views to form a hellish logic ladder. i was trying to figure out how i'd be able to untangle everything into a more tradition normalized database when i got a request from one of the engineers to insert a new trigger to account for some upcoming process change, i told him how much i didn't want to do that and asked if i could spend a day with him in order to get a better grasp on their problem domain - he was annoyed, but agreed. well it turns out the old engineer wasn't totally insane, the problem domain was pretty much unbounded and constantly changing: new metrics, new datatypes, new requirements - totally normal for their department. whereas i would have used a domain-key normal form in that situation, he just created a new table and added a trigger. both styles work, each has different weaknesses and strengths. neither of us would have arrived at the other's solution. diversity of thought.> in my description, the first argument is a filename. the contents of the file are a set of lines, terminated by a n.lol, even your attempt at clarification adds confusion. the ambiguity this time: is the set of lines terminated by n, or is each line in the set terminated by n, or is the file terminated by n? yes, i'm pretty confident that i know what you mean - but i have seen 0x1f used for stuff like this in production, bad things would have happened had i just made an assumption.> otherwise the desire to sort the contents makes no sense.sure it does: if instead of interpreting the explicit mention of ' n' to mean line termination within the file, one interpreted it as the termination of the first parameter. again, one can guess the intent due to convention - but it is ambiguously phrased and immediately led to two competing possibilities of intent in my mind. maybe that is because i think differently from you...", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["new", "totally normal"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["entire", "more", "much unbounded"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i think this one is a little bit opinion-based. but i will try to answer. i agree with dietrich epp: it's a combination of several things that make ghc fast. first and foremost, haskell is very high-level. this enables the compiler to perform aggressive optimisations without breaking your code. think about sql. now, when i write a code_removed statement, it might look like an imperative loop, but it isn't. it might look like it loops over all rows in that table trying to find the one that matches the specified conditions, but actually the \"compiler\" (the db engine) could be doing an index lookup instead \u2014 which has completely different performance characteristics. but because sql is so high-level, the \"compiler\" can substitute totally different algorithms, apply multiple processors or i/o channels or entire servers transparently, and more. i think of haskell as being the same. you might think you just asked haskell to map the input list to a second list, filter the second list into a third list, and then count how many items resulted. but you didn't see ghc apply stream-fusion rewrite rules behind the scenes, transforming the entire thing into a single tight machine code loop that does the whole job in a single pass over the data with no allocation \u2014 the kind of thing that would be tedious, error-prone and non-maintainable to write by hand. that's only really possible because of the lack of low-level details in the code. another way to look at it might be\u2026 why shouldn't haskell be fast? what does it do that should make it slow? it's not an interpreted language like perl or javascript. it's not even a virtual machine system like java or c#. it compiles all the way down to native machine code, so no overhead there. unlike oo languages [java, c#, javascript\u2026], haskell has full type erasure [like c, c++, pascal\u2026]. all type checking happens at compile-time only. so there's no run-time type-checking to slow you down either. (no null-pointer checks, for that matter. in, say, java, the jvm must check for null pointers and throw an exception if you deference one. haskell doesn't have to bother with that check.) you say it sounds slow to \"create functions on the fly at run-time\", but if you look very carefully, you don't actually do that. it might look like you do, but you don't. if you say code_removed, well, that's hard-coded into your source code. it cannot change at run-time. so it's not really a dynamic function. even curried functions are really just saving parameters into a data block. all the executable code actually exists at compile-time; there is no run-time interpretation. (unlike some other languages that have an \"eval function\".) think about pascal. it's old and nobody really uses it any more, but nobody would complain that pascal is slow. there are plenty of things to dislike about it, but slowness is not really one of them. haskell isn't really doing that much that's different to pascal, other than having garbage collection rather than manual memory management. and immutable data allows several optimisations to the gc engine [which lazy evaluation then complicates somewhat]. i think the thing is that haskell looks advanced and sophisticated and high-level, and everybody thinks \"oh wow, this is really powerful, it must be amazingly slow!\" but it isn't. or at least, it isn't in the way you'd expect. yes, it's got an amazing type system. but you know what? that all happens at compile-time. by run-time, it's gone. yes, it allows you to construct complicated adts with a line of code. but you know what? an adt is just a plain ordinary c code_removed of code_removeds. nothing more. the real killer is lazy evaluation. when you get the strictness / laziness of your code right, you can write stupidly fast code that is still elegant and beautiful. but if you get this stuff wrong, your program goes thousands of times slower, and it's really non-obvious why this is happening. for example, i wrote a trivial little program to count how many times each byte appears in a file. for a 25kb input file, the program took 20 minutes to run and swallowed 6 gigabytes of ram! that's absurd!! but then i realized what the problem was, added a single bang-pattern, and the run-time dropped to 0.02 seconds. this is where haskell goes unexpectedly slowly. and it sure takes a while to get used to it. but over time, it gets easier to write really fast code. what makes haskell so fast? purity. static types. laziness. but above all, being sufficiently high-level that the compiler can radically change the implementation without breaking your code's expectations. but i guess that's just my opinion\u2026", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["aggressive", "several"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "thanks! perhaps the question should be the speed of compiled output by various compilers rather than the actual language itself. then again, pulling out the intel manuals and optimising by hand will still win outright (provided you have the knowledge and the time (a lot of)).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["perhaps"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in mysticial's answer. now, if we look at the code code_removed we can find that the meaning of this particular code_removed branch is to add something when a condition is satisfied. this type of branch can be easily transformed into a conditional move statement, which would be compiled into a conditional move instruction: code_removed, in an code_removed system. the branch and thus the potential branch prediction penalty is removed. in code_removed, thus code_removed, the statement, which would compile directly (without any optimization) into the conditional move instruction in code_removed, is the ternary operator code_removed. so we rewrite the above statement into an equivalent one: code_removed while maintaining readability, we can check the speedup factor. on an intel core i7-2600k @ 3.4\u00a0ghz and visual studio 2010 release mode, the benchmark is (format copied from mysticial): x86 code_removed x64 code_removed the result is robust in multiple tests. we get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. in fact, when using a conditional move, the performance is the same regardless of the data pattern. now let's look more closely by investigating the code_removed assembly they generate. for simplicity, we use two functions code_removed and code_removed. code_removed uses the conditional branch code_removed: code_removed code_removed uses the ternary operator code_removed: code_removed on a x86-64 machine, code_removed generates the assembly below. code_removed code_removed uses much less code due to the usage of instruction code_removed. but the real gain is that code_removed does not involve branch jumps, code_removed, which would have a significant performance penalty if the predicted result is not right. so why does a conditional move perform better? in a typical code_removed processor, the execution of an instruction is divided into several stages. roughly, we have different hardware to deal with different stages. so we do not have to wait for one instruction to finish to start a new one. this is called pipelining. in a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. we have to either wait or predict. in a conditional move case, the execution conditional move instruction is divided into several stages, but the earlier stages like code_removed and code_removed does not depend on the result of the previous instruction; only latter stages need the result. thus, we wait a fraction of one instruction's execution time. this is why the conditional move version is slower than the branch when prediction is easy. the book computer systems: a programmer's perspective, second edition explains this in detail. you can check section 3.6.6 for conditional move instructions, entire chapter 4 for processor architecture, and section 5.11.2 for a special treatment for branch prediction and misprediction penalties. sometimes, some modern compilers can optimize our code to assembly with better performance, sometimes some compilers can't (the code in question is using visual studio's native compiler). knowing the performance difference between branch and conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["regardless same", "good", "good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "hm, this answer doesn't seem to focus on lazyness. the op already knows that he can choose which terms to expand (and probably also knows why/that the order doesn't make a difference for the result). now, what is lazyness? it's not throwing a dice, or the compiler finding an optimisation. it's a specific strategy.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["specific"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i would also like to stress some of the practical features of haskell, despite its mere beauty: gets in your way exactly where it should, and keeps out of your way otherwise. that's one of the interesting features, which is responsible for why haskell just works. has a great concurrency system, which is ready for high performance applications. provides the basis for new, innovative abstractions and design patterns, among them my personal favorite, functional reactive programming. makes even very complicated problems easy to tackle, because a lot of the things, which you need to think about in other languages (proper sequencing, locking, initialization, etc.), are much less of an issue in haskell. laziness is not simply an optimization. it allows you to solve problems in entirely new ways, which are much easier on the brain. no destructive updates, yet the same result with about the same performance. if you have the choice, i totally recommend learning haskell over any other language. it seems to make the optimal tradeoff between safety, level of abstractness and practicality among the existing languages.", "aspectos": {"AvailabilityAndScalability": ["optimal"], "Maintainability": [], "Performance": ["same"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i don't think code_removed should be seen as a particularly outstanding monad, but it's certainly one of the more astounding ones for beginners, so i'll use it for my explanation. na\u00efvely building an io system for haskell the simplest conceivable io system for a purely-functional language (and in fact the one haskell started out with) is this: code_removed with lazyness, that simple signature is enough to actually build interactive terminal programs \u2013 very limited, though. most frustrating is that we can only output text. what if we added some more exciting output possibilities? code_removed cute, but of course a much more realistic \u201calterative output\u201d would be writing to a file. but then you'd also want some way to read from files. any chance? well, when we take our code_removed program and simply pipe a file to the process (using operating system facilities), we have essentially implemented file-reading. if we could trigger that file-reading from within the haskell language... code_removed this would use an \u201cinteractive program\u201d code_removed, feed it a string obtained from a file, and yield a non-interactive program that simply executes the given one. there's one problem here: we don't really have a notion of when the file is read. the code_removed list sure gives a nice order to the outputs, but we don't get an order for when the inputs will be done. solution: make input-events also items in the list of things to do. code_removed ok, now you may spot an imbalance: you can read a file and make output dependent on it, but you can't use the file contents to decide to e.g. also read another file. obvious solution: make the result of the input-events also something of type code_removed, not just code_removed. that sure includes simple text output, but also allows reading additional files etc.. code_removed that would now actually allow you to express any file operation you might want in a program (though perhaps not with good performance), but it's somewhat overcomplicated: code_removed yields a whole list of actions. why don't we simply use the signature code_removed, which has this as a special case? the lists don't really give a reliable overview of program flow anymore: most subsequent computations will only be \u201cannounced\u201d as the result of some input operation. so we might as well ditch the list structure, and simply cons a \u201cand then do\u201d to each output operation. code_removed not too bad! so what has all of this to do with monads? in practice, you wouldn't want to use plain constructors to define all your programs. there would need to be a good couple of such fundamental constructors, yet for most higher-level stuff we would like to write a function with some nice high-level signature. it turns out most of these would look quite similar: accept some kind of meaningfully-typed value, and yield an io action as the result. code_removed there's evidently a pattern here, and we'd better write it as code_removed now that starts to look familiar, but we're still only dealing with thinly-disguised plain functions under the hood, and that's risky: each \u201cvalue-action\u201d has the responsibility of actually passing on the resulting action of any contained function (else the control flow of the entire program is easily disrupted by one ill-behaved action in the middle). we'd better make that requirement explicit. well, it turns out those are the monad laws, though i'm not sure we can really formulate them without the standard bind/join operators. at any rate, we've now reached a formulation of io that has a proper monad instance: code_removed obviously this is not an efficient implementation of io, but it's in principle usable.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "stevebmark's comment got me thinking about ui technology in general and computer science.the thing about ui... it's just, plain, _hard_.there's not much more to it then that. \"ui is hard\". user interfaces, no matter if they're text based or graphical, are perhaps the most frustrating field of computer science. they look simple. \"oh, this is just a bunch of boxes and text. i can bang that out in an hour!\" three weeks later. sound familiar? it's that illusion of simplicity that drives programmers crazy. ui has, as far as i can tell, the highest ratio of perceived simplicity to actual difficulty of any other computer science field.so here we are. we have several decades worth of computer science under our collective belts. over the plethora of decades that our field has existed we've: invented the transistor, made it the size of a handful of atoms, flew to the moon and back, beat humans at chess and go, can make video calls half way around the planet, and have crammed unthinkable amounts of technology into our pockets in the form of smart phones. my house bends to my very _voice_ thanks to modern computer science.but in all that time... ui is still hard.i don't think a lot of programmers stop to think about that. maybe, just maybe, all this thrashing about with ui libraries has more to do with the fact that ui, as a computer science problem, is perhaps one of the most complicated, impenetrable problems we've come across. the perceived simplicity of the problem so often blinds us to that fact.i believe it stems from a shared \"ancestor\" with multi-threading: concurrency. every programmer knows and fears the problem of multi-threading, but they don't fear ui in the same way. yet, these two problems are more alike than not. a ui is a system that is filled with concurrent, unpredictable, events and threads that could happen in any order. that's a multi-threaded system.so it's no surprise when viewed like this that ui is hard. it's very difficult for us to reason about a multi-threaded system. even the best engineers in the world make \"obvious\" (in hindsight) mistakes when they build concurrent systems. look at all the bugs that pop up when researchers attempt to do formal verification of concurrent primitives implementations.so if it's impossible for us to reason about ui, as a concurrent system, then what do we do?my time spent with rust, the programming language, has given me some theories. rust is most popularly known for its memory safety, but its true power lies in its type system. rust is the first language i've encountered to expose to the user an advanced type system in a practical way. languages like haskell et al have of course had these advanced type systems for _decades_. but rust offers them in a way that is digestible and ergonomic. for us common folk at least. it's perhaps the first chance that we as an industry will have at a widely used programming language with advanced typing and static analysis.that advanced typing system is what gives rust its true power. most salient to this discussion is its usage of the traits send and sync. these two traits allow us to communicate to other engineers and the compiler that \"this type is safe in these concurrent scenarios.\" suddenly the frightening world of concurrency blows apart. instead of being afraid, you can be fearless. write whatever code you want and then the compiler will check it and prove (in a limited sense) that your program is correct and safe.it's an incredible shift for programmers to have this power. send and sync are a small step in a new direction: being able to leverage static analysis by the compiler to assist programmers in designing their systems. before, in e.g. c, it was up to the programmer to think about all the state of their program in their head. at best we suck at that, especially in complex scenarios like concurrent systems (and ui!).now we have tools that can augment our mental facilities. in the same way you don't have to think as hard about memory in rust as you do in its ancestors, you don't have to think as hard about concurrent systems because the compiler and the libraries and types we build alleviate the number of problems we need to think about.i believe that it's possible this road that is leading to a brighter story for concurrent programming is also leading to a brighter story for ui. rather then having to think about _all_ the states that a ui and its backing state machines can be in, we instead build type systems that allow us to describe how we believe the system should look in our heads. and then the compiler will do the dirty work of proving our assumptions correct. our compilers will be 1000x better then us at considering an exponential number of states that a ui could be in given its concurrent and unpredictable nature.so just imagine a ui framework built on top of an advanced typing system. we could do insane things like using the typing system to say that certain view elements should only be visible given certain states in our model. for example, the logout view should never be visible when the user isn't in the loggedin state. and the advanced typing system, combined with the compiler's static analysis, checks all of our state machines to prove that logout will never be visible unless the loggedin state is active.it's crazy, right? but i think it's possible. just like rust's lifetime analysis can prove when certain objects will be alive so that the borrow checker can check all your references are alive and safe. i don't think it's so crazy to imagine a future where the compiler can determine the lifetimes of a view and make sure they aren't referenced in certain states.anyway, the most important thing i wanted to communicate is that ui is hard. really hard. and we shouldn't forget that. we should approach ui with the same caution and respect that we do multi-threaded programming. perhaps with that mindset less programmers will fall into the trap of frustration. that trap that has led so many to believe that it is our libraries and frameworks that are broken, and to go off and build yet-another-framework in the vain attempt to \"solve\" ui without making any real attempts to innovate on the core computer science problem that is ui.p.s. i'm not terribly good at communicating the strength of rust's type system and underlying compiler. there's just something magical about rust that makes it easy to write an api where a) it's obvious to users how to use it, and b) it's a compiler error to use it wrong. it's not any one thing and it's easy to compare rust to other languages. so i'm not people will reply with \"but language x has feature y just like rust; how dare you argue that rust is some kind of revolution!\" oh well.i'm also sure some will come along and take issue with my assertion that rust makes memory management easier. rust makes memory management easier only if you take the time to consider the full story. that is to say, it's quite easy to manage memory efficiently in, say, c. but to do it _without_ bugs? it takes _decades_ to write a c program with no memory bugs. yet i can write the same program in rust and the compiler will _ensure_ memory is managed correctly. (within certain limits, it's possible to leak memory, etc, etc.)", "aspectos": {"AvailabilityAndScalability": ["perceive", "perceive"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["formal"], "Interoperability": ["efficiently", "correctly"]}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 0, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": 1}}, {"comentario": "i'm facing a related situation right now designing a merge api for code_removed. the \"open\" approach is preferable in some ways. for one thing, i can implement it without gadts and therefore maintain compatibility with report haskell. for another, i don't need huge case analyses everywhere. but it's unpleasant in some other ways; in particular, it's much harder for me to take advantage of what i know about the behavior of values constructed in particular manners to optimize things.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["particular"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i don't see your reasoning here. how exactly will immutable data structures increase the big-oh complexity? i'm not aware of any sorting algorithm faster than o(n log(n)) in the average case.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["how exactly"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the simple answer is no. the more complex answer is that the computational model upon which haskell builds up and evaluates functions works in a lazy manner. as you will read in other answer there are ways to force evaluation of some functions earlier then normal, and it is occasionally adventitious to do so. but there is a large portion of valid haskell which has no normal form. this includes the io functions and a large amount of the standard prelude. conclusion: there is no more a way to turn of lazy evaluation in haskell then there is a way to turn off pointer arithmetic in c or to turn off oo in ruby of java. i suspect that this is much farther then you though this question would take you. (there's no code_removed mode), but if you really want to see just how deep the rabit hole goes, \"implementing lazy functional languages on stock hardware: the spineless tagless g-machine\" by simon peyton jones is an adventure worth having.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["lazy"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "in haskell? i'd construct an api that could be used like the following. this looks like the code we write at the place i work at:code_removed the signatures of socket, bind, etc, would look like (for example):code_removed then, at top levelcode_removed the key here is that error handling is factored out. the 'runservice' function expresses concisely all the steps taken, and the entire concern of error handling is factored out into the 'handleerror' function, whose behavior i can actually change based on what i may want. in a c implementation, changing error handling strategies, would mean passing some kind of flag in (you could rebuild exceptions using setjmp/longjmp, but meh).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["change"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "under what circumstances their benefits justify their complexity every language has strict (classical) io, where all resources are managed by the user. haskell also provides ubiquitous lazy io, where all resource management is delegated to the system. however, that can create problems, as the scope of resources is dependent on runtime demand properties. iteratees strike a third way: high level abstractions, like lazy io. explicit, lexical scoping of resources, like strict io. it is justified when you have complex io processing tasks, but very tight bounds on resource use. an example is a web server. indeed, snap is built around iteratee io on top of epoll.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["where"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "it is a completely wrong-headed perspective. monads are just an abstraction, they do not \"turn the language\" into anything; code that uses monads is normal haskell code evaluated with the same lazy strategy as all haskell code.haskell also does not need monads to do io as the author suggests. if you made monads impossible to express (as first class concepts) in haskell, say by blasting hkts out of the language, you would still do io the same way, just with concrete functions instead one's parameterized over an arbitrary monad. if you made haskell strict, you would still do io the same way (as an unrelated note though, i believe you would need to add an unbounded looping combinator uloop: (a -> io (a, bool)) -> a -> io a)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["same", "lazy"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "i am still new to monads, but i thought i would share a link i found that felt really good to read (with pictures!!): (no affiliation) basically, the warm and fuzzy concept that i got from the article was the concept that monads are basically adapters that allow disparate functions to work in a composable fashion, i.e. be able to string up multiple functions and mix and match them without worrying about inconsistent return types and such. so the bind function is in charge of keeping apples with apples and oranges with oranges when we're trying to make these adapters. and the lift function is in charge of taking \"lower level\" functions and \"upgrading\" them to work with bind functions and be composable as well. i hope i got it right, and more importantly, hope that the article has a valid view on monads. if nothing else, this article helped whet my appetite for learning more about monads.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["composable"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "if yes, then how can it exist? does it not violate the principle of functional programming? it particularly violates referential transparency it does not exist in a purely functional sense. or if no, then how can one know the current time in functional programming? it may first be useful to know how a time is retrieved on a computer. essentially there is onboard circuitry that keeps track of the time (which is the reason a computer would usually need a small cell battery). then there might be some internal process that sets the value of time at a certain memory register. which essentially boils down to a value that can be retrieved by the cpu. for haskell, there is a concept of an 'io action' which represents a type that can be made to carry out some io process. so instead of referencing a code_removed value we reference a code_removed value. all this would be purely functional. we aren't referencing code_removed but something along the lines of 'read the value of the time register'. when we actually execute the haskell program, the io action would actually take place.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the correct answer to this question is the third in thomas m. dubuisson's response. you are saying that you don't want to use the type integer, to which the response is, get another type -- or rather you're saying that, as you get clear on the function you propose to define, you see that the range of its significance is not 'integer', but something else which, as it happens, is readily captured in haskell. any mention of dependent typing in response to this question is a distraction and a demonstrable pedagogical disaster; it impedes the correct apprehension of the idea of a type.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["demonstrable", "pedagogical"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "using other exceptions than 'error' in the reciprocal function is what i consider bad usage of exceptions. the function should never be called with that value and the program should never try to catch exceptions from it, if so there is a logical flaw in our program. i prefer to kill the program in such cases with 'error', to detect the bug. if the bug is handled silently with exception handling, it might cause other bugs later.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["logical"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@evusas i'm not a hardware designer, so i don't know the answer for sure. but the rollback logic certainly isn't free. even if the cpu designers managed to completely hide the performance impact of a misprediction roll-back, there are still costs in terms of power consumption of the wasted computation. today's chips are very power optimized and will vary their clock speeds to stay under a power limit. so it's certainly within the realm of possibility that excessive waste of power from mispredictions can indirectly hurt performance.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["even"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i'd like to address a few of the points dflemstr brings up. i don't find the fact that you can't typecheck th to be that worrying. why? because even if there is an error, it will still be compile time. i'm not sure if this strengthens my argument, but this is similar in spirit to the errors that you receive when using templates in c++. i think these errors are more understandable than c++'s errors though, as you'll get a pretty printed version of the generated code. if a th expression / quasi-quoter does something that's so advanced that tricky corners can hide, then perhaps it's ill-advised? i break this rule quite a bit with quasi-quoters i've been working on lately (using haskell-src-exts / meta) - i know this introduces some bugs such as not being able to splice in the generalized list comprehensions. however, i think that there's a good chance that some of the ideas in will end up in the compiler. until then, the libraries for parsing haskell to th trees are a nearly perfect approximation. regarding compilation speed / dependencies, we can use the \"zeroth\" package to inline the generated code. this is at least nice for the users of a given library, but we can't do much better for the case of editing the library. can th dependencies bloat generated binaries? i thought it left out everything that's not referenced by the compiled code. the staging restriction / splitting of compilation steps of the haskell module does suck. re opacity: this is the same for any library function you call. you have no control over what data.list.groupby will do. you just have a reasonable \"guarantee\" / convention that the version numbers tell you something about the compatibility. it is somewhat of a different matter of change when. this is where using zeroth pays off - you're already versioning the generated files - so you'll always know when the form of the generated code has changed. looking at the diffs might be a bit gnarly, though, for large amounts of generated code, so that's one place where a better developer interface would be handy. re monolithism: you can certainly post-process the results of a th expression, using your own compile-time code. it wouldn't be very much code to filter on top-level declaration type / name. heck, you could imagine writing a function that does this generically. for modifying / de-monolithisizing quasiquoters, you can pattern match on \"quasiquoter\" and extract out the transformations used, or make a new one in terms of the old.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["good", "where handy"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "@krisvandermotten yes, that's correct. what would also help in this case is use the correct data type (e.g. code_removed); that would eliminate the branch completely, which means more speed.:-) basically i always assume that if (1) you're in a tight loop with a limited amount of code (such as here) and (2) if you could predict the branches with 'static code analysis', then the processor / jit'ter will do their work properly.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["more"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@adamfreeman - sorting is relevant here only inasmuch as in this code it increases branch prediction to 100% success.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["only inasmuch"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the big hindrance in getting more optimisations is manpower. there are only a handful of people working on ghc, and they have lots of other things to do. and it's not so easy to make the optimisations general. for the code_removed, you have the problem that you can only replace it with code_removed if code_removed is non-negative, or if you know that you're on a two's complement machine, for code_removed, only if you know code_removed is non-negative. doable, of course, but not a ten-minute-job. eliminating the list is also not as easy for a compiler (must be general) as for the programmer (specific to the situation).", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["more", "general"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "well, it will certainly cause a lot of confusion (and breakage of packages) in the transition period. but the overall consensus was that the gain is greater than the loss (no more spurious code_removed and code_removed instances for things like functions that can have sensible code_removed instances except for the old code_removed and code_removed requirements). the same (mutatis mutandis) applies to the removal of the code_removed superclass from code_removed. fortunately, the breakages are backward-compatibly fixed by adding the constraints.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["great"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "could you precompile a haskell app for os x and various linux architectures into executables for download, or is the apt-get/yum strategy safer?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["apt-get/yum", "safe"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "ghci accept it resulting code_removed. maybe some other compiler read code_removed as floating point and then it's loose for it any sense.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["then"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@user2407038 argh!!! left-most is completely different from outermost! there are 4 \"canonical\" strategies to reduce a redex. they are left-outermost (used by haskell, often called just outermost), right-outermost, left-innermost (used by most eager languages, often called just innermost) and right-innermost. the left/right direction is completely independent from the inner/outer direction. inner/outer is about a redex being inside an other redex, while left/right is only about sibling redexes and their position in the string. so, outermost is definitely not called \"left-most\".", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["canonical"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "addenda (relevant to community musings today):be aware that as a small and very distributed community, the haskell world has less power to eject bad actors than more centrally managed and resourced projects have (e.g., golang and rust have much more structural power to moderate). awful and abusive people exist in the community, and it's best to just start blocking and ignoring folks who disrespect you.the amazing thing about the haskell community is that knowledge is very well distributed throughout the community these days. the culture, influenced by academia, strongly values writing and publishing ideas rather than sharing them orally or in the workplace. this means that if you're interested in learning, there are a ton of places and ways to do it.if you're looking for good initial connections to folks who are respectful, well informed, and unlikely to expose you to some of the frustrating cabals in the community, i've got a few recommendations1. gabriel gonzales (this is his blog, and he's @gabrielg439 on twitter)2. chris martin of typeclasses. i'd also list his partner in crime julie moronuki, but her social media interaction is reduced these days. these two focus on helping programmers get up to speed with haskell from a variety of starting points, and they care more about functional programming than haskell specifics.3. patrick thompson of github (@importantshock on twitter). a fantastically skilled person who will link you to a network of amazing haskell folks who do stuff in a positively next-generational way.two people who are adjacent to the haskell community and incredibly interesting, but probably can't answer direct questions for you. worth a follow.1. dr. edwin brady, creator of the idris language. he's widely respected, humble, and has a beautiful vision for how humans and computers should interact to write programs.2. dr. bodil stokke (@bodil on twitter). bodil is not so much a haskell person these days, but she's got a phenomenal breadth of knowledge and always has interesting things to talk about in the fp space. worth a follow if you're on that platform.i suppose you can ask me for help too, but i'm certainly not as competent as these folks.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["more centrally", "social"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "no doubt some of us would be interested in ways of identifying code that is problematic for the cpu's branch-predictor. the valgrind tool code_removed has a branch-predictor simulator, enabled by using the code_removed flag. running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with code_removed, gives these results: sorted: code_removed unsorted: code_removed drilling down into the line-by-line output produced by code_removed we see for the loop in question: sorted: code_removed unsorted: code_removed this lets you easily identify the problematic line - in the unsorted version the code_removed line is causing 164,050,007 mispredicted conditional branches (code_removed) under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version. alternatively, on linux you can use the performance counters subsystem to accomplish the same task, but with native performance using cpu counters. code_removed sorted: code_removed unsorted: code_removed it can also do source code annotation with dissassembly. code_removed code_removed see the performance tutorial for more details.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["native"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "cyient | full time | onsite (remote for the right candidate) | melbourne, fl; bangalore, india; or hyderabad, india | is a software suite developed by cyient for the design, development, simulation, verification, and validation of safety-critical systems. certsafe features a graphical development environment for a visual modeling language based on dataflow/circuit diagram notation, a simulation engine and interactive testing interface, an automatic test generator based on satisfiability modulo theories (smt) solving, and more.as a member of the certsafe team, you will get to apply your software engineering and computer science knowledge in diverse areas, including programming language theory, graph theory, user interface design, concurrent and parallel software design, and software test automation. you will get to interact on a day-to-day basis with real-world users and customers working on safety-critical applications in aerospace, defense, transportation, medical devices, and other fields.certsafe is developed by a small team with a lean kanban development process. we use a variety of technologies including java, maven, jenkins, python, and aws, and also especially appreciate experience with functional languages such as haskell, f#, ocaml, lisp, etc.positions available include software engineer, software quality assurance engineer, application engineer, and devops engineer. visit for full position descriptions.if you plan on working outside of melbourne, fl, these roles require travel to melbourne, fl for 90-180 days to undergo necessary training. visa assistance is available.interested? email your resume to careers@certsafe.com.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["interactive"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "in my opinion code_removed and code_removed makes the code more fp than io. haskell is not a purely functional language because that \"looks better\". sometimes it does, often it doesn't. the reason for staying functional is not its syntax but its semantics. it equips us with referential transparency, which makes it far easier to prove invariants, allows very high-level optimisations, makes it easy to write general-purpose code etc.. none of this has much to do with syntax. monadic computations are still purely functional \u2013 regardless of whether you write them with code_removed notation or with code_removed, code_removed and code_removed, so we get haskell's benefits either way. however, notwithstanding the aforementioned fp-benefits, it is often more intuitive to think about algorithms from an imperative-like point of view \u2013 even if you're accustomed to how this is implemented through monads. in these cases, code_removed notation gives you this quick insight of \"order of computation\", \"origin of data\", \"point of modification\", yet it's trivial to manually desugar it in your head to the code_removed version, to grasp what's going on functionally. applicative style is certainly great in many ways, however it is inherently point-free. that is often a good thing, but especially in more complex problems it can be very helpful to give names to \"temporary\" variables. when using only \"fp\" haskell syntax, this requires either lambdas or explicitly named functions. both have good use cases, but the former introduces quite a bit of noise right in the middle of your code and the latter rather disrupts the \"flow\" since it requires a code_removed or code_removed placed somewhere else from where you use it. code_removed, on the other hand, allows you to introduce a named variable right where you need it, without introducing any noise at all.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["very high-level"], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there are some problems with the erlang implementation. as baseline for the following, my measured execution time for your unmodified erlang program was 47.6 seconds, compared to 12.7 seconds for the c code. the first thing you should do if you want to run computationally intensive erlang code is to use native code. compiling with code_removed got the time down to 41.3 seconds. this is however a much lower speedup (just 15%) than expected from native compilation on this kind of code, and the problem is your use of code_removed. this is useful for experimentation, but the fact that all functions are potentially reachable from the outside causes the native compiler to be very conservative. (the normal beam emulator is not that much affected.) replacing this declaration with code_removed gives a much better speedup: 31.5 seconds (almost 35% from the baseline). but the code itself has a problem: for each iteration in the factorcount loop, you perform this test: code_removed the c code doesn't do this. in general, it can be tricky to make a fair comparison between different implementations of the same code, and in particular if the algorithm is numerical, because you need to be sure that they are actually doing the same thing. a slight rounding error in one implementation due to some typecast somewhere may cause it to do many more iterations than the other even though both eventually reach the same result. to eliminate this possible error source (and get rid of the extra test in each iteration), i rewrote the factorcount function as follows, closely modelled on the c code: code_removed this rewrite, no code_removed, and native compilation, gave me the following run time: code_removed which is not too bad compared to the c code: code_removed considering that erlang is not at all geared towards writing numerical code, being only 50% slower than c on a program like this is pretty good. finally, regarding your questions: question 1: do erlang, python and haskell loose speed due to using arbitrary length integers or don't they as long as the values are less than maxint? yes, somewhat. in erlang, there is no way of saying \"use 32/64-bit arithmetic with wrap-around\", so unless the compiler can prove some bounds on your integers (and it usually can't), it must check all computations to see if they can fit in a single tagged word or if it has to turn them into heap-allocated bignums. even if no bignums are ever used in practice at runtime, these checks will have to be performed. on the other hand, that means you know that the algorithm will never fail because of an unexpected integer wraparound if you suddenly give it larger inputs than before. question 4: do my functional implementations permit lco and hence avoid adding unnecessary frames onto the call stack? yes, your erlang code is correct with respect to last call optimization.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["loose"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "people have different styles of learning. i loved lyahfgg, but hated haskell programming from first principles. as is evident from this thread, many others feel the opposite way. both books deserve to exist and be shared frequently.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "lists rock by far the most friendly data structure for sequential data in haskell is the list code_removed lists give you \u03f4(1) cons and pattern matching. the standard library, and for that matter the prelude, is full of useful list functions that should litter your code (code_removed,code_removed,code_removed). lists are persistant, aka purely functional, which is very nice. haskell lists aren't really \"lists\" because they are coinductive (other languages call these streams) so things like code_removed work wonderfully. infinite data structures rock. lists in haskell provide an interface much like iterators in imperative languages (because of laziness). so, it makes sense that they are widely used. on the other hand the first problem with lists is that to index into them code_removed takes \u03f4(k) time, which is annoying. also, appends can be slow code_removed, but haskell's lazy evaluation model means that these can be treated as fully amortized, if they happen at all. the second problem with lists is that they have poor data locality. real processors incur high constants when objects in memory are not laid out next to each other. so, in c++ code_removed has faster \"snoc\" (putting objects at the end) than any pure linked list data structure i know of, although this is not a persistant data structure so less friendly than haskell's lists. the third problem with lists is that they have poor space efficiency. bunches of extra pointers push up your storage (by a constant factor). sequences are functional code_removed is internally based on finger trees (i know, you don't want to know this) which means that they have some nice properties purely functional. code_removed is a fully persistant data structure. darn fast access to the beginning and end of the tree. \u03f4(1) (amortized) to get the first or last element, or to append trees. at the thing lists are fastest at, code_removed is at most a constant slower. \u03f4(log n) access to the middle of the sequence. this includes inserting values to make new sequences high quality api on the other hand, code_removed doesn't do much for the data locality problem, and only works for finite collections (it is less lazy than lists) arrays are not for the faint of heart arrays are one of the most important data structures in cs, but they dont fit very well with the lazy pure functional world. arrays provide \u03f4(1) access to the middle of the collection and exceptionally good data locality/constant factors. but, since they dont fit very well into haskell, they are a pain to use. there are actually a multitude of different array types in the current standard library. these include fully persistant arrays, mutable arrays for the io monad, mutable arrays for the st monad, and un-boxed versions of the above. for more check out the haskell wiki vector is a \"better\" array the code_removed package provides all of the array goodness, in a higher level and cleaner api. unless you really know what you are doing, you should use these if you need array like performance. of-course, some caveats still apply--mutable array like data structures just dont play nice in pure lazy languages. still, sometimes you want that o(1) performance, and code_removed gives it to you in a useable package. you have other options if you just want lists with the ability to efficiently insert at the end, you can use a difference list. the best example of lists screwing up performance tends to come from code_removed which the prelude has aliased as code_removed. code_removed lists are convient, but tend to run on the order of 20 times slower than c strings, so feel free to use code_removed or the very fast code_removed. i'm sure there are other sequence oriented libraries i'm not thinking of right now. conclusion 90+% of the time i need a sequential collection in haskell lists are the right data structure. lists are like iterators, functions that consume lists can easily be used with any of these other data structures using the code_removed functions they come with. in a better world the prelude would be fully parametric as to what container type it uses, but currently code_removed litters the standard library. so, using lists (almost) every where is definitely okay. you can get fully parametric versions of most of the list functions (and are noble to use them) code_removed in fact, code_removed defines an api that is more or less universal across any thing \"list like\". still, although you can be good and write only fully parametric code, most of us are not and use list all over the place. if you are learning, i strongly suggest you do too. edit: based on comments i realize i never explained when to use code_removed vs code_removed. arrays and vectors provide extremely fast indexing and slicing operations, but are fundamentally transient (imperative) data structures. pure functional data structures like code_removed and code_removed let efficiently produce new values from old values as if you had modified the old values. code_removed doesn't modify old list, and it doesn't have to copy it. so even if code_removed is incredibly long, this \"modification\" will be very fast. similarly code_removed will produce a new sequence with a code_removed for in the place of its 3000 element. again, it doesn't destroy the old sequence, it just creates a new one. but, it does this very efficiently, taking o(log(min(k,k-n)) where n is the length of the sequence, and k is the index you modify. you cant easily do this with code_removed and code_removed. they can be modified but that is real imperative modification, and so cant be done in regular haskell code. that means operations in the code_removed package that make modifications like code_removed and code_removed have to copy the entire vector so take code_removed time. the only exception to this is that you can use the mutable version (code_removed) inside the code_removed monad (or code_removed) and do all your modifications just like you would in an imperative language. when you are done, you \"freeze\" your vector to turn in into the immutable structure you want to use with pure code. my feeling is that you should default to using code_removed if a list is not appropriate. use code_removed only if your usage pattern doesn't involve making many modifications, or if you need extremely high performance within the st/io monads. if all this talk of the code_removed monad is leaving you confused: all the more reason to stick to pure fast and beautiful code_removed.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["poor", "extremely high"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "cron works great when you don\u2019t need to guarantee execution, e.g., if a server goes down. unfortunately, all the alternatives are pretty heavyweight, e.g., jenkins, azkaban, airflow. i\u2019ve been working a job scheduler that strives to work like a distributed cron. it works with very little code, because it leans heavily on postgres (for distributed locking, parsing time interval expressions, configuration storage, log storage) and postgrest (for the http api). the application binary (~100 lines of haskell), polls for new jobs, then checks out and execute tasks. the code is here if you\u2019re interested: compiles to machine code, so deploying the binary is easy. that said, i\u2019d like to add some tooling to simplify deploying and configuring postgres and postgrest.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["so"], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}}, {"comentario": "first, damn if that \"affair\" link wasn't one of the funniest things ever! now, while i posted an answer on the other link, i don't think much is happening in haskell web land. you've got happstack and maybe a few other frameworks that don't seem to go anywhere. then you've got fastcgi. if your like me, then fastcgi is probably good enough for most of your needs. most clients, i find, don't really have scale issues (and, besides, its good enough for the ruby folks, right). if fastcgi ain't your speed...well, perhaps yaws or lift (erlang and scala, respectively) are worth a look.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["n't"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "certainly, the obvious thing would be to simply write the desired constraint directly: code_removed alas, ghc gets huffy about that and refuses to play along: code_removed so, as is often the case when attempting to describe type constraints fancy enough to leave ghc recalcitrant, we must resort to some manner of underhanded trickery. recalling some relevant features of ghc where type hackery is involved: it is paranoid about type-level nontermination far out of proportion to the actual inconvenience it entails for the user. it will cheerfully commit itself to decisions about classes and instances before it has considered all the information available. it will dutifully attempt to check anything you've tricked it into committing to. these are the devious principles underlying the familiar old faux-generic instances, where types are unified post-hoc with code_removed in order to improve the type inference behavior of certain type hackery constructs. in this case, however, rather than sneaking type information past ghc, we would need to somehow prevent ghc from noticing a class constraint, which is an entirely different kind of... heeeey, waaaitaminute.... code_removed hoist by its own petard! it's the real deal, too. these are accepted, as you'd hope: code_removed but if we offer it some nonsense instead: code_removed ghc presents us with precisely the error message we'd like to see: code_removed there is one small snag, of course, namely that this: code_removed ...turns out to be less than well-founded, as we've told ghc to check that, whenever code_removed is code_removed, so is code_removed, which does not end well (or at all). the easiest way to avoid this would usually be to boilerplate on a pile of explicit base cases, but here ghc seems intent on diverging any time a code_removed constraint appears in an instance context. i would assume it's being unnecessarily eager in checking instance constraints somehow, and could perhaps be distracted long enough with another layer of trickery, but i'm not immediately sure where to start and have exhausted my capacity for post-midnight type hackery tonight. a bit of irc discussion on #haskell managed to jog my memory slightly on how ghc handles class context constraints, and it appears we can patch things up a little bit by means of a pickier constraint family. using this: code_removed we now have a much more well-behaved recursion for sums: code_removed the recursive case cannot be so easily bisected for products, however, and applying the same changes there improved matters only insofar as i received a context reduction stack overflow rather than it simply hanging in an infinite loop.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["devious"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "similar pattern matches can be useful. in particular, it's not unusual to write code_removed, where the non-binding lazy pattern match is a convenient way to provide the exception type. but using a numeric literal in such a fashion seems like a stretch.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["such", "numeric literal"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "for my personal computing needs i recently upgraded from the combination of an ancient i7 920 quad core desktop and a quad core haswell laptop to a ryzen 2700x desktop and a pile of lovely disposable x220 thinkpads.on the one hand, for software that's not complete garbage in terms of optimization (scientific software, video/audio software, games, my own code) the difference is staggering, i hadn't felt a change this drastic since i moved from pentium 1 to pentium 3. on the other hand, i now know that there is no amount of resources that will make a modern web browser or electron app run well.the good news is that now that i feel i deserve good performance i've made an effort to get rid of most of the crap. apart from disabling js etc. by default and blocking everything i possibly can i have no solution for the browsers, sadly, but everything else is gone. the thinkpads all run minimalistic arch linux setups and mostly work as thin clients, so overall every system i use is snappy and responsive, for the first time in a decade. i shouldn't have needed a hardware upgrade to return to common sense in computing, but it is good to know that with some discipline and a low tolerance for garbage it is still (mostly) possible to have a reasonable computing experience. now, if only there was a usable browser out there...", "aspectos": {"AvailabilityAndScalability": ["low"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["minimalistic"], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": null}}, {"comentario": "how you do it is by first getting a haskell compiler which can target c with the android ndk which comes with a gcc port for arm architectures. jhc can trivially do this with a very small inf style file which describes the platform (word size, c-compiler, etc) i've done this with the wii homebrew dev kit and it was quite easy. however jhc still has some stability issues with complex code such as using a monad transformer stack with io but jhc has been improving a lot over the last 6 months. there is only one person working on jhc i just wished more people could help him. the other option is to build an \"unregistered\" port of ghc targeting the ndk gcc, this is a lot more involved process because ghc is not a true cross-compiler at the moment and you need to understand the build system what parts you need to change. another option is nhc which can cross-compile to c, like ghc you need to build nhc targeting a c compiler, nhc does not have many haskell extensions like ghc. once you have haskell compiler targeting ndk gcc, you will need to write bindings to either the android ndk jni glue code framework (added since android 2.3) or you must write jni glue code between java-c-haskell, the former option is the easier solution and if i remember correctly might actually be backwards compatible with previous versions of android below 2.3. once you have this you must build haskell code as shared library or static library which gets linked into the ndk java glue code (which itself is a shared library). as far as i'm aware you can not officially run native executables on android. you could probably do it with a rooted phone, thus i assume this means you can not distribute native executables on the app store even when the ndk gcc port can generate native executables just fine. this also probably kills the option for using llvm unless you can get the ndk jni working with llvm. the biggest hurdle isn't so much of getting a haskell compiler for android (which is still a big hurdle) the biggest problem is that some one needs to write binding apis for ndk libraries which is a huge task and the situation is worse if you need to write android ui code because there are no ndk apis for this part of the android sdk. if you want to do android ui code in haskell somebody will have to write haskell bindings to java through jni/c. unless there is a more automated process to writing binding libraries (i know there are some, they are just not automated enough for me) then chances of some one doing it are quite low. l01man: is there a tutorial about how to do this? for the first part, i understand i have to download jhc. what do i have to write in the inf file and how to use it? please note before i answer this question i haven't used jhc for quite sometime since i originally wrote this and newer versions have been released since so i do not know how stable jhc currently is when it comes to code generation of more complex haskell programs. this is a warning to anyone before you consider making a large haskell program with jhc, you should do some small tests before you go full on. jhc does have a manual and a section on setting-up cross-compilation and.ini file with options: l01man: the second part is an alternative to the first. i don't know how to do what you said in the third. before you begin you should have some knowledge of c and be comfortable with using the haskell foreign function interface (ffi) and tools such as hs2c. you should also be familiar with using the android ndk and building.apk with shared libraries. you will need to know these to interface between c-haskell, java/c-haskell and develop haskell programs for android that you can officially distribute/sell on the market store. l01man: i understand that its goal is to create a binding for the android api. but... does the 4th part says we can't make.apk with haskell? .apk is just an app package file format and is built with the tools that come with the android sdk (not ndk), this has very little to do building the binaries itself. android packages can contain native shared libraries, this what your haskell program will be and the native shared/static libraries are generated via the android ndk.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["foreign"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@marek \"i just thought that side effects are possible only in monads\" -- the connection is much looser than that: (1) the code_removed type can be used to express side effects; (2) code_removed happens to be a monad, which turns out to be very convenient. monads are not essentially linked to side effects. it should also be noted that there is a meaning of \"effect\" which is broader than \"side effect\" in its usual sense -- one which include pure computations. on this last point, see also what exactly does \u201ceffectful\u201d mean.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["much"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "steven pemberton wrote 2 great posts on f# and wpf, his thoughts on wpf development with f# towards the end of the second post adds to this discussion. 2 other examples that also intrigued me were the use of a functional controller in event driven mvvm and the use of discriminated unions and recursion for constructing a simple interface in the wpf controls demo by flying frog consultancy.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["simple"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "when does branch prediction takes place? when does language will know that array is sorted? i'm thinking of situation of array that looks like: [1,2,3,4,5,...998,999,1000, 3, 10001, 10002]? will this obscure 3 increase running time? will it be as long as unsorted array?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["obscure"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the way i see it, the various code_removed nonfunctions really should only be used in cases where you want to do something that respects referential transparency but whose implementation would otherwise require augmenting the compiler or runtime system to add a new primitive capability. it's easier, more modular, readable, maintainable and agile to use the unsafe stuff than to have to modify the language implementation for things like that. ffi work often intrinsically requires you to do this sort of thing.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": ["new", "primitive"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "i work in a safety-critical industry, and our software projects generally have safety requirements imposed; things that we have to demonstrate that the software does to a high degree of certainty. often these are negatives, such as \" shall not corrupt more frequently than 1 in \". (i should add that these requirements come from statistical system safety requirements). one source of corruption is clearly coding errors, and i would like to use the haskell type system to exclude at least some classes of these errors. something like this: first, here is our critical data item that must not be corrupted. code_removed now i want to store this item in some other structures. code_removed now i want to write a conversion function from foo to bar which is guaranteed not to mess with the critical data. code_removed i want \"goodconvert\" to type check, but \"badconvert\" to fail type checking. obviously i can carefully not import the critical constructor into the module that does conversion. but it would be much better if i could express this property in the type, because then i can compose up functions that are guaranteed to preserve this property. i've tried adding phantom types and \"forall\" in various places, but that doesn't help. one thing that would work would be to not export the critical constructor, and then have code_removed since the only place that these critical data items get created is in the input functions, this makes some sense. but i'd prefer a more elegant and general solution. edit in the comments fuzxxl suggested a look at safe haskell. this looks like the best solution. rather than adding a \"no corruption\" modifier at the type level as i originally wanted, it looks like you can do it at the module level, like this: 1: create a module \"critical\" that exports all the features of the critical data type, including its constructor. mark this module as \"unsafe\" by putting \"{-# language unsafe #-}\" in the header. 2: create a module \"safecritical\" that re-exports everything except the constructor and any other functions that might be used to corrupt a critical value. mark this module as \"trustworthy\". 3: mark any modules that are required to handle critical values without corruption as \"safe\". then use this to demonstrate that any function imported as \"safe\" cannot cause corruption to a critical value. this will leave a smaller minority of code, such as input code that parses critical values, requiring further verification. we can't eliminate this code, but reducing the amount that needs detailed verification is still a significant win. the method is based on the fact that a function cannot invent a new value unless a function returns it. if a function only gets one critical value (as in the \"convert\" function above) then that is the only one it can return. a harder variation of the problem comes when a function has two or more critical values of the same type; it has to guarantee not to mix them up. for instance, code_removed however this can be handled by giving the same treatment to the containing data structures.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": ["further", "detailed"], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": -1, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": 1, "Interoperability": null}}, {"comentario": "i think indexing with the 0/1 value will probably be faster than an integer multiply, but i guess if performance is really critical you should profile it. i agree that small lookup tables are essential to avoid cache pressure, but clearly if you have a bigger cache you can get away with a bigger lookup table, so 4kb is more a rule of thumb than a hard rule. i think you meant code_removed? that would be true for 32-bit. my two-year-old cell phone has a 32kb l1 cache, so even a 4k lookup table might work, especially if the lookup values were a byte instead of an int.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["really critical"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "it's about branch prediction. what is it? a branch predictor is one of the ancient performance improving techniques which still finds relevance into modern architectures. while the simple prediction techniques provide fast lookup and power efficiency they suffer from a high misprediction rate. on the other hand, complex branch predictions \u2013either neural based or variants of two-level branch prediction \u2013provide better prediction accuracy, but they consume more power and complexity increases exponentially. in addition to this, in complex prediction techniques the time taken to predict the branches is itself very high \u2013ranging from 2 to 5 cycles \u2013which is comparable to the execution time of actual branches. branch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption, and low complexity with minimum resources. there really are three different kinds of branches: forward conditional branches - based on a run-time condition, the pc (program counter) is changed to point to an address forward in the instruction stream. backward conditional branches - the pc is changed to point backward in the instruction stream. the branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again. unconditional branches - this includes jumps, procedure calls and returns that have no specific condition. for example, an unconditional jump instruction might be coded in assembly language as simply \"jmp\", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as \"jmpne\" would redirect the instruction stream only if the result of a comparison of two values in a previous \"compare\" instructions shows the values to not be equal. (the segmented addressing scheme used by the x86 architecture adds extra complexity, since jumps can be either \"near\" (within a segment) or \"far\" (outside the segment). each type has different effects on branch prediction algorithms.) static/dynamic branch prediction: static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code. references: branch predictor a demonstration of self-profiling branch prediction review branch prediction", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["ancient", "exponentially"], "Reliability": ["low"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "when reading up on type classes i have seen that the relationship between functors, applicative functors, and monads is that of strictly increasing power. functors are types that can be mapped over. applicative functors can do the same things with certain effects. monads the same with possibly unrestrictive effects. moreover: code_removed the definition of the applicative functor shows this clearly with: code_removed but the definition of monad is: code_removed according to brent yorgey's great typeclassopedia that an alternative definition of monad could be: code_removed which is obviously simpler and would cement that functor < applicative functor < monad. so why isn't this the definition? i know applicative functors are new, but according to the 2010 haskell report page 80, this hasn't changed. why is this?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["strictly"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "right.one technique used for writing games to run on gc'd runtimes is to avoid allocations entirely in the game loop. with a lot of work, you can preallocate everything you're going to need and just modify it as you run.this technique is not a good match for haskell's primary design principle of avoiding mutable state.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["primary"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i'm afraid your proposed optimisation is flawed: code_removed has implementation defined behavior: code_removed has code_removed type, so code_removed will be negative for values less than 128. right shifting a negative value has implementation defined behavior. you can fix this for 2's complement architectures with a simple expression: code_removed for which many compilers will produce code without jumps. alternatively, given the range of code_removed: code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["your propose"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "@erikphilips why don't you let the people who frequent this tag decide if it belongs here? it seems like your only interaction with the haskell community is to put down its questions.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["only"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "a very simple answer is: monads are an abstraction that provide an interface for encapsulating values, for computing new encapsulated values, and for unwrapping the encapsulated value. what's convenient about them in practice is that they provide a uniform interface for creating data types that model state while not being stateful. it's important to understand that a monad is an abstraction, that is, an abstract interface for dealing with a certain kind of data structure. that interface is then used to build data types that have monadic behavior. you can find a very good and practical introduction in monads in ruby, part 1: introduction.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["uniform", "abstract"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i tried with code_removed. this still gives me substantially different results in the live bytes count (63mb) versus the peak data as shown in the profile (approx 6mb). hence i'm still at a loss as to how the memory is being used.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["hence", "still"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "learning elm really helped me learn haskell which is something i'm continuing to do, but elm helped a lot. so i can see why a haskell shop would want to use elm for their frontend work. this makes total sense.that said, my initial enthusiasm for using elm, aside from a gateway-drug to haskell, has waned. i just do not have enough confidence in adopting elm for our internal project nor to recommend it to other companies.the last release of elm was 1 year and 8 months ago. the new release is purported to break many things. however, this new release is unknown, it's really unknown when it's going to be released and aside from a few insiders and contributors no one else seem to know what to expect.elm applies some interesting principles (type safety, purity, etc.) that helps to reason about your code. but, it's direction is driven by one person. that in itself is not bad, however, there is very little communication coming out of him (the last blog update by him was 1.5 years ago). because of that, i started looking at reason and what fb and others are doing.i think it makes no sense to invest months or years into something like elm at this point and any advantages elm might have had initially, is coming to parity with other solutions.i still think if you want to get your hands dirty with functional programming, play around with elm. the pragmatic studio elm lesson is great starting point. but look elsewhere for any serious projects.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["interesting"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["very little"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "the problem you're having is that haskell has different functions for integer and 'fractional' division. integer division truncates, fractional division does not. so instead of code_removed you want to do code_removed what the error message actually means is that the function code_removed is part of the code_removed class. this is basically an interface that different types can implement. to get information on it fire up ghci and do code_removed the first gives you information about the function code_removed: it tells you that it is in the class code_removed. then when you code_removed it shows you all the instances for code_removed. notice that code_removed is not an instance of code_removed so you can't use code_removed with code_removed. another tip: the backticks (`) turn a function into an infix operator so code_removed is the same as code_removed", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["basically"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "> also if you make hardware absolutely optomised for lisp then all the c, fortran, and cobol (this was the 1970's!) programmers aren't particularly interested because it does nothing for their code.yes, but it's different now. now our programming languages are closer to lisp than c. we use javascript, python, ruby, haskell and throw functions all over the place and they come with a cost of frames etc. even \"low level\" languages like c++ and java recently gained powerful capabilities to express lambdas, and c++ programmers use lambdas and std::function pretty often. why not experiment with a machine that can handle function passing better turing machines. it seems like if you use enough high-level structures in your code, even a \"slower\" lisp machine can run your faster than \"fast\" classical turing-machine-like-cpu.this is not even for general purpose cpus. there are embedded devices people write python or javascript code on. why not make those cpus lisp machines?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["powerful"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i think that your first example isn't bad at all. the only syntactic weight is code_removed, plus code_removed instead of code_removed; the latter is offset by the fact that you can omit the function name for each clause. indeed, even dflemstr's proposed code_removed helper function is syntactically heavier. admittedly, it's slightly inconsistent compared to the normal function clause syntax, but this is probably a good thing: it more precisely visually delimits the scope in which code_removed is available.", "aspectos": {"AvailabilityAndScalability": ["only"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 0, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i wrote a hashtable based version of the bytecounter in c++, in 7 lines, two of which were unnecessary, and it profiled in at 8.1ms, on a 28kb file. i too am curious at how you managed 20min in a high-level language catered to aggressive optimization, and why even when correctly banged,it is not competitive with a modern lower level language.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["how"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "some more numbers and explanations for the c version. apparently noone did it during all those years. remember to upvote this answer so it can get on top for everyone to see and learn. step one: benchmark of the author's programs laptop specifications: cpu i3 m380 (931 mhz - maximum battery saving mode) 4gb memory win7 64 bits microsoft visual studio 2012 ultimate cygwin with gcc 4.9.3 python 2.7.10 commands: code_removed . code_removed filenames are: code_removed integertype is the same as the original program for now (more on that later) architecture is x86 or x64 depending on the compiler settings compiler is gcc or vs2012 step two: investigate, improve and benchmark again vs is 250% faster than gcc. the two compilers should give a similar speed. obviously, something is wrong with the code or the compiler options. let's investigate! the first point of interest is the integer types. conversions can be expensive and consistency is important for better code generation & optimizations. all integers should be the same type. it's a mixed mess of code_removed and code_removed right now. we're going to improve that. what type to use? the fastest. gotta benchmark them'all! code_removed integer types are code_removed code_removed code_removed code_removed code_removed and code_removed from code_removed there are lots of integer types in c, plus some signed/unsigned to play with, plus the choice to compile as x86 or x64 (not to be confused with the actual integer size). that is a lot of versions to compile and run ^^ step three: understanding the numbers definitive conclusions: 32 bits integers are ~200% faster than 64 bits equivalents unsigned 64 bits integers are 25 % faster than signed 64 bits (unfortunately, i have no explanation for that) trick question: \"what are the sizes of int and long in c?\" the right answer is: the size of int and long in c are not well-defined! from the c spec: int is at least 32 bits long is at least an int from the gcc man page (-m32 and -m64 flags): the 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any i386 system. the 64-bit environment sets int to 32 bits and long and pointer to 64 bits and generates code for amd\u2019s x86-64 architecture. from msdn documentation (data type ranges) int, 4 bytes, also knows as signed long, 4 bytes, also knows as long int and signed long int to conclude this: lessons learned 32 bits integers are faster than 64 bits integers. standard integers types are not well defined in c nor c++, they vary depending on compilers and architectures. when you need consistency and predictability, use the code_removed integer family from code_removed. speed issues solved. all other languages are back hundreds percent behind, c & c++ win again! they always do. the next improvement will be multithreading using openmp:d", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["similar"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "> monads in haskell are used as a mechanism for scheduling evaluation, thus turning a language with a hard-to-predict evaluation strategy into a language with predictable, sequential, interactions. this makes it possible to add interactive computations such as state and input-output to the language, noting that benign (non-interactive) computations are already a part of the language, transparent to the type system.that's a very operational/imperative perspective, and to my mind is putting the cart before the horse. to me the whole value of monads is that they let you talk about things like state and input-output in a declarative way, using plain old functions and values, rather than having to use these awkward/confusing concepts of \"evaluation\" and \"scheduling\".", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["hard-to-predict", "predictable"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "yes, i knew that idiom from erlang and its guard expressions restriction:) but that gets really ugly when the number of guards increase...", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["when"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "code_removed is the loop. its implementation depends on the data structure to be traversed. that might be a list, tree, code_removed, code_removed(uence), or anything that has a generic way of being traversed via something like a for-loop or recursive function. an array would have a for-loop, a list a while-loop, a tree either something recursive or the combination of a stack with a while-loop; but in functional languages you do not need these cumbersome loop commands: you combine the inner part of the loop (in the shape of a function) with the data structure in a more directly manner and less verbose. with the code_removed typeclass, you could probably write your algorithms more independent and versatile. but my experience says, that code_removed is usually only used to simply glue algorithms to existing data structures. it is quite nice not to need to write similar functions for different datatypes qualified, too.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["more directly"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "the article the essence of the iterator pattern might be helpful as it builds the notion of traverse step by step. some advanced concepts are present though", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["helpful"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "whilst the source shows the primes are not precomputed, this speed up is utterly insane, miles faster than the c version, so what the heck is going on?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["utterly insane", "up"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "location: san diego, caremote: yeswilling to relocate: notechnologies: react native, react, javascript, flow, redux, ruby, rails, postgresql, haskell, type systemsr\u00e9sum\u00e9/cv: hey@workwithgosha.comhey, i\u2019m gosha.i see how programming is just connecting business objectives with reality, not a craft unto itself. languages are all the same to me. (i also wrote toy languages and primitive type systems.)\u2028\u2028i\u2019ve been doing a lot of mobile and front-end work past couple of years, but i know my way around back-ends, architecture, deployment too. most of my experience comes from consulting. you can see my some of past works & references here: also keep a blog about react native & react ( and have self-published a book about forms in react ( my handle has nothing to do with the kkk.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["too"], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": null}}, {"comentario": "i am happy to see i am not the only person in the world that feels like this about signal.the interesting fact is that i \"ctrl+f\" this page for wire and i have seen nothing, even though this comment is about something that made me switch over wire from signal: to date, that's the unique instant messaging that has foss'ed both the server and the clients. (ok, the article also says about matrix.)i admire wire for a number of reasons, but certainly foss'ing all their code is one the main reasons. (the other is... haskell! and also rust.)and just to point out, not only wire bug-fixed the library implementation of the signal protocol, as they use the signal protocol. and their web interface is very good!oh, yes... and they are not based in usa.edit: i am not affiliated with wire, but just a happy customer.:)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["very good!oh"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "the operational perspective is valid but it doesn't help to answer the question, imo. if your answer to \"what is the problem?\" is \"the problem is our hard-to-predict evaluation strategy\", then the beginner's natural follow-up question is \"why not just use a normal evaluation strategy?\", and there's no good answer to that one (indeed many regard haskell's laziness as the wrong choice; in recent times we've seen post-haskell languages e.g. idris moving away from it, and the best-known industrial deployment of haskell uses a strict variant).meanwhile i find monads very useful in scala, even without any laziness in sight.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": ["best-known", "industrial"], "Securability": [], "Interoperability": ["hard-to-predict", "normal"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 0, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": -1, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": 1, "Securability": null, "Interoperability": -1}}, {"comentario": "i'm going to order this guide by the level of skill you have in haskell, going from an absolute beginner right up to an expert. note that this process will take many months (years?), so it is rather long. absolute beginner firstly, haskell is capable of anything, with enough skill. it is very fast (behind only c and c++ in my experience), and can be used for anything from simulations to servers, guis and web applications. however there are some problems that are easier to write for a beginner in haskell than others. mathematical problems and list process programs are good candidates for this, as they only require the most basic of haskell knowledge to be able to write. firstly, some good guides to learning the very basics of haskell are the happy learn haskell tutorial and the first 6 chapters of learn you a haskell. while reading these, it is a very good idea to also be solving simple problems with what you know. another two good resources are haskell programming from first principles, and programming in haskell. they both come with exercises for each chapter, so you have small simple problems matching what you learned on the last few pages. a good list of problems to try is the haskell 99 problems page. these start off very basic, and get more difficult as you go on. it is very good practice doing a lot of those, as they let you practice your skills in recursion and higher order functions. i would recommend skipping any problems that require randomness as that is a bit more difficult in haskell. check this so question in case you want to test your solutions with quickcheck (see intermediate below). once you have done a few of those, you could move on to doing a few of the project euler problems. these are sorted by how many people have completed them, which is a fairly good indication of difficulty. these test your logic and haskell more than the previous problems, but you should still be able to do the first few. a big advantage haskell has with these problems is integers aren't limited in size. to complete some of these problems, it will be useful to have read chapters 7 and 8 of learn you a haskell as well. beginner after that you should have a fairly good handle on recursion and higher order functions, so it would be a good time to start doing some more real world problems. a very good place to start is real world haskell (online book, you can also purchase a hard copy). i found the first few chapters introduced too much too quickly for someone who has never done functional programming/used recursion before. however with the practice you would have had from doing the previous problems you should find it perfectly understandable. working through the problems in the book is a great way of learning how to manage abstractions and building reusable components in haskell. this is vital for people used to object-orientated (oo) programming, as the normal oo abstraction methods (oo classes) don't appear in haskell (haskell has type classes, but they are very different to oo classes, more like oo interfaces). i don't think it is a good idea to skip chapters, as each introduces a lot new ideas that are used in later chapters. after a while you will get to chapter 14, the dreaded monads chapter (dum dum dummmm). almost everyone who learns haskell has trouble understanding monads, due to how abstract the concept is. i can't think of any concept in another language that is as abstract as monads are in functional programming. monads allows many ideas (such as io operations, computations that might fail, parsing,...) to be unified under one idea. so don't feel discouraged if after reading the monads chapter you don't really understand them. i found it useful to read many different explanations of monads; each one gives a new perspective on the problem. here is a very good list of monad tutorials. i highly recommend the all about monads, but the others are also good. also, it takes a while for the concepts to truly sink in. this comes through use, but also through time. i find that sometimes sleeping on a problem helps more than anything else! eventually, the idea will click, and you will wonder why you struggled to understand a concept that in reality is incredibly simple. it is awesome when this happens, and when it does, you might find haskell to be your favorite imperative programming language:) to make sure that you are understanding haskell type system perfectly, you should try to solve 20 intermediate haskell exercises. those exercises using fun names of functions like \"furry\" and \"banana\" and helps you to have a good understanding of some basic functional programming concepts if you don't have them already. nice way to spend your evening with list of paper covered with arrows, unicorns, sausages and furry bananas. intermediate once you understand monads, i think you have made the transition from a beginner haskell programmer to an intermediate haskeller. so where to go from here? the first thing i would recommend (if you haven't already learnt them from learning monads) is the various types of monads, such as reader, writer and state. again, real world haskell and all about monads gives great coverage of this. to complete your monad training learning about monad transformers is a must. these let you combine different types of monads (such as a reader and state monad) into one. this may seem useless to begin with, but after using them for a while you will wonder how you lived without them. now you can finish the real world haskell book if you want. skipping chapters now though doesn't really matter, as long as you have monads down pat. just choose what you are interested in. with the knowledge you would have now, you should be able to use most of the packages on cabal (well the documented ones at least...), as well as most of the libraries that come with haskell. a list of interesting libraries to try would be: parsec: for parsing programs and text. much better than using regexps. excellent documentation, also has a real world haskell chapter. quickcheck: a very cool testing program. what you do is write a predicate that should always be true (eg code_removed). you then pass the predicate the quickcheck, and it will generate a lot of random values (in this case lists) and test that the predicate is true for all results. see also the online manual. hunit: unit testing in haskell. gtk2hs: the most popular gui framework for haskell, lets you write gtk applications in haskell. happstack: a web development framework for haskell. doesn't use databases, instead a data type store. pretty good docs (other popular frameworks would be snap and yesod). also, there are many concepts (like the monad concept) that you should eventually learn. this will be easier than learning monads the first time, as your brain will be used to dealing with the level of abstraction involved. a very good overview for learning about these high level concepts and how they fit together is the typeclassopedia. applicative: an interface like monads, but less powerful. every monad is applicative, but not vice versa. this is useful as there are some types that are applicative but are not monads. also, code written using the applicative functions is often more composable than writing the equivalent code using the monad functions. see functors, applicative functors and monoids from the learn you a haskell guide. foldable,traversable: typeclasses that abstract many of the operations of lists, so that the same functions can be applied to other container types. see also the haskell wiki explaination. monoid: a monoid is a type that has a zero (or mempty) value, and an operation, notated code_removed that joins two monoids together, such that code_removed and code_removed. these are called identity and associativity laws. many types are monoids, such as numbers, with code_removed and code_removed. this is useful in many situations. arrows: arrows are a way of representing computations that take an input and return an output. a function is the most basic type of arrow, but there are many other types. the library also has many very useful functions for manipulating arrows - they are very useful even if only used with plain old haskell functions. arrays: the various mutable/immutable arrays in haskell. st monad: lets you write code with a mutable state that runs very quickly, while still remaining pure outside the monad. see the link for more details. frp: functional reactive programming, a new, experimental way of writing code that handles events, triggers, inputs and outputs (such as a gui). i don't know much about this though. paul hudak's talk about yampa is a good start. there are a lot of new language features you should have a look at. i'll just list them, you can find lots of info about them from google, the haskell wikibook, the haskellwiki.org site and ghc documentation. multiparameter type classes/functional dependencies type families existentially quantified types phantom types gadts others... a lot of haskell is based around category theory, so you may want to look into that. a good starting point is category theory for computer scientist. if you don't want to buy the book, the author's related article is also excellent. finally you will want to learn more about the various haskell tools. these include: ghc (and all its features) cabal: the haskell package system darcs: a distributed version control system written in haskell, very popular for haskell programs. haddock: a haskell automatic documentation generator while learning all these new libraries and concepts, it is very useful to be writing a moderate-sized project in haskell. it can be anything (eg a small game, data analyser, website, compiler). working on this will allow you to apply many of the things you are now learning. you stay at this level for ages (this is where i'm at). expert it will take you years to get to this stage (hello from 2009!), but from here i'm guessing you start writing phd papers, new ghc extensions, and coming up with new abstractions. getting help finally, while at any stage of learning, there are multiple places for getting information. these are: the #haskell irc channel the mailing lists. these are worth signing up for just to read the discussions that take place - some are very interesting. other places listed on the haskell.org home page conclusion well this turned out longer than i expected... anyway, i think it is a very good idea to become proficient in haskell. it takes a long time, but that is mainly because you are learning a completely new way of thinking by doing so. it is not like learning ruby after learning java, but like learning java after learning c. also, i am finding that my object-orientated programming skills have improved as a result of learning haskell, as i am seeing many new ways of abstracting ideas.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["how", "more", "less powerful"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "i'm studying haskell using the book \"haskell programming from first principles\", and towards the end of chapter 4, \"basic datatypes\", i've come across something that confused me. the book mentions a function code_removed and says that it works on code_removeds. everything is fine with that, but when i try this code_removed function with various code_removeds, what i see confused me: first, let's see the type of code_removed: code_removed ok, so i read above as \"takes a foldable, which i think as a list for convenience, and returns an int, that is the number of elements in the list.\" hence my first confusion: why does the the following work at all: code_removed because to me, it seems like i've just passed a tuple with two elements to code_removed, and it returned 1. is tuple a list? is tuple foldable? and of course, why code_removed? now i go one step further: code_removed another try: code_removed but the following works: code_removed is there any good explanation for the behavior i'm observing above? am i misreading the type of code_removed? or is there something else going on behind the scenes?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["first"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "from what i can tell, your best bet would be to build the generated parser (which will generate some c code) and then build a small interface in c. from there i would just use r/python's foreign function interface to call your c wrapper.alternatively for python you could use a parse combinator like parsec. depending on how complicated your file can get, using parsec could very likely be the better choice as it has first class support in python and seems powerful enough to handle your use case.there do seem to be a number of parse combinators in r but none of them seem as well established as parsec for python (which is based on the much more well known parsec for haskell).a quick look around seems to show that python will be your best bet for parsing as it has some decent tooling. here is an article on some of the different parse generators/parse combinators in the space.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["small", "foreign"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "if ghc already has the issue in their bug tracker, why would them coming here get a resolution any faster?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["fast"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "yes, it's possible for a pure function to return the time, if it's given that time as a parameter. different time argument, different time result. then form other functions of time as well and combine them with a simple vocabulary of function(-of-time)-transforming (higher-order) functions. since the approach is stateless, time here can be continuous (resolution-independent) rather than discrete, greatly boosting modularity. this intuition is the basis of functional reactive programming (frp).", "aspectos": {"AvailabilityAndScalability": ["greatly"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i'm currently writing a book with the title \"functional design and architecture\". it provides you with a complete set of techniques how to build a big application using pure functional approach. it describes many functional patterns and ideas while building an scada-like application 'andromeda' for controlling spaceships from scratch. my primary language is haskell. the book covers: approaches to architecture modelling using diagrams; requirements analysis; embedded dsl domain modelling; external dsl design and implementation; monads as subsystems with effects; free monads as functional interfaces; arrowised edsls; inversion of control using free monadic edsls; software transactional memory; lenses; state, reader, writer, rws, st monads; impure state: ioref, mvar, stm; multithreading and concurrent domain modelling; gui; applicability of mainstream techniques and approaches such as uml, solid, grasp; interaction with impure subsystems. you may get familiar with the code for the book here, and the 'andromeda' project code. i expect to finish this book at the end of 2017. until that happens, you may read my article \"design and architecture in functional programming\" (rus) here. update i shared my book online (first 5 chapters). see post on reddit", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["functional"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "by \"code_removed in general\" i mean roughly code_removed, i.e., working on an arbitrary instance. the things you can do with an arbitrary monad are almost exactly the same things you can do with code_removed: receive opaque primitives (as function arguments, or from libraries, respectively), construct no-ops with code_removed, or transform a value in an irreversible manner using code_removed. the essence of programming in an arbitrary monad is generating a list of irrevocable actions: \"do x, then do y, then...\". sounds pretty imperative to me!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["irreversible"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "congrats on the release! i have very high hopes for elm in the future, and i think it truly shifts the paradigm of frontend development.on an attempt to use elm in production i ended up switching back to javascript. the biggest issue i faced was lack of type-classes, which made certain parts of the code feel like i was pulling teeth to get elm's type system to be happy. perhaps this is more of an issue of expecting elm to be more like haskell than it is.i hope elm is able to get more adoption, and with it more examples of idiomatic approaches to problems in elm's style. however this somewhat feels like a chicken-and-egg problem.regardless, this release looks great for people using it in production already!", "aspectos": {"AvailabilityAndScalability": ["more"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there is one tricky point where, if you use it, doing what seems like an innocent refactor can change the behavior of a program. without any bells and whistles, it is this: code_removed but doing perhaps the most common haskell transformation in the book, eta contraction, to code_removed, gives code_removed eta contraction is already not semantics preserving because of the existence of code_removed; but without spoon eta contraction can only change a terminating program into an error; with spoon eta contraction can change a terminating program into a different terminating program. formally, the way code_removed is unsafe is that it is non-monotone on domains (and hence so can be functions defined in terms of it); whereas without code_removed every function is monotone. so technically you lose that useful property of formal reasoning. coming up with a real-life example of when this would be important is left as an exercise for the reader (read: i think it is very unlikely to matter in real life -- unless you start abusing it; e.g. using code_removed the way java programmers use code_removed)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["non-monotone"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "haswell massively improved the branch predictor, which gave a significant ipc boost to many real-world workloads (especially emulation and interpreters).", "aspectos": {"AvailabilityAndScalability": ["significant"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": -1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "if we check the source for ghc, we can find the type used for defining data constructors. it is named datacon, and it has the following field: code_removed going down the rabbit hole, name contains an occname: code_removed an occname contains a code_removed for the name: code_removed finally, a faststring is just a code_removed, also with a precalculated length, and a int to tag it for quick comparison: code_removed there is no limit on the size of the string using this data type (except obviously code_removed). however that doesn't rule out a bug somewhere else in the code that may cause problems. so we need a program to test this: code_removed here is the output of running code_removed: code_removed few interesting points: note how the time taken increases massively after beyond 1 million. you would expect an increase of x10 if the change was linear, but it is a change of x50. this would likely mean for a 100 million character constructor, it would take about 5000 seconds to compile (which i didn't test). the file size for the all of the entries was exactly code_removed. so each char takes up three bytes when used in a constructor.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["massively"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "your code_removed example seems more complicated than one in a modern imperative language; wouldn't you rather use a syntax-sugared iterator-foreach loop, instead of manually traversing your list with a code_removed-construct (requiring you to manually manage the iteration variable)? -- and btw, wouldn't a literal java-syntax translation using a code_removed construct look complicated as well?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["manually"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "for your second point, the term i've seen most often is spine-strict. for a spine-strict list, you could probably use code_removed (from containers) or code_removed (from vector). neither one is a list, however depending on what you're doing one (or both) are likely to be better. sequence provides o(1) cons and snoc, with very fast access to either end of the structure. vector's performance is similar to an array. if you want a more list-like interface to code_removed, you might consider the listlike package (there's a listlike interface for vectors too, but it's less useful because vector provides a fairly comprehensive interface on its own). both are spine-strict. for strict sets, you might try unordered-containers, which also provides a strict map.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["similar"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["more list-like", "listlike", "fairly comprehensive"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 0}}, {"comentario": "@jfritsch: after a map insert you need to copy o(log n) nodes for a tree with n elements. in fact, in general to work with a pure data structure you may have to do an extra logarithmic amount of work over a single mutable ephemeral data structure. but for insert into a tree, you would have to pay for this same amount of overhead just to recurse down to the nodes in the first place, so while a little more memory is allocated, the asymptotic performance of that operation remains the same. with a judy array, it can use small hash tables internally, going o(1) in places.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["asymptotic"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "there are some other lessons too, especially regarding haskell. basically the sad truth is that if you do not benchmark literally every single line, you can suddenly get much worse performance than expected. sometimes ghc's strictness analysis does not discover that it can unbox some things and you land in a boxing-unboxing loop or you hit some of optimization bugs (during the work on performance we've reported over 10 ghc bugs and even implemented our custom graph memory manager). so one of the biggest problems that we encountered earlier was that actually the ghc performance is much harder to predict than you think and you have to take extra care of it while building your software. of course using haskell pays off in other areas, but performance is tricky.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["much bad", "actually hard", "tricky"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "above there are very good detailed answers with theoretical background. but i want to give my view on io monad. i am not experienced haskell programmer, so may be it is quite naive or even wrong. but i helped me to deal with io monad to some extent (note, that it do not relates to other monads). first i want to say, that example with \"real world\" is not too clear for me as we cannot access its (real world) previous states. may be it do not relates to monad computations at all but it is desired in the sense of referential transparency, which is generally presents in haskell code. so we want our language (haskell) to be pure. but we need input/output operations as without them our program cannot be useful. and those operations cannot be pure by their nature. so the only way to deal with this we have to separate impure operations from the rest of code. here monad comes. actually, i am not sure, that there cannot exist other construct with similar needed properties, but the point is that monad have these properties, so it can be used (and it is used successfully). the main property is that we cannot escape from it. monad interface do not have operations to get rid of the monad around our value. other (not io) monads provide such operations and allow pattern matching (e.g. maybe), but those operations are not in monad interface. another required property is ability to chain operations. if we think about what we need in terms of type system, we come to the fact that we need type with constructor, which can be wrapped around any vale. constructor must be private, as we prohibit escaping from it(i.e. pattern matching). but we need function to put value into this constructor (here return comes to mind). and we need the way to chain operations. if we think about it for some time, we will come to the fact, that chaining operation must have type as >>= has. so, we come to something very similar to monad. i think, if we now analyze possible contradictory situations with this construct, we will come to monad axioms. note, that developed construct do not have anything in common with impurity. it only have properties, which we wished to have to be able to deal with impure operations, namely, no-escaping, chaining, and a way to get in. now some set of impure operations is predefined by the language within this selected monad io. we can combine those operations to create new unpure operations. and all those operations will have to have io in their type. note however, that presence of io in type of some function do not make this function impure. but as i understand, it is bad idea to write pure functions with io in their type, as it was initially our idea to separate pure and impure functions. finally, i want to say, that monad do not turn impure operations into pure ones. it only allows to separate them effectively. (i repeat, that it is only my understanding)", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential"], "Deployability": [], "Securability": [], "Interoperability": ["not"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": 0}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": -1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 0, "Deployability": null, "Securability": null, "Interoperability": -1}}, {"comentario": "as data is distributed between 0 and 255 when the array is sorted, around the first half of the iterations will not enter the code_removed-statement (the code_removed statement is shared below). code_removed the question is: what makes the above statement not execute in certain cases as in case of sorted data? here comes the \"branch predictor\". a branch predictor is a digital circuit that tries to guess which way a branch (e.g. an code_removed structure) will go before this is known for sure. the purpose of the branch predictor is to improve the flow in the instruction pipeline. branch predictors play a critical role in achieving high effective performance! let's do some bench marking to understand it better the performance of an code_removed-statement depends on whether its condition has a predictable pattern. if the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. on the other hand, if the pattern is unpredictable, the code_removed-statement will be much more expensive. let\u2019s measure the performance of this loop with different conditions: code_removed here are the timings of the loop with different true-false patterns: code_removed a \u201cbad\u201d true-false pattern can make an code_removed-statement up to six times slower than a \u201cgood\u201d pattern! of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor. so there is no doubt about the impact of branch prediction on performance!", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["high", "effective", "good"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "haskell can perform some checks at compile time that other languages perform at runtime. your question seems to imply you are hoping for arbitrary checks to be lifted to compile time, which isn't possible without a large potential for proof obligations (which could mean you, the programmer, would need to prove the property is true for all uses). in the below, i don't feel like i'm saying anything more than what pigworker touched on while mentioning the very cool sounding code_removed tool. hopefully the additional words on each topic will clarify some of the solution space for you. what people mean (when speaking of haskell's static guarantees) typically when i hear people talk about the static guarantees provided by haskell they are talking about the hindley milner style static type checking. this means one type can not be confused for another - any such misuse is caught at compile time (ex: code_removed is invalid). obviously, this only scratches the surface and we can discuss some more aspects of static checking in haskell. smart constructors: check once at runtime, ensure safety via types gabriel's solution is to have a type, code_removed, that can only be positive. building positive values still requires a check at runtime but once you have a positive there are no checks required by consuming functions - the static (compile time) type checking can be leveraged from here. this is a good solution for many many problems. i recommended the same thing when discussing golden numbers. never-the-less, i don't think this is what you are fishing for. exact representations dflemstr commented that you can use a type, code_removed, which is unable to represent negative numbers (a slightly different issue than representing positives). in this manner you really don't need to use a guarded constructor (as above) because there is no inhabitant of the type that violates your invariant. a more common example of using proper representations is non-empty lists. if you want a type that can never be empty then you could just make a non-empty list type: code_removed this is in contrast to the traditional list definition using code_removed instead of code_removed. going back to the positive example, you could use a form of peano numbers: code_removed or user gadts to build unsigned binary numbers (and you can add code_removed, and other instances, allowing functions like code_removed): code_removed external proofs while not part of the haskell universe, it is possible to generate haskell using alternate systems (such as coq) that allow richer properties to be stated and proven. in this manner the haskell code can simply omit checks like code_removed but the fact that x will always be greater than 0 will be a static guarantee (again: the safety is not due to haskell). from what pigworker said, i would classify code_removed in this category. haskell has not grown sufficiently to perform your desired tasks, but tools to generate haskell (in this case, very thin layers over haskell) continue to make progress. research on more descriptive static properties the research community that works with haskell is wonderful. while too immature for general use, people have developed tools to do things like statically check function partiality and contracts. if you look around you'll find it's a rich field.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["large", "n't possible"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "might i recommend jeremy gibbons' excellent book patterns in fp: patternsinfp.wordpress.com and his quite comprehensible paper \"calculating functional programs\"? they both cover coalgebras in a quite rigorous fashion (compared to, e.g., a blog post), but they are also fairly self contained for someone who knows a bit of haskell.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["quite rigorous"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": 1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "i would really recommend reading the 1.2 von neumann languages (or really the whole first chapter) in introduction to functional programming systems using haskell. the author does a really great job at explaining why referential transparency is so important to mathematics.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["referential", "why important"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "because i find the question interesting, i decided to write down my thoughts on the subject: logical say we define code_removed as \"the list, that, if you put code_removed on its end, is equal to xs. this is equivalent to: code_removed is the list without its last element. for code_removed, there exists no last element, so code_removed has to be undefined. you could add a special case for this, like in \"if xs is the empty list, then code_removed is the empty list, otherwise code_removed is the list, that, if you put code_removed on its end, is equal to xs\". notice how this is much more verbose and less clean. we introduce additional complexity, but what for? intuitive code_removed note how the length of the lists on the right-hand side of the equations decreases along with the length of the left-hand side. to me, this series cannot be continued in a sensible way, because the list on the right side would have to have a negative size! practical as others have pointed out, defining a special case handling for code_removed or code_removed for the empty list as an argument, can introduce hard-to-spot errors in situations where functions can have no sensible result for the empty list, but still don't produce an exception for it! furthermore, i can think of no algorithm were it would actually be of advantage to have code_removed evaluate to code_removed, so why introduce that extra complexity? programming is all about simplicity and especially haskell is all about purity, wouldn't you agree?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["how"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "this type of signaling is very real and present in functional programming languages specifically. java programmers feel insecure because they're not writing scala, the scala people wish they were as functional as the haskell people, the haskell people wish they were as advanced as the academic idris people.it's a never ending comparison contest. and despite functional programming having an objectively higher barrier to entry, it is entirely possible to write absolute garbage code in an fp language as well.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": ["objectively high"], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": -1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": 1, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "arrowized frp also has the neat feature that signals are always stated in context of their inputs which lets you transform the outputs covariantly and the inputs contravariantly in order to better simulate interactive frp. see genuinely functional user interfaces by courtney and elliott for a great example of that feature.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["genuinely functional"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "i have data types defined as: code_removed now, as it stands, i have a persistent model defined as: code_removed i can pretty easily create a query to populate a committeeview, using esqueleto. it would go something like this: code_removed now, consider the problem of populating code_removed. in principle, we get enough data to populate by running subquery in the above query. okay, fair enough. now how can i use \"group by haskell-list\" like code_removed in sql? how can i fold rows so that i can end up with a list of lists of people? i get the impression that code_removed can't handle the case as such (i.e., it doesn't have a combinator that would do it). and my underlying database obviously doesn't support haskell lists as a column. but, surely, i can't be the only person to face this issue. what is an effective strategy? folding an n-list of lists into a n-list? or running code_removed queries? are there any other options?", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": ["effective"]}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": 1}}, {"comentario": "@lucas: the big one vs. bare-bones haskell is lack of higher-kinded polymorphism and type classes. beyond that, quite a few ghc-specific extensions are pretty nice. none of it's a fatal flaw by any means, but after getting used to haskell it just feels kinda clumsy not having that stuff. imagine going from modern c# back to using c# 1.x...", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": ["fatal"], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": 0, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": -1, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "very good point about code_removed being so light weight in haskell!", "aspectos": {"AvailabilityAndScalability": ["so", "light"], "Maintainability": [], "Performance": [], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": 1, "Maintainability": null, "Performance": null, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}, {"comentario": "last i checked haskell \"primes\" was just a huge list of precomputed primes -- no computation, just lookup. so yes, of course this will be faster, but it tells you nothing about the computational speed of deriving primes in haskell.", "aspectos": {"AvailabilityAndScalability": [], "Maintainability": [], "Performance": ["computational"], "Reliability": [], "Deployability": [], "Securability": [], "Interoperability": []}, "clas_modelo": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_modelo_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_tb_no_neutro": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": -1, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}, "clas_manual": {"AvailabilityAndScalability": null, "Maintainability": null, "Performance": 0, "Reliability": null, "Deployability": null, "Securability": null, "Interoperability": null}}]